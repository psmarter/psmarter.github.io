<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>PMPP-第五章：内存架构和数据局部性 | Smarter's blog</title><meta name="author" content="Smarter"><meta name="copyright" content="Smarter"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="前言 第四章理解了GPU的调度机制和硬件架构，这一章进入性能优化的核心——内存。GPU计算能力强大，但数据供应跟不上就白搭。第五章讲解GPU的内存层次结构，重点是Shared Memory和Tiling技术。掌握这些，矩阵乘法性能可以提升10倍以上。  📦 配套资源：本系列文章配有完整的 GitHub 仓库，包含每章的练习题解答、CUDA 代码实现和详细注释。所有代码都经过测试，可以直接运行。">
<meta property="og:type" content="article">
<meta property="og:title" content="PMPP-第五章：内存架构和数据局部性">
<meta property="og:url" content="https://smarter.xin/posts/3bb3179b/">
<meta property="og:site_name" content="Smarter&#39;s blog">
<meta property="og:description" content="前言 第四章理解了GPU的调度机制和硬件架构，这一章进入性能优化的核心——内存。GPU计算能力强大，但数据供应跟不上就白搭。第五章讲解GPU的内存层次结构，重点是Shared Memory和Tiling技术。掌握这些，矩阵乘法性能可以提升10倍以上。  📦 配套资源：本系列文章配有完整的 GitHub 仓库，包含每章的练习题解答、CUDA 代码实现和详细注释。所有代码都经过测试，可以直接运行。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://smarter.xin/img/PMPP.jpg">
<meta property="article:published_time" content="2026-01-16T02:16:08.000Z">
<meta property="article:modified_time" content="2026-01-18T14:12:10.556Z">
<meta property="article:author" content="Smarter">
<meta property="article:tag" content="CUDA">
<meta property="article:tag" content="GPU编程">
<meta property="article:tag" content="并行计算">
<meta property="article:tag" content="PMPP">
<meta property="article:tag" content="Tiling">
<meta property="article:tag" content="共享内存">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://smarter.xin/img/PMPP.jpg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "PMPP-第五章：内存架构和数据局部性",
  "url": "https://smarter.xin/posts/3bb3179b/",
  "image": "https://smarter.xin/img/PMPP.jpg",
  "datePublished": "2026-01-16T02:16:08.000Z",
  "dateModified": "2026-01-18T14:12:10.556Z",
  "author": [
    {
      "@type": "Person",
      "name": "Smarter",
      "url": "https://smarter.xin/"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.svg"><link rel="canonical" href="https://smarter.xin/posts/3bb3179b/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-C3EHX75F81"></script><script>window.dataLayer = window.dataLayer || []
function gtag(){dataLayer.push(arguments)}
gtag('js', new Date())
gtag('config', 'G-C3EHX75F81')
btf.addGlobalFn('pjaxComplete', () => {
  gtag('config', 'G-C3EHX75F81', {'page_path': window.location.pathname})
}, 'google_analytics')
</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.json","preload":false,"top_n_per_article":3,"unescape":true,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":true},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'PMPP-第五章：内存架构和数据局部性',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/js-heo@1.0.11/mainColor/heoMainColor.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/js-heo@1.0.11/poem/poem.css"><!-- hexo injector head_end start --><link rel="stylesheet" href="/css/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="/css/swiperstyle.css" media="print" onload="this.media='all'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="Smarter's blog" type="application/atom+xml">
</head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><script>(()=>{
  const $loadingBox = document.getElementById('loading-box')
  const $body = document.body
  const preloader = {
    endLoading: () => {
      $body.style.overflow = ''
      $loadingBox.classList.add('loaded')
    },
    initLoading: () => {
      $body.style.overflow = 'hidden'
      $loadingBox.classList.remove('loaded')
    }
  }

  preloader.initLoading()
  window.addEventListener('load', preloader.endLoading)

  if (false) {
    btf.addGlobalFn('pjaxSend', preloader.initLoading, 'preloader_init')
    btf.addGlobalFn('pjaxComplete', preloader.endLoading, 'preloader_end')
  }
})()</script><div id="web_bg" style="background-image: url(/img/backup.jpg);"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">72</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">110</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">12</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/img/PMPP.jpg);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><img class="site-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/nav6.gif" alt="Logo"><span class="site-name">Smarter's blog</span></a><a class="nav-page-title" href="/"><span class="site-name">PMPP-第五章：内存架构和数据局部性</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">PMPP-第五章：内存架构和数据局部性</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2026-01-16T02:16:08.000Z" title="发表于 2026-01-16 10:16:08">2026-01-16</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2026-01-18T14:12:10.556Z" title="更新于 2026-01-18 22:12:10">2026-01-18</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/knowledge-sharing/">知识分享</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">3.2k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>12分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><section class="main-hero-waves-area waves-area"><svg class="waves-svg" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M -160 44 c 30 0 58 -18 88 -18 s 58 18 88 18 s 58 -18 88 -18 s 58 18 88 18 v 44 h -352 Z"></path></defs><g class="parallax"><use href="#gentle-wave" x="48" y="0"></use><use href="#gentle-wave" x="48" y="3"></use><use href="#gentle-wave" x="48" y="5"></use><use href="#gentle-wave" x="48" y="7"></use></g></svg></section></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h2 id="qian-yan" tabindex="-1" id="前言">前言</h2>
<p>第四章理解了GPU的调度机制和硬件架构，这一章进入性能优化的核心——内存。GPU计算能力强大，但数据供应跟不上就白搭。第五章讲解GPU的内存层次结构，重点是Shared Memory和Tiling技术。掌握这些，矩阵乘法性能可以提升10倍以上。</p>
<blockquote>
<p><strong>📦 配套资源</strong>：本系列文章配有完整的 <a target="_blank" rel="noopener" href="https://github.com/psmarter/PMPP-Learning">GitHub 仓库</a>，包含每章的练习题解答、CUDA 代码实现和详细注释。所有代码都经过测试，可以直接运行。</p>
</blockquote>
<h2 id="nei-cun-dai-kuan-xing-neng-de-tian-hua-ban" tabindex="-1" id="内存带宽：性能的天花板">内存带宽：性能的天花板</h2>
<h3 id="wen-ti-de-ben-zhi" tabindex="-1" id="问题的本质">问题的本质</h3>
<p>回顾第三章的矩阵乘法：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">__global__ void matMul(float *M, float *N, float *P, int width) &#123;</span><br><span class="line">    int row = blockIdx.y * blockDim.y + threadIdx.y;</span><br><span class="line">    int col = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    </span><br><span class="line">    if (row &lt; width &amp;&amp; col &lt; width) &#123;</span><br><span class="line">        float sum = 0.0f;</span><br><span class="line">        for (int k = 0; k &lt; width; k++) &#123;</span><br><span class="line">            sum += M[row * width + k] * N[k * width + col];</span><br><span class="line">        &#125;</span><br><span class="line">        P[row * width + col] = sum;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>计算 P[row][col] 需要读取 M 的一行和 N 的一列，共 2×width 个元素。每个元素 4 字节，width=1024 时：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">每线程读取：2 × 1024 × 4 = 8192 字节</span><br><span class="line">每线程计算：2 × 1024 = 2048 FLOP</span><br><span class="line">算术强度：2048 / 8192 = 0.25 FLOP/Byte</span><br></pre></td></tr></table></figure>
<p>现代 GPU 峰值 10+ TFLOPS，带宽 500+ GB/s，需要 20 FLOP/Byte 才能跑满计算单元。实际只有 0.25，<strong>GPU 大部分时间在等数据</strong>。</p>
<h3 id="shu-ju-zhong-fu-fang-wen" tabindex="-1" id="数据重复访问">数据重复访问</h3>
<p>更严重的是：<strong>同一数据被多个线程重复读取</strong>。</p>
<p>M[i][k] 被第 i 行的所有线程读取，N[k][j] 被第 j 列的所有线程读取。1024×1024 矩阵，每个元素被读 1024 次，但每次都从全局内存（DRAM）读。</p>
<p>这就是优化的切入点：<strong>让数据复用发生在快速存储上，而不是全局内存</strong>。</p>
<h2 id="gpu-nei-cun-ceng-ci" tabindex="-1" id="GPU-内存层次">GPU 内存层次</h2>
<h3 id="ceng-ci-jie-gou" tabindex="-1" id="层次结构">层次结构</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">┌─────────────────────────────────────────────┐</span><br><span class="line">│                   Host Memory               │   CPU DDR4/DDR5</span><br><span class="line">│                   (GB 级别)                  │   ~50 GB/s</span><br><span class="line">├─────────────────────────────────────────────┤</span><br><span class="line">│              Global Memory (DRAM)           │   GPU 显存</span><br><span class="line">│                  (GB 级别)                   │   ~500 GB/s</span><br><span class="line">├─────────────────────────────────────────────┤</span><br><span class="line">│    L2 Cache (SM 共享)                        │   几 MB</span><br><span class="line">│                                              │   ~1-2 TB/s</span><br><span class="line">├──────────────┬──────────────┬───────────────┤</span><br><span class="line">│   Shared     │   Shared     │   Shared      │   每 SM</span><br><span class="line">│   Memory     │   Memory     │   Memory      │   ~100 KB</span><br><span class="line">│   L1 Cache   │   L1 Cache   │   L1 Cache    │   ~10 TB/s</span><br><span class="line">├──────────────┼──────────────┼───────────────┤</span><br><span class="line">│  Registers   │  Registers   │  Registers    │   每线程</span><br><span class="line">│              │              │               │   ~几十 TB/s</span><br><span class="line">└──────────────┴──────────────┴───────────────┘</span><br><span class="line">     SM 0           SM 1           SM 2</span><br></pre></td></tr></table></figure>
<p><strong>核心规律</strong>：越靠近计算单元，容量越小，速度越快。</p>
<h3 id="ge-ji-cun-chu-te-dian" tabindex="-1" id="各级存储特点">各级存储特点</h3>
<table>
<thead>
<tr>
<th>存储类型</th>
<th>作用域</th>
<th>容量</th>
<th>延迟</th>
<th>程序员控制</th>
</tr>
</thead>
<tbody>
<tr>
<td>寄存器</td>
<td>单线程</td>
<td>~255个/线程</td>
<td>1周期</td>
<td>隐式（变量）</td>
</tr>
<tr>
<td>共享内存</td>
<td>Block内</td>
<td>~100KB/SM</td>
<td>~20周期</td>
<td>显式</td>
</tr>
<tr>
<td>L1缓存</td>
<td>SM内</td>
<td>~128KB/SM</td>
<td>~20周期</td>
<td>部分</td>
</tr>
<tr>
<td>L2缓存</td>
<td>全局</td>
<td>~6MB</td>
<td>~200周期</td>
<td>无</td>
</tr>
<tr>
<td>全局内存</td>
<td>全局</td>
<td>~数GB</td>
<td>~400周期</td>
<td>显式</td>
</tr>
</tbody>
</table>
<p><strong>关键洞察</strong>：</p>
<ul>
<li><strong>寄存器</strong>最快，但容量有限，且只属于单个线程</li>
<li><strong>共享内存</strong>是程序员可控的 Block 级缓存，这是优化的主战场</li>
<li><strong>全局内存</strong>是唯一能容纳大数据的地方，但太慢</li>
</ul>
<h2 id="gong-xiang-nei-cun-shared-memory" tabindex="-1" id="共享内存（Shared-Memory）">共享内存（Shared Memory）</h2>
<h3 id="ji-ben-gai-nian" tabindex="-1" id="基本概念">基本概念</h3>
<p>共享内存是 SM 上的可编程缓存：</p>
<ul>
<li><strong>Block 内所有线程共享</strong>：同 Block 的线程可以读写同一块共享内存</li>
<li><strong>生命周期与 Block 绑定</strong>：Block 结束，共享内存释放</li>
<li><strong>低延迟</strong>：约 20 周期，比全局内存快 20 倍</li>
</ul>
<h3 id="sheng-ming-yu-fa" tabindex="-1" id="声明语法">声明语法</h3>
<p><strong>静态分配</strong>（编译时确定大小）：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">__global__ void kernel() &#123;</span><br><span class="line">    __shared__ float sharedData[256];  // Block 内共享</span><br><span class="line">    // ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>动态分配</strong>（运行时确定大小）：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">__global__ void kernel() &#123;</span><br><span class="line">    extern __shared__ float sharedData[];  // 大小由启动配置指定</span><br><span class="line">    // ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 启动时指定共享内存大小</span><br><span class="line">kernel&lt;&lt;&lt;grid, block, sharedMemBytes&gt;&gt;&gt;(args);</span><br></pre></td></tr></table></figure>
<h3 id="tong-bu-syncthreads" tabindex="-1" id="同步：-syncthreads">同步：__syncthreads()</h3>
<p>共享内存是 Block 内共享的，需要同步保证数据一致性：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">__shared__ float data[256];</span><br><span class="line"></span><br><span class="line">// 阶段1：所有线程写入</span><br><span class="line">data[threadIdx.x] = input[globalIdx];</span><br><span class="line"></span><br><span class="line">__syncthreads();  // 等待所有线程完成写入</span><br><span class="line"></span><br><span class="line">// 阶段2：所有线程读取（此时数据已就绪）</span><br><span class="line">float val = data[(threadIdx.x + 1) % 256];</span><br></pre></td></tr></table></figure>
<p><strong>__syncthreads() 是栅栏同步</strong>：Block 内所有线程必须到达这一点，才能继续执行。</p>
<p><strong>常见错误</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">// 危险！条件内使用 syncthreads</span><br><span class="line">if (threadIdx.x &lt; 128) &#123;</span><br><span class="line">    data[threadIdx.x] = ...;</span><br><span class="line">    __syncthreads();  // 只有部分线程执行，会死锁！</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>同步必须保证 Block 内所有活跃线程都执行到。</p>
<h2 id="tiling-fen-kuai-chu-li" tabindex="-1" id="Tiling：分块处理">Tiling：分块处理</h2>
<h3 id="he-xin-si-xiang" tabindex="-1" id="核心思想">核心思想</h3>
<p>既然全局内存慢但共享内存快，策略就是：</p>
<ol>
<li><strong>分块加载</strong>：将数据分成小块（Tile），逐块加载到共享内存</li>
<li><strong>计算复用</strong>：在共享内存中完成该块的所有计算</li>
<li><strong>移动窗口</strong>：处理下一块，直到完成</li>
</ol>
<p>这样，每个数据从全局内存只读一次，但在共享内存中被多次使用。</p>
<h3 id="tiled-ju-zhen-cheng-fa" tabindex="-1" id="Tiled-矩阵乘法">Tiled 矩阵乘法</h3>
<p><strong>问题</strong>：计算 P = M × N，每个 P[i][j] = Σ M[i][k] × N[k][j]</p>
<p><strong>朴素版本</strong>：每个线程独立读取整行和整列（大量重复读取）</p>
<p><strong>Tiled 版本</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">┌───────────────┐   ┌───────────────┐</span><br><span class="line">│   M 矩阵       │   │   N 矩阵       │</span><br><span class="line">│  ┌───┐        │   │      ┌───┐    │</span><br><span class="line">│  │Tile│ ────→ │   │      │Tile│   │</span><br><span class="line">│  └───┘        │   │      └───┘    │</span><br><span class="line">│               │   │        │      │</span><br><span class="line">└───────────────┘   └────────│──────┘</span><br><span class="line">                             ↓</span><br><span class="line">                    ┌───────────────┐</span><br><span class="line">                    │   P 矩阵       │</span><br><span class="line">                    │      ┌───┐    │</span><br><span class="line">                    │      │计算│    │</span><br><span class="line">                    │      └───┘    │</span><br><span class="line">                    └───────────────┘</span><br></pre></td></tr></table></figure>
<p><strong>步骤</strong>：</p>
<ol>
<li>将 M 的一个 Tile 和 N 的一个 Tile 加载到共享内存</li>
<li>Block 内所有线程使用共享内存中的数据进行部分计算</li>
<li>加载下一对 Tile，累加结果</li>
<li>重复直到完成</li>
</ol>
<h3 id="dai-ma-shi-xian" tabindex="-1" id="代码实现">代码实现</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">#define TILE_WIDTH 16</span><br><span class="line"></span><br><span class="line">__global__ void matMulTiled(float *M, float *N, float *P, int width) &#123;</span><br><span class="line">    // 共享内存声明</span><br><span class="line">    __shared__ float Mds[TILE_WIDTH][TILE_WIDTH];</span><br><span class="line">    __shared__ float Nds[TILE_WIDTH][TILE_WIDTH];</span><br><span class="line">    </span><br><span class="line">    int bx = blockIdx.x, by = blockIdx.y;</span><br><span class="line">    int tx = threadIdx.x, ty = threadIdx.y;</span><br><span class="line">    </span><br><span class="line">    // 计算该线程负责的 P 元素位置</span><br><span class="line">    int row = by * TILE_WIDTH + ty;</span><br><span class="line">    int col = bx * TILE_WIDTH + tx;</span><br><span class="line">    </span><br><span class="line">    float Pvalue = 0;</span><br><span class="line">    </span><br><span class="line">    // 分块循环</span><br><span class="line">    for (int ph = 0; ph &lt; width / TILE_WIDTH; ++ph) &#123;</span><br><span class="line">        </span><br><span class="line">        // 协作加载 M 的 Tile</span><br><span class="line">        Mds[ty][tx] = M[row * width + (ph * TILE_WIDTH + tx)];</span><br><span class="line">        </span><br><span class="line">        // 协作加载 N 的 Tile</span><br><span class="line">        Nds[ty][tx] = N[(ph * TILE_WIDTH + ty) * width + col];</span><br><span class="line">        </span><br><span class="line">        __syncthreads();  // 确保 Tile 加载完成</span><br><span class="line">        </span><br><span class="line">        // 使用共享内存计算部分点积</span><br><span class="line">        for (int k = 0; k &lt; TILE_WIDTH; ++k) &#123;</span><br><span class="line">            Pvalue += Mds[ty][k] * Nds[k][tx];</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        __syncthreads();  // 确保计算完成再加载下一个 Tile</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    P[row * width + col] = Pvalue;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="guan-jian-dian-jie-xi" tabindex="-1" id="关键点解析">关键点解析</h3>
<p><strong>1. 协作加载</strong></p>
<p>Block 内的线程分工加载 Tile：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Mds[ty][tx] = M[row * width + (ph * TILE_WIDTH + tx)];</span><br></pre></td></tr></table></figure>
<p>每个线程加载一个元素，16×16 = 256 个线程加载 256 个元素。比单线程加载整个 Tile 高效得多。</p>
<p><strong>2. 两次同步</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">__syncthreads();  // 第一次：确保数据加载完成</span><br><span class="line">// ... 计算 ...</span><br><span class="line">__syncthreads();  // 第二次：确保计算完成再覆盖共享内存</span><br></pre></td></tr></table></figure>
<p>两次同步都必要：</p>
<ul>
<li>第一次：防止读到未加载的数据</li>
<li>第二次：防止快线程覆盖慢线程还在用的数据</li>
</ul>
<p><strong>3. 内层循环</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">for (int k = 0; k &lt; TILE_WIDTH; ++k) &#123;</span><br><span class="line">    Pvalue += Mds[ty][k] * Nds[k][tx];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这个循环只访问共享内存，没有全局内存访问。这是性能提升的来源。</p>
<h3 id="xing-neng-fen-xi" tabindex="-1" id="性能分析">性能分析</h3>
<p><strong>朴素版本</strong>：</p>
<ul>
<li>每线程读取全局内存：2 × width 次</li>
<li>总全局内存访问：width³ × 2（读）+ width²（写）</li>
</ul>
<p><strong>Tiled 版本</strong>：</p>
<ul>
<li>每 Tile 阶段：Block 读 2 × TILE_WIDTH² 个元素</li>
<li>共 width/TILE_WIDTH 个阶段</li>
<li>每线程贡献：2 × width 次（与朴素相同？不对！）</li>
</ul>
<p><strong>关键差异</strong>：在 Tiled 版本中，每个全局内存读取被 TILE_WIDTH 个线程共享使用。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">全局内存访问减少倍数 = TILE_WIDTH</span><br><span class="line">算术强度提升 = TILE_WIDTH 倍</span><br></pre></td></tr></table></figure>
<p>TILE_WIDTH = 16 时，算术强度从 0.25 提升到 4 FLOP/Byte。TILE_WIDTH = 32 时可达 8 FLOP/Byte。</p>
<h3 id="bian-jie-chu-li" tabindex="-1" id="边界处理">边界处理</h3>
<p>上面的代码假设 width 是 TILE_WIDTH 的倍数。实际需要处理边界：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">// 带边界检查的加载</span><br><span class="line">if (row &lt; width &amp;&amp; (ph * TILE_WIDTH + tx) &lt; width)</span><br><span class="line">    Mds[ty][tx] = M[row * width + (ph * TILE_WIDTH + tx)];</span><br><span class="line">else</span><br><span class="line">    Mds[ty][tx] = 0;  // 越界元素填0</span><br><span class="line"></span><br><span class="line">if ((ph * TILE_WIDTH + ty) &lt; width &amp;&amp; col &lt; width)</span><br><span class="line">    Nds[ty][tx] = N[(ph * TILE_WIDTH + ty) * width + col];</span><br><span class="line">else</span><br><span class="line">    Nds[ty][tx] = 0;</span><br></pre></td></tr></table></figure>
<p>填 0 不影响加法结果，是处理边界的常用技巧。</p>
<h2 id="nei-cun-fang-wen-mo-shi" tabindex="-1" id="内存访问模式">内存访问模式</h2>
<h3 id="he-bing-fang-wen-coalesced-access" tabindex="-1" id="合并访问（Coalesced-Access）">合并访问（Coalesced Access）</h3>
<p>GPU 内存控制器按 <strong>32 字节或 128 字节</strong> 的事务读写数据。如果 Warp 中的线程访问连续地址，可以合并成一次事务：</p>
<p><strong>好的访问模式</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// 线程 0,1,2,...,31 访问连续地址</span><br><span class="line">data[threadIdx.x];  // 一次 128B 事务</span><br></pre></td></tr></table></figure>
<p><strong>差的访问模式</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// 线程 0,1,2,...,31 访问跨步地址</span><br><span class="line">data[threadIdx.x * 32];  // 32 次事务！</span><br></pre></td></tr></table></figure>
<p><strong>矩阵访问的陷阱</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">// P[i][j] 遍历</span><br><span class="line">// 按行遍历（好）：data[row * width + col]，col 连续</span><br><span class="line">// 按列遍历（差）：data[row * width + col]，row 连续（跨步 = width）</span><br></pre></td></tr></table></figure>
<h3 id="gong-xiang-nei-cun-bank-chong-tu" tabindex="-1" id="共享内存-Bank-冲突">共享内存 Bank 冲突</h3>
<p>共享内存分成 32 个 <strong>Bank</strong>，每个 Bank 宽度 4 字节。不同 Bank 可以同时访问，但同一 Bank 的不同地址会串行化。</p>
<p><strong>Bank 映射</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">地址 0,32,64,...  → Bank 0</span><br><span class="line">地址 4,36,68,...  → Bank 1</span><br><span class="line">地址 8,40,72,...  → Bank 2</span><br><span class="line">...</span><br><span class="line">地址 124,156,... → Bank 31</span><br></pre></td></tr></table></figure>
<p><strong>无冲突</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data[threadIdx.x];      // 32 线程访问 32 个 Bank</span><br><span class="line">data[threadIdx.x * 2];  // 跨步 2，访问 Bank 0,2,4,...（无冲突）</span><br></pre></td></tr></table></figure>
<p><strong>有冲突</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data[threadIdx.x * 32]; // 所有线程访问 Bank 0！32-way 冲突</span><br></pre></td></tr></table></figure>
<p><strong>特例——广播</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data[0];  // 所有线程读同一地址，硬件广播，无冲突</span><br></pre></td></tr></table></figure>
<h3 id="ju-zhen-zhuan-zhi-de-bank-chong-tu" tabindex="-1" id="矩阵转置的-Bank-冲突">矩阵转置的 Bank 冲突</h3>
<p>考虑共享内存中 16×16 的矩阵：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">__shared__ float tile[16][16];</span><br><span class="line"></span><br><span class="line">// 加载（列访问）</span><br><span class="line">tile[ty][tx] = input[row * width + col];  // 无冲突</span><br><span class="line"></span><br><span class="line">// 存储（行访问）</span><br><span class="line">output[col * width + row] = tile[tx][ty];  // 有冲突！</span><br></pre></td></tr></table></figure>
<p><code>tile[tx][ty]</code> 使得线程 0,1,2,…,15 分别访问 tile[0][ty], tile[1][ty], …，这些元素地址为 ty, ty+16, ty+32, …，步长 16×4 = 64 字节 = 16 个 Bank。部分线程会访问同一 Bank。</p>
<p><strong>解决方案——Padding</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">__shared__ float tile[16][17];  // 多加一列</span><br><span class="line"></span><br><span class="line">// 现在 tile[i][j] 的地址是 i*17 + j</span><br><span class="line">// 步长变成 17×4 = 68 字节，不再对齐</span><br></pre></td></tr></table></figure>
<p>Padding 打破了 Bank 对齐，消除冲突。代价是浪费一点共享内存。</p>
<h2 id="chang-liang-nei-cun-constant-memory" tabindex="-1" id="常量内存（Constant-Memory）">常量内存（Constant Memory）</h2>
<h3 id="te-dian" tabindex="-1" id="特点">特点</h3>
<ul>
<li><strong>只读</strong>：Kernel 内不能写</li>
<li><strong>缓存优化</strong>：有专用缓存，广播访问效率高</li>
<li><strong>容量有限</strong>：64 KB</li>
</ul>
<h3 id="gua-yong-chang-jing" tabindex="-1" id="适用场景">适用场景</h3>
<p>所有线程读相同数据（如卷积核、变换矩阵）：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">__constant__ float kernel[9];  // 声明</span><br><span class="line"></span><br><span class="line">// Host 端写入</span><br><span class="line">cudaMemcpyToSymbol(kernel, h_kernel, 9 * sizeof(float));</span><br><span class="line"></span><br><span class="line">// Kernel 内使用</span><br><span class="line">__global__ void conv(...) &#123;</span><br><span class="line">    float sum = 0;</span><br><span class="line">    for (int i = 0; i &lt; 9; i++) &#123;</span><br><span class="line">        sum += data[i] * kernel[i];  // 所有线程读相同 kernel[i]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果每个线程读不同地址，常量内存反而更慢（串行化）。</p>
<h2 id="ji-cun-qi-you-hua" tabindex="-1" id="寄存器优化">寄存器优化</h2>
<h3 id="ji-cun-qi-de-zhong-yao-xing" tabindex="-1" id="寄存器的重要性">寄存器的重要性</h3>
<p>寄存器是最快的存储，单周期延迟。但数量有限（每 SM 约 64K 个），过度使用会导致：</p>
<ol>
<li><strong>寄存器溢出（Spilling）</strong>：溢出到 Local Memory（实际是全局内存），极慢</li>
<li><strong>占用率下降</strong>：每线程用更多寄存器，SM 能容纳的线程数减少</li>
</ol>
<h3 id="cha-kan-ji-cun-qi-shi-yong" tabindex="-1" id="查看寄存器使用">查看寄存器使用</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvcc --ptxas-options=-v kernel.cu</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ptxas info: Used 32 registers, ...</span><br></pre></td></tr></table></figure>
<h3 id="kong-zhi-ce-lue" tabindex="-1" id="控制策略">控制策略</h3>
<p><strong>编译器提示</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">__global__ void __launch_bounds__(256, 4) kernel(...) &#123;</span><br><span class="line">    // 告诉编译器：每 Block 256 线程，每 SM 至少 4 个 Block</span><br><span class="line">    // 编译器据此优化寄存器分配</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>编译选项</strong>：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvcc -maxrregcount=32 kernel.cu  <span class="comment"># 限制每线程最多 32 个寄存器</span></span><br></pre></td></tr></table></figure>
<p><strong>权衡</strong>：限制过严可能导致溢出，限制过松可能降低占用率。需要实测。</p>
<h2 id="shu-ju-ju-bu-xing-you-hua-qing-dan" tabindex="-1" id="数据局部性优化清单">数据局部性优化清单</h2>
<h3 id="kong-jian-ju-bu-xing" tabindex="-1" id="空间局部性">空间局部性</h3>
<p><strong>定义</strong>：访问的数据在内存中相邻</p>
<p><strong>优化手段</strong>：</p>
<ul>
<li>连续访问，利用合并</li>
<li>数据布局优化（AoS → SoA）</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">// Array of Structures（差）</span><br><span class="line">struct Particle &#123; float x, y, z; &#125;;</span><br><span class="line">Particle particles[N];</span><br><span class="line">particles[i].x;  // 跨步 12 字节</span><br><span class="line"></span><br><span class="line">// Structure of Arrays（好）</span><br><span class="line">struct Particles &#123; float x[N], y[N], z[N]; &#125;;</span><br><span class="line">Particles p;</span><br><span class="line">p.x[i];  // 连续访问</span><br></pre></td></tr></table></figure>
<h3 id="shi-jian-ju-bu-xing" tabindex="-1" id="时间局部性">时间局部性</h3>
<p><strong>定义</strong>：同一数据短期内被多次访问</p>
<p><strong>优化手段</strong>：</p>
<ul>
<li>Tiling 到共享内存/寄存器</li>
<li>循环分块</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">// 无时间局部性</span><br><span class="line">for (int k = 0; k &lt; N; k++) &#123;</span><br><span class="line">    C[i][j] += A[i][k] * B[k][j];  // A、B 每次从全局内存读</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 有时间局部性（Tiled）</span><br><span class="line">for (int tile = 0; tile &lt; N/TILE; tile++) &#123;</span><br><span class="line">    // 加载 tile 到共享内存</span><br><span class="line">    for (int k = 0; k &lt; TILE; k++) &#123;</span><br><span class="line">        C[i][j] += As[ty][k] * Bs[k][tx];  // 从共享内存读，复用</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="shi-zhan-you-hua-hou-de-ju-zhen-cheng-fa-xing-neng" tabindex="-1" id="实战：优化后的矩阵乘法性能">实战：优化后的矩阵乘法性能</h2>
<p>以 1024×1024 矩阵为例：</p>
<table>
<thead>
<tr>
<th>版本</th>
<th>全局内存访问</th>
<th>算术强度</th>
<th>相对性能</th>
</tr>
</thead>
<tbody>
<tr>
<td>朴素</td>
<td>2×10⁹ 次</td>
<td>0.25</td>
<td>1×</td>
</tr>
<tr>
<td>Tiled (16×16)</td>
<td>1.25×10⁸ 次</td>
<td>4</td>
<td>~8×</td>
</tr>
<tr>
<td>Tiled (32×32)</td>
<td>6.25×10⁷ 次</td>
<td>8</td>
<td>~12×</td>
</tr>
<tr>
<td>+ 寄存器优化</td>
<td>更少</td>
<td>16+</td>
<td>~20×</td>
</tr>
</tbody>
</table>
<p>实际提升取决于具体 GPU 和问题规模，但 10× 以上是常见的。</p>
<h2 id="xiao-jie" tabindex="-1" id="小结">小结</h2>
<p>第五章是性能优化的核心：</p>
<p><strong>内存层次认知</strong>：寄存器→共享内存→L2→全局内存，速度差 100 倍以上。写高性能代码就是让热数据留在快存储。</p>
<p><strong>共享内存本质</strong>：程序员可控的 Block 级缓存。声明简单，但需要正确同步。两次 __syncthreads() 别忘。</p>
<p><strong>Tiling 核心</strong>：分块加载，块内复用。矩阵乘法从 0.25 提升到 8+ FLOP/Byte，这是实打实的 10× 加速。</p>
<p><strong>访问模式</strong>：</p>
<ul>
<li>全局内存要合并访问</li>
<li>共享内存要避免 Bank 冲突</li>
<li>必要时用 Padding</li>
</ul>
<p><strong>局部性原则</strong>：空间局部性（连续访问），时间局部性（重复使用）。Tiling 同时利用了两者。</p>
<p>掌握了内存优化，GPU 的计算能力才能真正发挥。下一章会学习更多计算模式——卷积、规约、前缀和，这些都需要精心设计的内存访问策略。</p>
<hr>
<p><strong>参考资料：</strong></p>
<ul>
<li>Hwu, W., Kirk, D., &amp; El Hajj, I. (2022). <em>Programming Massively Parallel Processors: A Hands-on Approach</em> (4th Edition). Morgan Kaufmann.</li>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#memory-hierarchy">CUDA C++ Programming Guide - Memory Model</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/">CUDA Best Practices Guide</a></li>
</ul>
<hr>
<blockquote>
<p><strong>本文 GitHub 仓库</strong>: <a target="_blank" rel="noopener" href="https://github.com/psmarter/PMPP-Learning">https://github.com/psmarter/PMPP-Learning</a></p>
</blockquote>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://smarter.xin">Smarter</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://smarter.xin/posts/3bb3179b/">https://smarter.xin/posts/3bb3179b/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://smarter.xin" target="_blank">Smarter's blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/CUDA/">CUDA</a><a class="post-meta__tags" href="/tags/gpu-programming/">GPU编程</a><a class="post-meta__tags" href="/tags/parallel-computing/">并行计算</a><a class="post-meta__tags" href="/tags/PMPP/">PMPP</a><a class="post-meta__tags" href="/tags/Tiling/">Tiling</a><a class="post-meta__tags" href="/tags/shared-memory/">共享内存</a></div><div class="post-share"><div class="social-share" data-image="/img/PMPP.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related  no-desc" href="/posts/220818c3/" title="PMPP-第六章：性能方面的考虑"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/PMPP.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">PMPP-第六章：性能方面的考虑</div></div></div></a><a class="pagination-related  no-desc" href="/posts/bd5d1d6/" title="PMPP-第四章：计算架构和调度"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/PMPP.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">PMPP-第四章：计算架构和调度</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related no-desc" href="/posts/1c778456/" title="PMPP-第七章：卷积"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/PMPP.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2026-01-16</div><div class="info-item-2">PMPP-第七章：卷积</div></div></div></a><a class="pagination-related no-desc" href="/posts/93c68d7a/" title="PMPP-第八章：模板"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/PMPP.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2026-01-17</div><div class="info-item-2">PMPP-第八章：模板</div></div></div></a><a class="pagination-related no-desc" href="/posts/10d278b0/" title="PMPP-第一章：引言"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/PMPP.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2026-01-11</div><div class="info-item-2">PMPP-第一章：引言</div></div></div></a></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Smarter</div><div class="author-info-description">再见少年拉满弓，不惧岁月不惧风</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">72</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">110</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">12</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/psmarter"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/psmarter/" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:smarter.shh1104@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">Welcome to Smarter's blog</div></div><div class="card-widget" id="card-poem"><div id="poem_sentence"></div><div id="poem_info"><div id="poem_dynasty"></div><div id="poem_author"></div></div></div><script src="https://cdn.jsdelivr.net/npm/js-heo@1.0.11/poem/jinrishici.js" charset="utf-8"></script><script type="text/javascript">jinrishici.load(function(result) {
    var sentence = document.querySelector("#poem_sentence")
    var author = document.querySelector("#poem_author")
    var dynasty = document.querySelector("#poem_dynasty")

    var sentenceText = result.data.content
    sentenceText = sentenceText.substr(0, sentenceText.length - 1);
    sentence.innerHTML = sentenceText
    dynasty.innerHTML = result.data.origin.dynasty
    author.innerHTML = result.data.origin.author + '《' + result.data.origin.title + '》'
});</script><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#qian-yan"><span class="toc-text">前言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#nei-cun-dai-kuan-xing-neng-de-tian-hua-ban"><span class="toc-text">内存带宽：性能的天花板</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#wen-ti-de-ben-zhi"><span class="toc-text">问题的本质</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#shu-ju-zhong-fu-fang-wen"><span class="toc-text">数据重复访问</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#gpu-nei-cun-ceng-ci"><span class="toc-text">GPU 内存层次</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#ceng-ci-jie-gou"><span class="toc-text">层次结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ge-ji-cun-chu-te-dian"><span class="toc-text">各级存储特点</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#gong-xiang-nei-cun-shared-memory"><span class="toc-text">共享内存（Shared Memory）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#ji-ben-gai-nian"><span class="toc-text">基本概念</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#sheng-ming-yu-fa"><span class="toc-text">声明语法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#tong-bu-syncthreads"><span class="toc-text">同步：__syncthreads()</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#tiling-fen-kuai-chu-li"><span class="toc-text">Tiling：分块处理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#he-xin-si-xiang"><span class="toc-text">核心思想</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#tiled-ju-zhen-cheng-fa"><span class="toc-text">Tiled 矩阵乘法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#dai-ma-shi-xian"><span class="toc-text">代码实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#guan-jian-dian-jie-xi"><span class="toc-text">关键点解析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#xing-neng-fen-xi"><span class="toc-text">性能分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#bian-jie-chu-li"><span class="toc-text">边界处理</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#nei-cun-fang-wen-mo-shi"><span class="toc-text">内存访问模式</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#he-bing-fang-wen-coalesced-access"><span class="toc-text">合并访问（Coalesced Access）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#gong-xiang-nei-cun-bank-chong-tu"><span class="toc-text">共享内存 Bank 冲突</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ju-zhen-zhuan-zhi-de-bank-chong-tu"><span class="toc-text">矩阵转置的 Bank 冲突</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#chang-liang-nei-cun-constant-memory"><span class="toc-text">常量内存（Constant Memory）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#te-dian"><span class="toc-text">特点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#gua-yong-chang-jing"><span class="toc-text">适用场景</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ji-cun-qi-you-hua"><span class="toc-text">寄存器优化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#ji-cun-qi-de-zhong-yao-xing"><span class="toc-text">寄存器的重要性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cha-kan-ji-cun-qi-shi-yong"><span class="toc-text">查看寄存器使用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#kong-zhi-ce-lue"><span class="toc-text">控制策略</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#shu-ju-ju-bu-xing-you-hua-qing-dan"><span class="toc-text">数据局部性优化清单</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#kong-jian-ju-bu-xing"><span class="toc-text">空间局部性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#shi-jian-ju-bu-xing"><span class="toc-text">时间局部性</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#shi-zhan-you-hua-hou-de-ju-zhen-cheng-fa-xing-neng"><span class="toc-text">实战：优化后的矩阵乘法性能</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#xiao-jie"><span class="toc-text">小结</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/posts/d9ee9484/" title="PMPP-第十三章：排序"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/PMPP.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="PMPP-第十三章：排序"/></a><div class="content"><a class="title" href="/posts/d9ee9484/" title="PMPP-第十三章：排序">PMPP-第十三章：排序</a><time datetime="2026-01-18T14:04:20.000Z" title="发表于 2026-01-18 22:04:20">2026-01-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/31928809/" title="PMPP-第十二章：归并"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/PMPP.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="PMPP-第十二章：归并"/></a><div class="content"><a class="title" href="/posts/31928809/" title="PMPP-第十二章：归并">PMPP-第十二章：归并</a><time datetime="2026-01-18T13:42:06.000Z" title="发表于 2026-01-18 21:42:06">2026-01-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/a6fc4cf6/" title="PMPP-第十一章：前缀和"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/PMPP.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="PMPP-第十一章：前缀和"/></a><div class="content"><a class="title" href="/posts/a6fc4cf6/" title="PMPP-第十一章：前缀和">PMPP-第十一章：前缀和</a><time datetime="2026-01-18T07:51:17.000Z" title="发表于 2026-01-18 15:51:17">2026-01-18</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2025 - 2026 By Smarter</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.3.5</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><div class="js-pjax"><script>(async () => {
  const showKatex = () => {
    document.querySelectorAll('#article-container .katex').forEach(el => el.classList.add('katex-show'))
  }

  if (!window.katex_js_css) {
    window.katex_js_css = true
    await btf.getCSS('https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css')
    if (true) {
      await btf.getScript('https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js')
    }
  }

  showKatex()
})()</script><script>(() => {
  const runMermaid = ele => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    ele.forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const mermaidThemeConfig = `%%{init:{ 'theme':'${theme}'}}%%\n`
      const mermaidID = `mermaid-${index}`
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)
      const renderMermaid = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      // mermaid v9 and v10 compatibility
      typeof renderFn === 'string' ? renderMermaid(renderFn) : renderFn.then(({ svg }) => renderMermaid(svg))
    })
  }

  const codeToMermaid = () => {
    const codeMermaidEle = document.querySelectorAll('pre > code.mermaid')
    if (codeMermaidEle.length === 0) return

    codeMermaidEle.forEach(ele => {
      const preEle = document.createElement('pre')
      preEle.className = 'mermaid-src'
      preEle.hidden = true
      preEle.textContent = ele.textContent
      const newEle = document.createElement('div')
      newEle.className = 'mermaid-wrap'
      newEle.appendChild(preEle)
      ele.parentNode.replaceWith(newEle)
    })
  }

  const loadMermaid = () => {
    if (true) codeToMermaid()
    const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
    if ($mermaid.length === 0) return

    const runMermaidFn = () => runMermaid($mermaid)
    btf.addGlobalFn('themeChange', runMermaidFn, 'mermaid')
    window.loadMermaid ? runMermaidFn() : btf.getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaidFn)
  }

  btf.addGlobalFn('encrypt', loadMermaid, 'mermaid')
  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = null

  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://twikoo.smarter.xin',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(res => {
      countELement.textContent = res[0].count
    }).catch(err => {
      console.error(err)
    })
  }

  const init = (el = document, path = location.pathname) => {
    twikoo.init({
      el: el.querySelector('#twikoo-wrap'),
      envId: 'https://twikoo.smarter.xin',
      region: '',
      onCommentLoaded: () => {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      },
      ...option,
      path: isShuoshuo ? path : (option && option.path) || path
    })

    

    isShuoshuo && (window.shuoshuoComment.destroyTwikoo = () => {
      if (el.children.length) {
        el.innerHTML = ''
        el.classList.add('no-comment')
      }
    })
  }

  const loadTwikoo = (el, path) => {
    if (typeof twikoo === 'object') setTimeout(() => init(el, path), 0)
    else btf.getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(() => init(el, path))
  }

  if (isShuoshuo) {
    'Twikoo' === 'Twikoo'
      ? window.shuoshuoComment = { loadComment: loadTwikoo }
      : window.loadOtherComment = loadTwikoo
    return
  }

  if ('Twikoo' === 'Twikoo' || !true) {
    if (true) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo()
  } else {
    window.loadOtherComment = loadTwikoo
  }
})()</script></div><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-fluttering-ribbon.min.js"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-heart.min.js" async="async" mobile="true"></script><!--script(async data-pjax src= theme.asset.busuanzi || '//npm.elemecdn.com/penndu@1.0.0/bsz.js')--><script async data-pjax src="https://events.vercount.one/js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div><!-- hexo injector body_end start --><script data-pjax>
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="posts/b21cbc80/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/AI-Infra.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-12-31</span><a class="blog-slider__title" href="posts/b21cbc80/" alt="">AI Infra学习之旅-第一个vLLM程序</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="posts/b21cbc80/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="posts/db1cf321/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/AI-Infra.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2026-01-04</span><a class="blog-slider__title" href="posts/db1cf321/" alt="">AI Infra学习之旅-Transformer详解</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="posts/db1cf321/" alt="">详情   </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'undefined'.split(',');
  var cpage = location.pathname;
  var epage = '/';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer src="/js/swiper.min.js"></script><script defer data-pjax src="/js/swiper_init.js"></script><!-- hexo injector body_end end --></body></html>