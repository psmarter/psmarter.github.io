<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Smarter&#39;s blog</title>
  
  <subtitle>要学习、要快乐</subtitle>
  <link href="https://smarter.xin/atom.xml" rel="self"/>
  
  <link href="https://smarter.xin/"/>
  <updated>2026-01-24T11:47:21.461Z</updated>
  <id>https://smarter.xin/</id>
  
  <author>
    <name>Smarter</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>PMPP-大规模并行处理器程序设计：导读</title>
    <link href="https://smarter.xin/posts/30730973/"/>
    <id>https://smarter.xin/posts/30730973/</id>
    <published>2026-01-24T09:11:42.000Z</published>
    <updated>2026-01-24T11:47:21.461Z</updated>
    
    <content type="html"><![CDATA[<h2 id="qian-yan" tabindex="-1" id="前言">前言</h2><p>《Programming Massively Parallel Processors: A Hands-on Approach》（简称 PMPP）是 GPU 并行编程领域的经典教材，由 NVIDIA 首席科学家 David Kirk 和 Wen-mei Hwu 教授编写。第四版于 2022 年出版，涵盖了截至 Ampere 架构的最新技术。</p><p>这本书不只是 CUDA API 手册，更是一部**并行计算思维（Parallel Computational Thinking）**的养成指南。从最基础的线程模型到高级的分布式计算，从简单的向量加法到复杂的深度学习优化，循序渐进地构建完整的并行编程知识体系。</p><p>本系列博客完整覆盖了全书 22 章内容，每章一篇。这篇导读将帮助你：</p><ul><li>快速了解全书结构和各章核心内容</li><li>找到每章博客的链接</li><li>根据自身背景选择合适的学习路线</li></ul><blockquote><p><strong>📦 配套资源</strong>：本系列文章配有完整的 <a href="https://github.com/psmarter/PMPP-Learning">GitHub 仓库</a>，包含每章的练习题解答、CUDA 代码实现和详细注释。所有代码都经过测试，可以直接运行。</p></blockquote><h2 id="quan-shu-jie-gou" tabindex="-1" id="全书结构">全书结构</h2><p>PMPP 第四版共 22 章，可以分为四大部分：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">┌─────────────────────────────────────────────────────────────┐</span><br><span class="line">│  第一部分：CUDA 基础（1-6章）                                 │</span><br><span class="line">│  建立 GPU 编程的基础概念和核心技能                             │</span><br><span class="line">├─────────────────────────────────────────────────────────────┤</span><br><span class="line">│  第二部分：并行模式（7-15章）                                  │</span><br><span class="line">│  学习 9 种核心并行算法模式                                     │</span><br><span class="line">├─────────────────────────────────────────────────────────────┤</span><br><span class="line">│  第三部分：实际应用（16-18章）                                 │</span><br><span class="line">│  在真实场景中应用并行技术                                      │</span><br><span class="line">├─────────────────────────────────────────────────────────────┤</span><br><span class="line">│  第四部分：高级主题（19-22章）                                 │</span><br><span class="line">│  计算思维、分布式计算、高级特性                                 │</span><br><span class="line">└─────────────────────────────────────────────────────────────┘</span><br></pre></td></tr></table></figure><hr><h2 id="di-yi-bu-fen-cuda-ji-chu-1-6-zhang" tabindex="-1" id="第一部分：CUDA-基础（1-6章）">第一部分：CUDA 基础（1-6章）</h2><p>这是入门必读部分，建立 GPU 编程的完整基础。</p><h3 id="ge-zhang-gai-yao" tabindex="-1" id="📖-各章概要">📖 各章概要</h3><table><thead><tr><th>章节</th><th>标题</th><th>核心内容</th><th>博客链接</th></tr></thead><tbody><tr><td>1</td><td>引言</td><td>CPU vs GPU 设计哲学、CUDA 生态、异构计算模型</td><td><a href="https://smarter.xin/posts/10d278b0/">阅读</a></td></tr><tr><td>2</td><td>异构数据并行计算</td><td>Thread/Block/Grid 概念、向量加法、错误处理</td><td><a href="https://smarter.xin/posts/3ee22ce5/">阅读</a></td></tr><tr><td>3</td><td>多维网格和数据</td><td>2D/3D 索引计算、图像处理、边界检查</td><td><a href="https://smarter.xin/posts/6b7045b6/">阅读</a></td></tr><tr><td>4</td><td>计算架构和调度</td><td>SM 结构、Warp 调度、资源限制、占用率</td><td><a href="https://smarter.xin/posts/bd5d1d6/">阅读</a></td></tr><tr><td>5</td><td>内存架构和数据局部性</td><td>内存层次、共享内存、<strong>Tiling 技术</strong></td><td><a href="https://smarter.xin/posts/3bb3179b/">阅读</a></td></tr><tr><td>6</td><td>性能方面的考虑</td><td>合并访问、Bank 冲突、分支发散、资源分配</td><td><a href="https://smarter.xin/posts/220818c3/">阅读</a></td></tr></tbody></table><h3 id="guan-jian-zhi-shi-dian" tabindex="-1" id="🔑-关键知识点">🔑 关键知识点</h3><p><strong>硬件架构</strong>：</p><ul><li>GPU 由多个流式多处理器（SM，Streaming Multiprocessor）组成</li><li>每个 SM 有自己的寄存器、共享内存、L1 缓存</li><li>线程以32个一组（线程束，Warp）在 SM 上执行</li></ul><p><strong>编程模型</strong>：</p><ul><li>核函数（Kernel）是在 GPU 上执行的并行函数</li><li>线程组织为块（Block），块组织为网格（Grid）</li><li>线程通过 <code>threadIdx</code>、<code>blockIdx</code>、<code>blockDim</code> 确定自己的位置</li></ul><p><strong>内存优化</strong>（最重要）：</p><ul><li>寄存器 → 共享内存 → L2 缓存 → 全局内存，速度差异可达100倍</li><li><strong>分块（Tiling）</strong>：将数据分块加载到共享内存，块内复用</li><li><strong>合并访问（Coalesced Access）</strong>：让线程束内的线程访问连续地址</li></ul><h3 id="xue-xi-jian-yi" tabindex="-1" id="💡-学习建议">💡 学习建议</h3><ol><li>第一遍快速浏览 1-3 章，理解基本概念</li><li>重点学习 4-6 章，这是性能优化的基础</li><li><strong>第 5 章的 Tiled 矩阵乘法必须亲手实现</strong></li></ol><hr><h2 id="di-er-bu-fen-bing-xing-mo-shi-7-15-zhang" tabindex="-1" id="第二部分：并行模式（7-15章）">第二部分：并行模式（7-15章）</h2><p>这是本书的核心部分，介绍 9 种可复用的并行算法模式。</p><h3 id="ge-zhang-gai-yao-1" tabindex="-1" id="📖-各章概要-2">📖 各章概要</h3><table><thead><tr><th>章节</th><th>标题</th><th>核心模式</th><th>博客链接</th></tr></thead><tbody><tr><td>7</td><td>卷积</td><td>Tiling + Halo 处理、常量内存</td><td><a href="https://smarter.xin/posts/1c778456/">阅读</a></td></tr><tr><td>8</td><td>模板</td><td>寄存器 Tiling、分块时间迭代</td><td><a href="https://smarter.xin/posts/93c68d7a/">阅读</a></td></tr><tr><td>9</td><td>并行直方图</td><td>原子操作、私有化、聚合</td><td><a href="https://smarter.xin/posts/d29973f1/">阅读</a></td></tr><tr><td>10</td><td>归约</td><td>树形归约、Warp Shuffle、CUB 库</td><td><a href="https://smarter.xin/posts/43b40d12/">阅读</a></td></tr><tr><td>11</td><td>前缀和</td><td>Kogge-Stone、Brent-Kung、分层 Scan</td><td><a href="https://smarter.xin/posts/a6fc4cf6/">阅读</a></td></tr><tr><td>12</td><td>归并</td><td>Co-Rank 技术、并行归并路径</td><td><a href="https://smarter.xin/posts/31928809/">阅读</a></td></tr><tr><td>13</td><td>排序</td><td>基数排序、归并排序、Thrust 库</td><td><a href="https://smarter.xin/posts/d9ee9484/">阅读</a></td></tr><tr><td>14</td><td>稀疏矩阵</td><td>CSR/ELL/COO/HYB 格式、SpMV</td><td><a href="https://smarter.xin/posts/7af84cf7/">阅读</a></td></tr><tr><td>15</td><td>图遍历</td><td>并行 BFS、边界推进、层级同步</td><td><a href="https://smarter.xin/posts/70b05668/">阅读</a></td></tr></tbody></table><h3 id="guan-jian-zhi-shi-dian-1" tabindex="-1" id="🔑-关键知识点-2">🔑 关键知识点</h3><p><strong>数据并行模式</strong>：</p><table><thead><tr><th>模式</th><th>特点</th><th>典型应用</th></tr></thead><tbody><tr><td>Map</td><td>一对一变换</td><td>向量运算、图像滤波</td></tr><tr><td>Reduce</td><td>多对一归约</td><td>求和、最大值</td></tr><tr><td>Scan</td><td>前缀操作</td><td>压缩、流分配</td></tr><tr><td>Gather/Scatter</td><td>不规则访问</td><td>稀疏矩阵、图计算</td></tr></tbody></table><p><strong>输出冲突处理</strong>（第 9 章）：</p><ul><li>原子操作：正确但慢</li><li>私有化：每线程/每 Block 私有副本</li><li>聚合：相同地址只做一次原子操作</li></ul><p><strong>树形并行</strong>（第 10-11 章）：</p><ul><li>归约：多个值 → 一个值</li><li>扫描：多个值 → 多个前缀和</li><li>都是 O(log N) 步，但 Scan 更复杂</li></ul><h3 id="xue-xi-jian-yi-1" tabindex="-1" id="💡-学习建议-2">💡 学习建议</h3><ol><li>第 7 章卷积是第 5 章 Tiling 的进阶应用</li><li><strong>第 10-11 章（归约和前缀和）是最重要的两章</strong></li><li>稀疏矩阵和图遍历展示了如何处理不规则数据</li></ol><hr><h2 id="di-san-bu-fen-shi-ji-ying-yong-16-18-zhang" tabindex="-1" id="第三部分：实际应用（16-18章）">第三部分：实际应用（16-18章）</h2><p>将前面学到的技术应用于真实的科学计算和工程问题。</p><h3 id="ge-zhang-gai-yao-2" tabindex="-1" id="📖-各章概要-3">📖 各章概要</h3><table><thead><tr><th>章节</th><th>标题</th><th>应用领域</th><th>博客链接</th></tr></thead><tbody><tr><td>16</td><td>深度学习</td><td>卷积神经网络、Im2col、Tensor Core</td><td><a href="https://smarter.xin/posts/feaca34d/">阅读</a></td></tr><tr><td>17</td><td>迭代式 MRI 重建</td><td>NUFFT、共轭梯度、医学成像</td><td><a href="https://smarter.xin/posts/fab0715b/">阅读</a></td></tr><tr><td>18</td><td>静电势能图</td><td>N-body 问题、空间分区、cutoff 优化</td><td><a href="https://smarter.xin/posts/d7c6e6a8/">阅读</a></td></tr></tbody></table><h3 id="guan-jian-zhi-shi-dian-2" tabindex="-1" id="🔑-关键知识点-3">🔑 关键知识点</h3><p><strong>深度学习（第 16 章）</strong>：</p><ul><li>卷积是 95%+ 的计算量</li><li>Im2col 把卷积转为 GEMM</li><li>Winograd 减少乘法次数</li><li>cuDNN 自动选择最优算法</li></ul><p><strong>科学计算</strong>：</p><ul><li>迭代算法需要多次 Kernel 启动</li><li>非均匀网格需要特殊处理</li><li>空间分区降低 O(N²) 到 O(N)</li></ul><h3 id="xue-xi-jian-yi-2" tabindex="-1" id="💡-学习建议-3">💡 学习建议</h3><ol><li>如果做深度学习，第 16 章必读</li><li>第 17-18 章展示科学计算的完整流程</li><li>理解如何组合多种技术解决复杂问题</li></ol><hr><h2 id="di-si-bu-fen-gao-ji-zhu-ti-19-22-zhang" tabindex="-1" id="第四部分：高级主题（19-22章）">第四部分：高级主题（19-22章）</h2><p>计算思维方法论、分布式扩展和未来趋势。</p><h3 id="ge-zhang-gai-yao-3" tabindex="-1" id="📖-各章概要-4">📖 各章概要</h3><table><thead><tr><th>章节</th><th>标题</th><th>核心内容</th><th>博客链接</th></tr></thead><tbody><tr><td>19</td><td>并行编程与计算思维</td><td>问题分解、算法选择、性能推理</td><td><a href="https://smarter.xin/posts/46b3d994/">阅读</a></td></tr><tr><td>20</td><td>异构计算集群编程</td><td>MPI+CUDA、多 GPU、Halo 交换</td><td><a href="https://smarter.xin/posts/9506dbb9/">阅读</a></td></tr><tr><td>21</td><td>CUDA 动态并行性</td><td>设备端启动、递归算法、自适应网格</td><td><a href="https://smarter.xin/posts/e519c4bc/">阅读</a></td></tr><tr><td>22</td><td>高级实践与未来演变</td><td>性能方法论、代码可移植性、发展趋势</td><td><a href="https://smarter.xin/posts/a3a140de/">阅读</a></td></tr></tbody></table><h3 id="guan-jian-zhi-shi-dian-3" tabindex="-1" id="🔑-关键知识点-4">🔑 关键知识点</h3><p><strong>计算思维（第 19 章）</strong>：</p><ul><li>识别并行性：数据并行 vs 任务并行</li><li>算法选择：计算复杂度 vs 并行度</li><li>性能推理：Roofline 模型</li></ul><p><strong>分布式扩展（第 20 章）</strong>：</p><ul><li>多 GPU：CUDA-aware MPI、GPUDirect</li><li>通信隐藏：重叠计算和传输</li><li>弱扩展 vs 强扩展</li></ul><p><strong>动态并行（第 21 章）</strong>：</p><ul><li>设备端可以启动子 Kernel</li><li>适合递归和自适应算法</li><li>有同步和开销限制</li></ul><h3 id="xue-xi-jian-yi-3" tabindex="-1" id="💡-学习建议-4">💡 学习建议</h3><ol><li>第 19 章提炼了全书的方法论精华</li><li>如果需要多 GPU/多节点，重点学第 20 章</li><li>第 22 章可作为持续学习的指南</li></ol><hr><h2 id="he-xin-zhi-shi-tu-pu" tabindex="-1" id="核心知识图谱">核心知识图谱</h2><h3 id="nei-cun-you-hua-ji-zhu" tabindex="-1" id="内存优化技术">内存优化技术</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">                    ┌──────────────────────────────────────┐</span><br><span class="line">                    │         GPU 内存层次结构              │</span><br><span class="line">                    ├──────────────────────────────────────┤</span><br><span class="line">                    │  寄存器 (~TB/s) ◀── 最快，数量有限    │</span><br><span class="line">                    │     ↓                                │</span><br><span class="line">                    │  共享内存 (~10 TB/s) ◀── 可编程缓存   │</span><br><span class="line">                    │     ↓                                │</span><br><span class="line">                    │  L2 缓存 (~1 TB/s) ◀── 自动管理       │</span><br><span class="line">                    │     ↓                                │</span><br><span class="line">                    │  全局内存 (~500 GB/s) ◀── 容量大但慢  │</span><br><span class="line">                    └──────────────────────────────────────┘</span><br><span class="line"></span><br><span class="line">优化策略：</span><br><span class="line">├── Tiling（第5章）：数据分块，在共享内存中复用</span><br><span class="line">├── 合并访问（第6章）：连续地址，减少内存事务</span><br><span class="line">├── 寄存器Tiling（第8章）：数据保留在寄存器</span><br><span class="line">└── 私有化（第9章）：避免原子操作的竞争</span><br></pre></td></tr></table></figure><h3 id="bing-xing-suan-fa-xuan-ze" tabindex="-1" id="并行算法选择">并行算法选择</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">问题类型                    推荐算法</span><br><span class="line">───────────────────────────────────────────────</span><br><span class="line">逐元素运算                  Map（直接并行）</span><br><span class="line">全局聚合（求和/最大值）      树形归约（第10章）</span><br><span class="line">前缀依赖计算                Scan（第11章）</span><br><span class="line">有序数据合并                Co-rank归并（第12章）</span><br><span class="line">整数键排序                  基数排序（第13章）</span><br><span class="line">稀疏数据处理                CSR/ELL格式（第14章）</span><br><span class="line">图遍历                      边界推进BFS（第15章）</span><br></pre></td></tr></table></figure><h3 id="xing-neng-diao-you-fang-fa-lun" tabindex="-1" id="性能调优方法论">性能调优方法论</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">1. Profile 先行</span><br><span class="line">   └── 使用 Nsight Compute 定位瓶颈</span><br><span class="line"></span><br><span class="line">2. 判断瓶颈类型</span><br><span class="line">   ├── 内存受限：优化访问模式、增加数据复用</span><br><span class="line">   └── 计算受限：减少指令数、使用快速数学函数</span><br><span class="line"></span><br><span class="line">3. 层次化优化（从上到下收益递减）</span><br><span class="line">   ├── 算法选择</span><br><span class="line">   ├── 数据布局</span><br><span class="line">   ├── 并行策略</span><br><span class="line">   ├── 内存层次利用</span><br><span class="line">   └── 指令级优化</span><br><span class="line"></span><br><span class="line">4. 迭代验证</span><br><span class="line">   └── 保持正确性，逐步优化</span><br></pre></td></tr></table></figure><hr><h2 id="xue-xi-lu-xian-tui-jian" tabindex="-1" id="学习路线推荐">学习路线推荐</h2><h3 id="kuai-su-ru-men-lu-xian-2-zhou" tabindex="-1" id="🚀-快速入门路线（2周）">🚀 快速入门路线（2周）</h3><p>适合：有编程基础，想快速上手 CUDA</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Week 1: 1→2→3→5（基础概念 + Tiling）</span><br><span class="line">Week 2: 10→16（归约 + 深度学习应用）</span><br></pre></td></tr></table></figure><h3 id="xi-tong-xue-xi-lu-xian-2-yue" tabindex="-1" id="📚-系统学习路线（2月）">📚 系统学习路线（2月）</h3><p>适合：想深入掌握 GPU 编程</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Month 1（基础+模式）:</span><br><span class="line">  Week 1-2: 1-6章（打牢基础）</span><br><span class="line">  Week 3-4: 7-11章（核心模式）</span><br><span class="line"></span><br><span class="line">Month 2（进阶+应用）:</span><br><span class="line">  Week 1-2: 12-16章（高级模式+应用）</span><br><span class="line">  Week 3-4: 19-22章（思维+扩展）</span><br></pre></td></tr></table></figure><h3 id="zhuan-xiang-ti-sheng-lu-xian" tabindex="-1" id="🎯-专项提升路线">🎯 专项提升路线</h3><p><strong>深度学习方向</strong>：1→2→5→7→10→16</p><p><strong>科学计算方向</strong>：1→2→5→10→11→14→17→18</p><p><strong>HPC 方向</strong>：1→2→4→5→6→10→20</p><hr><h2 id="xue-xi-zi-yuan" tabindex="-1" id="学习资源">学习资源</h2><h3 id="pei-tao-dai-ma" tabindex="-1" id="配套代码">配套代码</h3><ul><li><strong>GitHub 仓库</strong>：<a href="https://github.com/psmarter/PMPP-Learning">https://github.com/psmarter/PMPP-Learning</a></li><li>包含所有章节练习题解答</li><li>可直接编译运行的 CUDA 代码</li><li>详细的中文注释</li></ul><h3 id="guan-fang-zi-yuan" tabindex="-1" id="官方资源">官方资源</h3><ul><li><a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/">CUDA C++ Programming Guide</a></li><li><a href="https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/">CUDA Best Practices Guide</a></li><li><a href="https://docs.nvidia.com/nsight-compute/">Nsight Compute Documentation</a></li></ul><h3 id="xiang-guan-ke-cheng" tabindex="-1" id="相关课程">相关课程</h3><ul><li>UIUC ECE 408（Coursera 可看）</li><li>书籍作者的配套课程</li></ul><hr><h2 id="xie-zai-zui-hou" tabindex="-1" id="写在最后">写在最后</h2><p>PMPP 不是一本可以一次读完的书。第一遍建立框架，第二遍深入细节，每次实战后再回来都会有新的理解。</p><p><strong>学习建议</strong>：</p><ol><li><strong>动手实践</strong>：每章的练习题都需要实际编码，仅阅读难以真正掌握</li><li><strong>使用性能分析工具</strong>：Nsight Compute 和 Nsight Systems 是理解性能的最佳途径</li><li><strong>理解底层原理</strong>：API 会更新，但硬件原理和优化思想具有长期价值</li><li><strong>项目驱动</strong>：在真实项目中应用这些技术才能融会贯通</li></ol><p>GPU 并行编程的重要性日益凸显——深度学习、科学计算、图形渲染、高性能计算都离不开它。掌握 PMPP 的内容，就掌握了进入这些领域的核心技能。</p><p>祝学习进步！</p><hr><p><strong>参考资料：</strong></p><ul><li>Hwu, W., Kirk, D., &amp; El Hajj, I. (2022). <em>Programming Massively Parallel Processors: A Hands-on Approach</em> (4th Edition). Morgan Kaufmann.</li><li><a href="https://docs.nvidia.com/cuda/">NVIDIA CUDA 官方文档</a></li><li><a href="https://developer.nvidia.com/blog/">NVIDIA Developer Blog</a></li></ul><hr><blockquote><p><strong>本文 GitHub 仓库</strong>: <a href="https://github.com/psmarter/PMPP-Learning">https://github.com/psmarter/PMPP-Learning</a></p><p><strong>系列总览</strong>：本文是 PMPP 全书 22 章博客系列的导读索引。</p></blockquote>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h2 id=&quot;qian-yan&quot; tabindex=&quot;-1&quot; id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;《Programming Massively Parallel Processors: A Hands-on Approach》（简称 PMPP）是 GPU</summary>
        
      
    
    
    
    <category term="知识分享" scheme="https://smarter.xin/categories/knowledge-sharing/"/>
    
    
    <category term="学习路线" scheme="https://smarter.xin/tags/learning-path/"/>
    
    <category term="CUDA" scheme="https://smarter.xin/tags/CUDA/"/>
    
    <category term="GPU编程" scheme="https://smarter.xin/tags/gpu-programming/"/>
    
    <category term="并行计算" scheme="https://smarter.xin/tags/parallel-computing/"/>
    
    <category term="PMPP" scheme="https://smarter.xin/tags/PMPP/"/>
    
    <category term="全书导读" scheme="https://smarter.xin/tags/book-guide/"/>
    
  </entry>
  
  <entry>
    <title>PMPP-第二十二章：高级实践与未来演变</title>
    <link href="https://smarter.xin/posts/a3a140de/"/>
    <id>https://smarter.xin/posts/a3a140de/</id>
    <published>2026-01-24T08:56:01.000Z</published>
    <updated>2026-01-24T11:47:21.462Z</updated>
    
    <content type="html"><![CDATA[<h2 id="qian-yan" tabindex="-1" id="前言">前言</h2><p>第二十一章介绍了动态并行性。作为全书的最后一章，第二十二章总结了<strong>高级实践（Advanced Practices）<strong>并展望了</strong>未来演变（Future Evolution）</strong>。本章不再引入新的编程技术，而是讨论如何在实际项目中应用前面学到的知识，以及 GPU 计算领域的发展趋势。掌握这些内容，将有助于在快速变化的技术环境中持续成长。</p><blockquote><p><strong>📦 配套资源</strong>：本系列文章配有完整的 <a href="https://github.com/psmarter/PMPP-Learning">GitHub 仓库</a>，包含每章的练习题解答、CUDA 代码实现和详细注释。所有代码都经过测试，可以直接运行。</p></blockquote><h2 id="xing-neng-you-hua-fang-fa-lun" tabindex="-1" id="性能优化方法论">性能优化方法论</h2><h3 id="xing-neng-fen-xi-qu-dong" tabindex="-1" id="性能分析驱动">性能分析驱动</h3><p><strong>不要猜测，要测量</strong>。</p><p>优化前必须先找到瓶颈：</p><ol><li>使用 Nsight Systems 分析整体流程</li><li>使用 Nsight Compute 分析单个 kernel</li><li>根据数据决定优化方向</li></ol><h3 id="roofline-mo-xing-hui-gu" tabindex="-1" id="Roofline-模型回顾">Roofline 模型回顾</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">性能上限 = min(峰值算力, 带宽 × 算术强度)</span><br></pre></td></tr></table></figure><p><strong>算术强度</strong> = FLOP / Byte</p><table><thead><tr><th>算术强度</th><th>瓶颈类型</th><th>优化方向</th></tr></thead><tbody><tr><td>&lt; 10</td><td>内存受限</td><td>提高数据复用、减少访存</td></tr><tr><td>&gt; 10</td><td>计算受限</td><td>优化计算效率、减少指令数</td></tr></tbody></table><h3 id="you-hua-ceng-ci" tabindex="-1" id="优化层次">优化层次</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">┌─────────────────────────────────────────┐</span><br><span class="line">│ 第五层：算法选择                         │</span><br><span class="line">│   选择更高效的算法（收益最大）            │</span><br><span class="line">├─────────────────────────────────────────┤</span><br><span class="line">│ 第四层：数据布局                         │</span><br><span class="line">│   SoA vs AoS、对齐、Padding             │</span><br><span class="line">├─────────────────────────────────────────┤</span><br><span class="line">│ 第三层：并行策略                         │</span><br><span class="line">│   任务分解、负载均衡、线程映射            │</span><br><span class="line">├─────────────────────────────────────────┤</span><br><span class="line">│ 第二层：内存层次                         │</span><br><span class="line">│   共享内存、寄存器、缓存利用              │</span><br><span class="line">├─────────────────────────────────────────┤</span><br><span class="line">│ 第一层：指令级                           │</span><br><span class="line">│   循环展开、向量化、快速数学函数          │</span><br><span class="line">└─────────────────────────────────────────┘</span><br></pre></td></tr></table></figure><p><strong>从上往下优化</strong>：高层优化的收益通常远大于低层。</p><h2 id="chang-jian-you-hua-ji-zhu-zong-jie" tabindex="-1" id="常见优化技术总结">常见优化技术总结</h2><h3 id="nei-cun-you-hua" tabindex="-1" id="内存优化">内存优化</h3><table><thead><tr><th>技术</th><th>适用场景</th><th>效果</th></tr></thead><tbody><tr><td>合并访问</td><td>全局内存访问</td><td>减少内存事务</td></tr><tr><td>共享内存</td><td>数据复用</td><td>减少全局访问</td></tr><tr><td>常量内存</td><td>只读广播数据</td><td>利用缓存</td></tr><tr><td>纹理内存</td><td>2D 局部性</td><td>硬件插值</td></tr><tr><td>寄存器 Tiling</td><td>矩阵运算</td><td>最大化复用</td></tr></tbody></table><h3 id="ji-suan-you-hua" tabindex="-1" id="计算优化">计算优化</h3><table><thead><tr><th>技术</th><th>适用场景</th><th>效果</th></tr></thead><tbody><tr><td>循环展开</td><td>固定迭代循环</td><td>减少指令开销</td></tr><tr><td>线程粗化</td><td>每线程工作太少</td><td>减少调度开销</td></tr><tr><td>快速数学</td><td>精度要求不高</td><td>减少时钟周期</td></tr><tr><td>Warp Shuffle</td><td>Warp 内通信</td><td>避免共享内存</td></tr></tbody></table><h3 id="bing-xing-du-you-hua" tabindex="-1" id="并行度优化">并行度优化</h3><table><thead><tr><th>技术</th><th>适用场景</th><th>效果</th></tr></thead><tbody><tr><td>增加线程数</td><td>隐藏延迟</td><td>提高占用率</td></tr><tr><td>动态并行</td><td>递归/自适应</td><td>减少 CPU 参与</td></tr><tr><td>CUDA 流</td><td>多任务重叠</td><td>隐藏传输延迟</td></tr></tbody></table><h2 id="dai-ma-ke-yi-zhi-xing" tabindex="-1" id="代码可移植性">代码可移植性</h2><h3 id="kua-gpu-jia-gou" tabindex="-1" id="跨-GPU-架构">跨 GPU 架构</h3><p>不同 GPU 架构有不同特性：</p><table><thead><tr><th>架构</th><th>特点</th></tr></thead><tbody><tr><td>Kepler (sm_35)</td><td>动态并行首次支持</td></tr><tr><td>Maxwell (sm_50)</td><td>改进的共享内存</td></tr><tr><td>Pascal (sm_60)</td><td>统一内存改进</td></tr><tr><td>Volta (sm_70)</td><td>Tensor Core、独立线程调度</td></tr><tr><td>Ampere (sm_80)</td><td>异步拷贝、更大 L2</td></tr><tr><td>Hopper (sm_90)</td><td>Transformer Engine</td></tr></tbody></table><h3 id="bian-xie-ke-yi-zhi-dai-ma" tabindex="-1" id="编写可移植代码">编写可移植代码</h3><p><strong>参数化关键常量</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#if __CUDA_ARCH__ &gt;= 800</span><br><span class="line">    #define SHARED_MEM_SIZE 164 * 1024  // Ampere: 164KB</span><br><span class="line">#elif __CUDA_ARCH__ &gt;= 700</span><br><span class="line">    #define SHARED_MEM_SIZE 96 * 1024   // Volta: 96KB</span><br><span class="line">#else</span><br><span class="line">    #define SHARED_MEM_SIZE 48 * 1024   // 默认: 48KB</span><br><span class="line">#endif</span><br></pre></td></tr></table></figure><p><strong>运行时查询能力</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cudaDeviceProp prop;</span><br><span class="line">cudaGetDeviceProperties(&amp;prop, 0);</span><br><span class="line"></span><br><span class="line">int blocks_per_sm = prop.maxBlocksPerMultiProcessor;</span><br><span class="line">int shared_mem = prop.sharedMemPerBlock;</span><br><span class="line">int max_threads = prop.maxThreadsPerBlock;</span><br></pre></td></tr></table></figure><h3 id="kua-ping-tai-ji-zhu" tabindex="-1" id="跨平台技术">跨平台技术</h3><table><thead><tr><th>技术</th><th>描述</th><th>优势</th></tr></thead><tbody><tr><td>CUDA</td><td>NVIDIA 专用</td><td>性能最佳</td></tr><tr><td>OpenCL</td><td>跨厂商标准</td><td>可移植性</td></tr><tr><td>SYCL</td><td>C++ 标准化</td><td>现代 C++ 风格</td></tr><tr><td>HIP</td><td>AMD 兼容 CUDA</td><td>易于迁移</td></tr><tr><td>Kokkos</td><td>抽象层</td><td>多后端支持</td></tr></tbody></table><h2 id="diao-shi-yu-yan-zheng" tabindex="-1" id="调试与验证">调试与验证</h2><h3 id="chang-jian-cuo-wu-lei-xing" tabindex="-1" id="常见错误类型">常见错误类型</h3><ol><li><strong>内存错误</strong>：越界访问、未初始化内存</li><li><strong>竞态条件</strong>：同步不当导致数据竞争</li><li><strong>数值误差</strong>：浮点精度、舍入误差</li><li><strong>死锁</strong>：同步原语使用不当</li></ol><h3 id="diao-shi-gong-ju" tabindex="-1" id="调试工具">调试工具</h3><table><thead><tr><th>工具</th><th>用途</th></tr></thead><tbody><tr><td>cuda-memcheck</td><td>内存错误检测</td></tr><tr><td>compute-sanitizer</td><td>新一代错误检测</td></tr><tr><td>Nsight Eclipse</td><td>IDE 集成调试</td></tr><tr><td>Nsight Visual Studio</td><td>Windows 调试</td></tr><tr><td>printf</td><td>简单调试（慎用）</td></tr></tbody></table><h3 id="yan-zheng-ce-lue" tabindex="-1" id="验证策略">验证策略</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">// 1. 保留 CPU 参考实现</span><br><span class="line">void cpu_reference(float *output, float *input, int n);</span><br><span class="line"></span><br><span class="line">// 2. 对比 GPU 结果</span><br><span class="line">bool verify_result(float *gpu, float *cpu, int n, float epsilon) &#123;</span><br><span class="line">    for (int i = 0; i &lt; n; i++) &#123;</span><br><span class="line">        if (fabsf(gpu[i] - cpu[i]) &gt; epsilon) &#123;</span><br><span class="line">            printf(&quot;Mismatch at %d: GPU=%.6f, CPU=%.6f\n&quot;, </span><br><span class="line">                   i, gpu[i], cpu[i]);</span><br><span class="line">            return false;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    return true;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 3. 渐进式测试</span><br><span class="line">// 小规模 → 中规模 → 大规模</span><br><span class="line">// 1 Block → 多 Block → 多 SM</span><br></pre></td></tr></table></figure><h2 id="sheng-chan-huan-jing-zui-jia-shi-jian" tabindex="-1" id="生产环境最佳实践">生产环境最佳实践</h2><h3 id="cuo-wu-chu-li" tabindex="-1" id="错误处理">错误处理</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">#define CUDA_CHECK(call) \</span><br><span class="line">    do &#123; \</span><br><span class="line">        cudaError_t err = call; \</span><br><span class="line">        if (err != cudaSuccess) &#123; \</span><br><span class="line">            fprintf(stderr, &quot;CUDA error at %s:%d: %s\n&quot;, \</span><br><span class="line">                    __FILE__, __LINE__, cudaGetErrorString(err)); \</span><br><span class="line">            exit(EXIT_FAILURE); \</span><br><span class="line">        &#125; \</span><br><span class="line">    &#125; while(0)</span><br><span class="line"></span><br><span class="line">// 使用</span><br><span class="line">CUDA_CHECK(cudaMalloc(&amp;d_ptr, size));</span><br><span class="line">CUDA_CHECK(cudaMemcpy(d_ptr, h_ptr, size, cudaMemcpyHostToDevice));</span><br></pre></td></tr></table></figure><h3 id="zi-yuan-guan-li" tabindex="-1" id="资源管理">资源管理</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">// RAII 风格管理 CUDA 资源</span><br><span class="line">class CudaBuffer &#123;</span><br><span class="line">    void *ptr;</span><br><span class="line">    size_t size;</span><br><span class="line">public:</span><br><span class="line">    CudaBuffer(size_t n) : size(n) &#123;</span><br><span class="line">        CUDA_CHECK(cudaMalloc(&amp;ptr, n));</span><br><span class="line">    &#125;</span><br><span class="line">    ~CudaBuffer() &#123;</span><br><span class="line">        cudaFree(ptr);</span><br><span class="line">    &#125;</span><br><span class="line">    void* get() &#123; return ptr; &#125;</span><br><span class="line">    // 禁止拷贝</span><br><span class="line">    CudaBuffer(const CudaBuffer&amp;) = delete;</span><br><span class="line">    CudaBuffer&amp; operator=(const CudaBuffer&amp;) = delete;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="xing-neng-jian-kong" tabindex="-1" id="性能监控">性能监控</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">// 计时</span><br><span class="line">cudaEvent_t start, stop;</span><br><span class="line">cudaEventCreate(&amp;start);</span><br><span class="line">cudaEventCreate(&amp;stop);</span><br><span class="line"></span><br><span class="line">cudaEventRecord(start);</span><br><span class="line">my_kernel&lt;&lt;&lt;grid, block&gt;&gt;&gt;(args);</span><br><span class="line">cudaEventRecord(stop);</span><br><span class="line"></span><br><span class="line">cudaEventSynchronize(stop);</span><br><span class="line">float milliseconds = 0;</span><br><span class="line">cudaEventElapsedTime(&amp;milliseconds, start, stop);</span><br><span class="line"></span><br><span class="line">printf(&quot;Kernel time: %.3f ms\n&quot;, milliseconds);</span><br><span class="line"></span><br><span class="line">cudaEventDestroy(start);</span><br><span class="line">cudaEventDestroy(stop);</span><br></pre></td></tr></table></figure><h2 id="gpu-ji-suan-sheng-tai-xi-tong" tabindex="-1" id="GPU-计算生态系统">GPU 计算生态系统</h2><h3 id="cuda-ku" tabindex="-1" id="CUDA-库">CUDA 库</h3><table><thead><tr><th>库</th><th>领域</th><th>功能</th></tr></thead><tbody><tr><td>cuBLAS</td><td>线性代数</td><td>矩阵运算</td></tr><tr><td>cuFFT</td><td>信号处理</td><td>傅里叶变换</td></tr><tr><td>cuDNN</td><td>深度学习</td><td>神经网络原语</td></tr><tr><td>cuSPARSE</td><td>稀疏矩阵</td><td>稀疏运算</td></tr><tr><td>cuRAND</td><td>随机数</td><td>伪随机生成</td></tr><tr><td>Thrust</td><td>通用</td><td>STL 风格容器</td></tr><tr><td>CUB</td><td>底层</td><td>原语库</td></tr></tbody></table><h3 id="shi-yong-ku-de-you-shi" tabindex="-1" id="使用库的优势">使用库的优势</h3><ol><li><strong>经过高度优化</strong>：专家团队持续调优</li><li><strong>版本间改进</strong>：自动受益于新架构优化</li><li><strong>减少开发时间</strong>：专注业务逻辑</li><li><strong>减少错误</strong>：经过广泛测试</li></ol><h3 id="he-shi-zi-ji-shi-xian" tabindex="-1" id="何时自己实现">何时自己实现</h3><ul><li>特殊需求库不满足</li><li>库的通用实现不够高效</li><li>学习目的</li></ul><h2 id="wei-lai-qu-shi" tabindex="-1" id="未来趋势">未来趋势</h2><h3 id="ying-jian-yan-jin" tabindex="-1" id="硬件演进">硬件演进</h3><p><strong>更多核心</strong>：</p><ul><li>SM 数量持续增加</li><li>更高的并行度</li><li>对负载均衡要求更高</li></ul><p><strong>专用加速器</strong>：</p><ul><li>Tensor Core（矩阵运算）</li><li>RT Core（光线追踪）</li><li>Transformer Engine（AI）</li></ul><p><strong>内存技术</strong>：</p><ul><li>HBM 带宽持续增长</li><li>更大的 L2 缓存</li><li>统一内存性能改进</li></ul><h3 id="bian-cheng-mo-xing-yan-jin" tabindex="-1" id="编程模型演进">编程模型演进</h3><p><strong>更高抽象</strong>：</p><ul><li>CUDA Graphs：静态任务图</li><li>CUDA Cooperative Groups：灵活同步</li><li>C++ 标准并行：std::execution</li></ul><p><strong>跨平台标准</strong>：</p><ul><li>SYCL 普及</li><li>oneAPI 生态</li><li>可移植性重要性增加</li></ul><h3 id="ying-yong-ling-yu-kuo-zhan" tabindex="-1" id="应用领域扩展">应用领域扩展</h3><p><strong>传统 HPC</strong>：</p><ul><li>气象模拟</li><li>分子动力学</li><li>流体力学</li></ul><p><strong>AI/ML</strong>：</p><ul><li>大语言模型训练</li><li>推理加速</li><li>自动驾驶</li></ul><p><strong>新兴领域</strong>：</p><ul><li>量子计算模拟</li><li>数字孪生</li><li>元宇宙渲染</li></ul><h2 id="chi-xu-xue-xi-zi-yuan" tabindex="-1" id="持续学习资源">持续学习资源</h2><h3 id="guan-fang-zi-yuan" tabindex="-1" id="官方资源">官方资源</h3><ul><li><strong>CUDA 文档</strong>：<a href="https://docs.nvidia.com/cuda/">https://docs.nvidia.com/cuda/</a></li><li><strong>NVIDIA Developer Blog</strong>：技术文章和最佳实践</li><li><strong>GTC 大会</strong>：最新技术发布</li><li><strong>CUDA Zone</strong>：示例代码和教程</li></ul><h3 id="xue-zhu-zi-yuan" tabindex="-1" id="学术资源">学术资源</h3><ul><li><strong>PMPP 教材</strong>：本书是经典参考</li><li><strong>UIUC ECE 408</strong>：配套课程（Coursera 可看）</li><li><strong>Stanford CS 149</strong>：并行计算基础</li><li><strong>论文</strong>：GTC、SC、ICS 会议</li></ul><h3 id="she-qu" tabindex="-1" id="社区">社区</h3><ul><li><strong>Stack Overflow</strong>：cuda 标签</li><li><strong>NVIDIA 开发者论坛</strong>：官方支持</li><li><strong>GitHub</strong>：开源 CUDA 项目</li><li><strong>Reddit r/CUDA</strong>：讨论社区</li></ul><h2 id="quan-shu-hui-gu" tabindex="-1" id="全书回顾">全书回顾</h2><h3 id="ji-chu-pian-1-6-zhang" tabindex="-1" id="基础篇（1-6章）">基础篇（1-6章）</h3><table><thead><tr><th>章节</th><th>主题</th><th>核心概念</th></tr></thead><tbody><tr><td>1</td><td>引言</td><td>异构计算、CUDA 生态</td></tr><tr><td>2</td><td>数据并行</td><td>Thread、Block、Grid</td></tr><tr><td>3</td><td>多维数据</td><td>线程索引、边界检查</td></tr><tr><td>4</td><td>计算架构</td><td>SM、Warp、调度</td></tr><tr><td>5</td><td>内存架构</td><td>层次结构、Tiling</td></tr><tr><td>6</td><td>性能考虑</td><td>合并访问、发散、资源</td></tr></tbody></table><h3 id="mo-shi-pian-7-15-zhang" tabindex="-1" id="模式篇（7-15章）">模式篇（7-15章）</h3><table><thead><tr><th>章节</th><th>主题</th><th>核心模式</th></tr></thead><tbody><tr><td>7</td><td>卷积</td><td>Tiling、Halo</td></tr><tr><td>8</td><td>模板</td><td>缓存、Register Tiling</td></tr><tr><td>9</td><td>直方图</td><td>原子操作、私有化</td></tr><tr><td>10</td><td>归约</td><td>树形归约、Warp 原语</td></tr><tr><td>11</td><td>前缀和</td><td>Scan、Work-Efficient</td></tr><tr><td>12</td><td>归并</td><td>Co-Rank、循环展开</td></tr><tr><td>13</td><td>排序</td><td>基数排序、并行归并</td></tr><tr><td>14</td><td>稀疏矩阵</td><td>CSR/ELL/COO 格式</td></tr><tr><td>15</td><td>图算法</td><td>BFS、边界推进</td></tr></tbody></table><h3 id="ying-yong-pian-16-18-zhang" tabindex="-1" id="应用篇（16-18章）">应用篇（16-18章）</h3><table><thead><tr><th>章节</th><th>主题</th><th>应用领域</th></tr></thead><tbody><tr><td>16</td><td>深度学习</td><td>卷积、池化、全连接</td></tr><tr><td>17</td><td>MRI 重建</td><td>NUFFT、共轭梯度</td></tr><tr><td>18</td><td>静电势能</td><td>N-body、空间分区</td></tr></tbody></table><h3 id="gao-ji-pian-19-22-zhang" tabindex="-1" id="高级篇（19-22章）">高级篇（19-22章）</h3><table><thead><tr><th>章节</th><th>主题</th><th>核心内容</th></tr></thead><tbody><tr><td>19</td><td>计算思维</td><td>方法论、设计原则</td></tr><tr><td>20</td><td>集群编程</td><td>MPI+CUDA、Halo交换</td></tr><tr><td>21</td><td>动态并行</td><td>设备端启动、递归</td></tr><tr><td>22</td><td>高级实践</td><td>最佳实践、未来趋势</td></tr></tbody></table><h2 id="xie-zai-zui-hou" tabindex="-1" id="写在最后">写在最后</h2><h3 id="bing-xing-bian-cheng-xin-fa-shi-tiao" tabindex="-1" id="并行编程心法十条">并行编程心法十条</h3><ol><li><strong>理解硬件</strong>：了解 GPU 架构，扬长避短</li><li><strong>数据为王</strong>：性能通常受限于数据移动</li><li><strong>最大化并行</strong>：暴露足够的并行性隐藏延迟</li><li><strong>最小化同步</strong>：同步是性能杀手</li><li><strong>合并访问</strong>：让内存访问连续</li><li><strong>复用数据</strong>：共享内存是你最好的朋友</li><li><strong>避免发散</strong>：让 Warp 内线程走相同路径</li><li><strong>权衡取舍</strong>：没有银弹，只有适合的解</li><li><strong>Profile 优先</strong>：数据驱动优化，不要猜测</li><li><strong>渐进迭代</strong>：先正确，后优化，持续改进</li></ol><h3 id="cong-xue-xi-dao-shi-jian" tabindex="-1" id="从学习到实践">从学习到实践</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">阶段一：理解基础</span><br><span class="line">  ↓ 多写代码、多做练习</span><br><span class="line">阶段二：掌握模式</span><br><span class="line">  ↓ 在实际项目中应用</span><br><span class="line">阶段三：形成直觉</span><br><span class="line">  ↓ 阅读论文、参与开源</span><br><span class="line">阶段四：持续精进</span><br></pre></td></tr></table></figure><h3 id="jie-yu" tabindex="-1" id="结语">结语</h3><p>这本书带你从 CUDA 入门走到了高级实践。但学习永无止境——GPU 技术快速演进，新架构、新特性不断涌现。</p><p><strong>核心能力</strong>胜过<strong>具体知识</strong>：</p><ul><li>理解并行计算原理 &gt; 记住 API 细节</li><li>掌握优化方法论 &gt; 背诵优化技巧</li><li>培养计算思维 &gt; 复制代码模板</li></ul><p>希望这本书和这个系列博客能帮助你建立扎实的并行计算基础。接下来，不断实践、持续学习，在 GPU 计算的世界里探索更多可能！</p><hr><p><strong>参考资料：</strong></p><ul><li>Hwu, W., Kirk, D., &amp; El Hajj, I. (2022). <em>Programming Massively Parallel Processors: A Hands-on Approach</em> (4th Edition). Morgan Kaufmann.</li><li>NVIDIA. <em>CUDA C++ Programming Guide</em>. <a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/">https://docs.nvidia.com/cuda/cuda-c-programming-guide/</a></li><li>NVIDIA. <em>CUDA C++ Best Practices Guide</em>. <a href="https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/">https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/</a></li></ul><hr><blockquote><p><strong>本文 GitHub 仓库</strong>: <a href="https://github.com/psmarter/PMPP-Learning">https://github.com/psmarter/PMPP-Learning</a></p><p><strong>系列完结</strong>：感谢阅读 PMPP 全书 22 章博客系列！</p></blockquote>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h2 id=&quot;qian-yan&quot; tabindex=&quot;-1&quot; id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;第二十一章介绍了动态并行性。作为全书的最后一章，第二十二章总结了&lt;strong&gt;高级实践（Advanced</summary>
        
      
    
    
    
    <category term="知识分享" scheme="https://smarter.xin/categories/knowledge-sharing/"/>
    
    
    <category term="CUDA" scheme="https://smarter.xin/tags/CUDA/"/>
    
    <category term="GPU编程" scheme="https://smarter.xin/tags/gpu-programming/"/>
    
    <category term="并行计算" scheme="https://smarter.xin/tags/parallel-computing/"/>
    
    <category term="PMPP" scheme="https://smarter.xin/tags/PMPP/"/>
    
    <category term="性能优化" scheme="https://smarter.xin/tags/performance-optimization/"/>
    
    <category term="未来趋势" scheme="https://smarter.xin/tags/future-trends/"/>
    
    <category term="最佳实践" scheme="https://smarter.xin/tags/best-practices/"/>
    
  </entry>
  
  <entry>
    <title>PMPP-第二十一章：CUDA动态并行性</title>
    <link href="https://smarter.xin/posts/e519c4bc/"/>
    <id>https://smarter.xin/posts/e519c4bc/</id>
    <published>2026-01-24T08:20:44.000Z</published>
    <updated>2026-01-24T11:47:21.462Z</updated>
    
    <content type="html"><![CDATA[<h2 id="qian-yan" tabindex="-1" id="前言">前言</h2><p>第二十章介绍了多 GPU 集群编程。第二十一章回到单 GPU 的高级特性——<strong>动态并行性（Dynamic Parallelism）</strong>。传统 CUDA 程序中，只有 CPU 能启动核函数；而动态并行性允许<strong>GPU 核函数直接启动子核函数</strong>，无需返回 CPU。这一特性对递归算法、自适应计算、不规则数据结构（如树、图）的处理特别有用。</p><blockquote><p><strong>📦 配套资源</strong>：本系列文章配有完整的 <a href="https://github.com/psmarter/PMPP-Learning">GitHub 仓库</a>，包含每章的练习题解答、CUDA 代码实现和详细注释。所有代码都经过测试，可以直接运行。</p></blockquote><h2 id="shi-yao-shi-dong-tai-bing-xing-xing" tabindex="-1" id="什么是动态并行性">什么是动态并行性</h2><h3 id="chuan-tong-cuda-mo-xing-de-xian-zhi" tabindex="-1" id="传统-CUDA-模型的限制">传统 CUDA 模型的限制</h3><p>传统 CUDA 程序中：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">CPU 代码 → 启动 kernel1 → GPU 执行 → 返回 CPU</span><br><span class="line">         → 启动 kernel2 → GPU 执行 → 返回 CPU</span><br><span class="line">         → ...</span><br></pre></td></tr></table></figure><p><strong>问题</strong>：</p><ol><li>每次启动 kernel 都需要 CPU 参与</li><li>递归算法难以表达</li><li>自适应算法需要多次 CPU-GPU 往返</li></ol><h3 id="dong-tai-bing-xing-xing" tabindex="-1" id="动态并行性">动态并行性</h3><p><strong>动态并行性</strong>：允许 GPU kernel 直接启动子 kernel（child kernel）。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">CPU 代码 → 启动父 kernel → GPU 执行</span><br><span class="line">                           ├→ 启动子 kernel1 → GPU 执行</span><br><span class="line">                           ├→ 启动子 kernel2 → GPU 执行</span><br><span class="line">                           └→ ...</span><br></pre></td></tr></table></figure><p><strong>优势</strong>：</p><ul><li>减少 CPU-GPU 通信</li><li>自然表达递归算法</li><li>根据数据特性动态调整计算</li></ul><h3 id="ying-jian-yao-qiu" tabindex="-1" id="硬件要求">硬件要求</h3><p>动态并行性需要计算能力 3.5 或更高的 GPU。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 编译时需要特殊选项</span></span><br><span class="line">nvcc -<span class="built_in">arch</span>=sm_35 -rdc=<span class="literal">true</span> my_program.cu -lcudadevrt</span><br></pre></td></tr></table></figure><ul><li><code>-rdc=true</code>：启用可重定位设备代码</li><li><code>-lcudadevrt</code>：链接设备运行时库</li></ul><h2 id="ji-ben-yu-fa" tabindex="-1" id="基本语法">基本语法</h2><h3 id="zai-she-bei-dai-ma-zhong-qi-dong-kernel" tabindex="-1" id="在设备代码中启动-kernel">在设备代码中启动 kernel</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">__global__ void child_kernel(int *data, int n) &#123;</span><br><span class="line">    int idx = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    if (idx &lt; n) &#123;</span><br><span class="line">        data[idx] *= 2;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">__global__ void parent_kernel(int *data, int n) &#123;</span><br><span class="line">    // 在设备代码中启动子 kernel</span><br><span class="line">    child_kernel&lt;&lt;&lt;1, 32&gt;&gt;&gt;(data, n);</span><br><span class="line">    </span><br><span class="line">    // 等待子 kernel 完成</span><br><span class="line">    cudaDeviceSynchronize();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="she-bei-duan-tong-bu" tabindex="-1" id="设备端同步">设备端同步</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">// 等待当前线程启动的所有子 kernel 完成</span><br><span class="line">cudaDeviceSynchronize();</span><br><span class="line"></span><br><span class="line">// 等待特定流中的操作完成</span><br><span class="line">cudaStreamSynchronize(stream);</span><br></pre></td></tr></table></figure><p><strong>注意</strong>：父 kernel 退出时会隐式等待所有子 kernel 完成。</p><h3 id="she-bei-duan-nei-cun-guan-li" tabindex="-1" id="设备端内存管理">设备端内存管理</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">__global__ void parent_kernel() &#123;</span><br><span class="line">    float *temp;</span><br><span class="line">    </span><br><span class="line">    // 在设备端分配内存</span><br><span class="line">    cudaMalloc(&amp;temp, 1024 * sizeof(float));</span><br><span class="line">    </span><br><span class="line">    // 使用内存...</span><br><span class="line">    child_kernel&lt;&lt;&lt;1, 256&gt;&gt;&gt;(temp, 1024);</span><br><span class="line">    cudaDeviceSynchronize();</span><br><span class="line">    </span><br><span class="line">    // 释放内存</span><br><span class="line">    cudaFree(temp);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="nei-cun-ke-jian-xing" tabindex="-1" id="内存可见性">内存可见性</h2><h3 id="na-xie-nei-cun-zi-kernel-ke-yi-fang-wen" tabindex="-1" id="哪些内存子-kernel-可以访问">哪些内存子 kernel 可以访问</h3><table><thead><tr><th>内存类型</th><th>子 kernel 可访问</th><th>说明</th></tr></thead><tbody><tr><td>全局内存</td><td>✓</td><td>父子共享</td></tr><tr><td>常量内存</td><td>✓</td><td>编译时确定，共享</td></tr><tr><td>纹理内存</td><td>✓</td><td>父子共享</td></tr><tr><td>共享内存</td><td>✗</td><td>仅限当前 Block</td></tr><tr><td>局部内存</td><td>✗</td><td>仅限当前线程</td></tr></tbody></table><h3 id="nei-cun-yi-zhi-xing" tabindex="-1" id="内存一致性">内存一致性</h3><p>父 kernel 的全局内存写入对子 kernel 可见，需要遵循一定规则：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">__global__ void parent_kernel(int *data) &#123;</span><br><span class="line">    // 写入全局内存</span><br><span class="line">    data[threadIdx.x] = threadIdx.x * 2;</span><br><span class="line">    </span><br><span class="line">    // 确保写入完成（块内同步）</span><br><span class="line">    __threadfence();</span><br><span class="line">    </span><br><span class="line">    // 启动子 kernel</span><br><span class="line">    if (threadIdx.x == 0) &#123;</span><br><span class="line">        child_kernel&lt;&lt;&lt;1, 32&gt;&gt;&gt;(data);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>关键点</strong>：</p><ul><li>父线程在启动子 kernel 前的写入对子 kernel 可见</li><li>子 kernel 的写入在 <code>cudaDeviceSynchronize()</code> 后对父线程可见</li></ul><h2 id="liu-yu-bing-fa" tabindex="-1" id="流与并发">流与并发</h2><h3 id="mo-ren-liu-xing-wei" tabindex="-1" id="默认流行为">默认流行为</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">__global__ void parent_kernel() &#123;</span><br><span class="line">    // 这两个 kernel 在同一个 Block 的默认流中顺序执行</span><br><span class="line">    child_kernel1&lt;&lt;&lt;1, 32&gt;&gt;&gt;();</span><br><span class="line">    child_kernel2&lt;&lt;&lt;1, 32&gt;&gt;&gt;();  // 等待 child_kernel1 完成</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>重要</strong>：同一 Block 内的线程共享默认流，因此子 kernel 会串行执行。</p><h3 id="shi-yong-du-li-liu-shi-xian-bing-fa" tabindex="-1" id="使用独立流实现并发">使用独立流实现并发</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">__global__ void parent_kernel() &#123;</span><br><span class="line">    cudaStream_t stream;</span><br><span class="line">    cudaStreamCreateWithFlags(&amp;stream, cudaStreamNonBlocking);</span><br><span class="line">    </span><br><span class="line">    // 在独立流中启动，可以与其他 kernel 并发</span><br><span class="line">    child_kernel&lt;&lt;&lt;1, 32, 0, stream&gt;&gt;&gt;();</span><br><span class="line">    </span><br><span class="line">    cudaStreamDestroy(stream);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="bing-fa-zi-kernel-shi-li" tabindex="-1" id="并发子-kernel-示例">并发子 kernel 示例</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">__global__ void parent_kernel(float *data, int n) &#123;</span><br><span class="line">    int chunk_size = n / 4;</span><br><span class="line">    cudaStream_t streams[4];</span><br><span class="line">    </span><br><span class="line">    for (int i = 0; i &lt; 4; i++) &#123;</span><br><span class="line">        cudaStreamCreateWithFlags(&amp;streams[i], cudaStreamNonBlocking);</span><br><span class="line">        child_kernel&lt;&lt;&lt;1, 256, 0, streams[i]&gt;&gt;&gt;(</span><br><span class="line">            data + i * chunk_size, chunk_size);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    // 等待所有流完成</span><br><span class="line">    cudaDeviceSynchronize();</span><br><span class="line">    </span><br><span class="line">    for (int i = 0; i &lt; 4; i++) &#123;</span><br><span class="line">        cudaStreamDestroy(streams[i]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="qi-dong-chi-pei-zhi" tabindex="-1" id="启动池配置">启动池配置</h2><h3 id="shi-yao-shi-qi-dong-chi" tabindex="-1" id="什么是启动池">什么是启动池</h3><p>每次子 kernel 启动需要从<strong>启动池</strong>分配资源。</p><p><strong>两种池</strong>：</p><ol><li><strong>固定大小池</strong>：默认 2048 个槽位，预分配</li><li><strong>虚拟化池</strong>：动态扩展，但性能较低</li></ol><h3 id="pei-zhi-qi-dong-chi" tabindex="-1" id="配置启动池">配置启动池</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// 获取当前设备属性</span><br><span class="line">cudaDeviceProp prop;</span><br><span class="line">cudaGetDeviceProperties(&amp;prop, 0);</span><br><span class="line"></span><br><span class="line">// 设置固定池大小</span><br><span class="line">cudaDeviceSetLimit(cudaLimitDevRuntimePendingLaunchCount, 8192);</span><br></pre></td></tr></table></figure><p><strong>建议</strong>：</p><ul><li>如果预期子 kernel 数量超过默认值，增大固定池</li><li>如果子 kernel 数量可预测，设置为该值</li></ul><h2 id="ying-yong-shi-li-bezier-qu-xian-xi-fen" tabindex="-1" id="应用示例：Bezier-曲线细分">应用示例：Bezier 曲线细分</h2><h3 id="wen-ti-miao-shu" tabindex="-1" id="问题描述">问题描述</h3><p>Bezier 曲线由控制点定义。曲线越弯曲，需要越多采样点才能平滑显示。</p><p><strong>自适应细分</strong>：根据曲率决定采样点数量。</p><h3 id="shu-ju-jie-gou" tabindex="-1" id="数据结构">数据结构</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#define MAX_TESS_POINTS 32</span><br><span class="line"></span><br><span class="line">struct BezierLine &#123;</span><br><span class="line">    float2 CP[3];                      // 3 个控制点</span><br><span class="line">    float2 vertexPos[MAX_TESS_POINTS]; // 细分后的顶点</span><br><span class="line">    int nVertices;                     // 顶点数量</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="ji-suan-qu-lu" tabindex="-1" id="计算曲率">计算曲率</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">__device__ float computeCurvature(float2 *cp) &#123;</span><br><span class="line">    // 计算首尾连线长度</span><br><span class="line">    float dx = cp[2].x - cp[0].x;</span><br><span class="line">    float dy = cp[2].y - cp[0].y;</span><br><span class="line">    float line_length = sqrtf(dx * dx + dy * dy);</span><br><span class="line">    </span><br><span class="line">    if (line_length &lt; 0.001f) return 0.0f;</span><br><span class="line">    </span><br><span class="line">    // 计算中点到直线的距离（曲率近似）</span><br><span class="line">    float cross = fabsf((cp[1].x - cp[0].x) * dy - </span><br><span class="line">                        (cp[1].y - cp[0].y) * dx);</span><br><span class="line">    return cross / line_length;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="zi-kernel-ji-suan-xi-fen-dian" tabindex="-1" id="子-kernel：计算细分点">子 kernel：计算细分点</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">__global__ void computeBezierLine_child(</span><br><span class="line">    int lidx, BezierLine *bLines, int nTessPoints) &#123;</span><br><span class="line">    </span><br><span class="line">    int idx = threadIdx.x + blockDim.x * blockIdx.x;</span><br><span class="line">    if (idx &lt; nTessPoints) &#123;</span><br><span class="line">        // 计算参数 u ∈ [0, 1]</span><br><span class="line">        float u = (float)idx / (float)(nTessPoints - 1);</span><br><span class="line">        float omu = 1.0f - u;</span><br><span class="line">        </span><br><span class="line">        // 二次 Bezier 基函数</span><br><span class="line">        float B[3];</span><br><span class="line">        B[0] = omu * omu;</span><br><span class="line">        B[1] = 2.0f * u * omu;</span><br><span class="line">        B[2] = u * u;</span><br><span class="line">        </span><br><span class="line">        // 计算点位置</span><br><span class="line">        float2 pos = &#123;0, 0&#125;;</span><br><span class="line">        for (int i = 0; i &lt; 3; i++) &#123;</span><br><span class="line">            pos.x += B[i] * bLines[lidx].CP[i].x;</span><br><span class="line">            pos.y += B[i] * bLines[lidx].CP[i].y;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        bLines[lidx].vertexPos[idx] = pos;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="fu-kernel-dong-tai-jue-ding-xi-fen-cheng-du" tabindex="-1" id="父-kernel：动态决定细分程度">父 kernel：动态决定细分程度</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">__global__ void computeBezierLines_parent(</span><br><span class="line">    BezierLine *bLines, int nLines) &#123;</span><br><span class="line">    </span><br><span class="line">    int lidx = threadIdx.x + blockDim.x * blockIdx.x;</span><br><span class="line">    if (lidx &lt; nLines) &#123;</span><br><span class="line">        // 根据曲率计算需要的顶点数</span><br><span class="line">        float curvature = computeCurvature(bLines[lidx].CP);</span><br><span class="line">        int nVertices = min(max((int)(curvature * 16.0f), 4), </span><br><span class="line">                            MAX_TESS_POINTS);</span><br><span class="line">        bLines[lidx].nVertices = nVertices;</span><br><span class="line">        </span><br><span class="line">        // 动态启动子 kernel</span><br><span class="line">        int blocks = (nVertices + 31) / 32;</span><br><span class="line">        computeBezierLine_child&lt;&lt;&lt;blocks, 32&gt;&gt;&gt;(</span><br><span class="line">            lidx, bLines, nVertices);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="dong-tai-vs-jing-tai-dui-bi" tabindex="-1" id="动态-vs-静态对比">动态 vs 静态对比</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">// 静态版本：每条曲线使用固定 Block，循环处理</span><br><span class="line">__global__ void computeBezierLines_static(</span><br><span class="line">    BezierLine *bLines, int nLines) &#123;</span><br><span class="line">    </span><br><span class="line">    int bidx = blockIdx.x;</span><br><span class="line">    if (bidx &lt; nLines) &#123;</span><br><span class="line">        float curvature = computeCurvature(bLines[bidx].CP);</span><br><span class="line">        int nVertices = min(max((int)(curvature * 16.0f), 4), </span><br><span class="line">                            MAX_TESS_POINTS);</span><br><span class="line">        bLines[bidx].nVertices = nVertices;</span><br><span class="line">        </span><br><span class="line">        // 用循环代替子 kernel</span><br><span class="line">        for (int inc = 0; inc &lt; nVertices; inc += blockDim.x) &#123;</span><br><span class="line">            int idx = inc + threadIdx.x;</span><br><span class="line">            if (idx &lt; nVertices) &#123;</span><br><span class="line">                // ... 计算顶点 ...</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>对比</strong>：</p><table><thead><tr><th>方面</th><th>动态并行</th><th>静态版本</th></tr></thead><tbody><tr><td>代码结构</td><td>更自然</td><td>需要手动循环</td></tr><tr><td>资源利用</td><td>子 kernel 精确配置</td><td>可能浪费线程</td></tr><tr><td>启动开销</td><td>较高</td><td>无额外开销</td></tr><tr><td>适用场景</td><td>工作量变化大</td><td>工作量均匀</td></tr></tbody></table><h2 id="ying-yong-shi-li-si-cha-shu-gou-jian" tabindex="-1" id="应用示例：四叉树构建">应用示例：四叉树构建</h2><h3 id="wen-ti-miao-shu-1" tabindex="-1" id="问题描述-2">问题描述</h3><p><strong>四叉树（Quadtree）</strong>：递归地将 2D 空间划分为四个象限，用于空间索引、碰撞检测、图像压缩等。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">初始区域         第一次划分         继续划分...</span><br><span class="line">┌─────────┐     ┌────┬────┐     ┌──┬──┬────┐</span><br><span class="line">│         │     │ TL │ TR │     │  │  │ TR │</span><br><span class="line">│    *    │  →  ├────┼────┤  →  ├──┼──┼────┤</span><br><span class="line">│   **    │     │ BL │ BR │     │  │  │    │</span><br><span class="line">└─────────┘     └────┴────┘     └──┴──┴────┘</span><br></pre></td></tr></table></figure><h3 id="di-gui-suan-fa" tabindex="-1" id="递归算法">递归算法</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">function build_quadtree(node, points):</span><br><span class="line">    if depth &gt; max_depth or len(points) &lt; threshold:</span><br><span class="line">        return  // 停止递归</span><br><span class="line">    </span><br><span class="line">    // 将点分类到四个象限</span><br><span class="line">    for each point in points:</span><br><span class="line">        classify to TL, TR, BL, or BR</span><br><span class="line">    </span><br><span class="line">    // 递归处理每个象限</span><br><span class="line">    build_quadtree(node.TL, TL_points)</span><br><span class="line">    build_quadtree(node.TR, TR_points)</span><br><span class="line">    build_quadtree(node.BL, BL_points)</span><br><span class="line">    build_quadtree(node.BR, BR_points)</span><br></pre></td></tr></table></figure><h3 id="shu-ju-jie-gou-1" tabindex="-1" id="数据结构-2">数据结构</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">class Quadtree_node &#123;</span><br><span class="line">    int m_id;                  // 节点 ID</span><br><span class="line">    Bounding_box m_bbox;       // 边界框</span><br><span class="line">    int m_begin, m_end;        // 点范围 [begin, end)</span><br><span class="line">    </span><br><span class="line">public:</span><br><span class="line">    __device__ int num_points() const &#123; return m_end - m_begin; &#125;</span><br><span class="line">    // ...</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">struct Parameters &#123;</span><br><span class="line">    int point_selector;         // 双缓冲选择器</span><br><span class="line">    int num_nodes_at_this_level; // 当前层节点数</span><br><span class="line">    int depth;                  // 当前深度</span><br><span class="line">    int max_depth;              // 最大深度</span><br><span class="line">    int min_points_per_node;    // 停止阈值</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="he-xin-kernel" tabindex="-1" id="核心-kernel">核心 kernel</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">__global__ void build_quadtree_kernel(</span><br><span class="line">    Quadtree_node *nodes, Points *points, Parameters params) &#123;</span><br><span class="line">    </span><br><span class="line">    __shared__ int smem[8];  // 每个象限的点数和偏移</span><br><span class="line">    </span><br><span class="line">    Quadtree_node *node = &amp;nodes[blockIdx.x];</span><br><span class="line">    int num_points = node-&gt;num_points();</span><br><span class="line">    </span><br><span class="line">    // 检查停止条件</span><br><span class="line">    if (params.depth &gt;= params.max_depth || </span><br><span class="line">        num_points &lt;= params.min_points_per_node) &#123;</span><br><span class="line">        return;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    // 计算边界框中心</span><br><span class="line">    float2 center;</span><br><span class="line">    node-&gt;bounding_box().compute_center(&amp;center);</span><br><span class="line">    </span><br><span class="line">    // 统计每个象限的点数</span><br><span class="line">    count_points_in_children(points[params.point_selector], </span><br><span class="line">                              smem, node, center);</span><br><span class="line">    </span><br><span class="line">    // 计算重排偏移</span><br><span class="line">    scan_for_offsets(node-&gt;points_begin(), smem);</span><br><span class="line">    </span><br><span class="line">    // 重排点到双缓冲</span><br><span class="line">    reorder_points(points[(params.point_selector + 1) % 2],</span><br><span class="line">                   points[params.point_selector], smem, node, center);</span><br><span class="line">    </span><br><span class="line">    // 递归启动子 kernel</span><br><span class="line">    if (threadIdx.x == 0) &#123;</span><br><span class="line">        Quadtree_node *children = </span><br><span class="line">            &amp;nodes[params.num_nodes_at_this_level + blockIdx.x * 4];</span><br><span class="line">        </span><br><span class="line">        prepare_children(children, node, smem, center);</span><br><span class="line">        </span><br><span class="line">        Parameters next_params(params, true);  // 更新参数</span><br><span class="line">        </span><br><span class="line">        for (int i = 0; i &lt; 4; i++) &#123;</span><br><span class="line">            if (smem[i] &gt; 0) &#123;  // 只处理非空象限</span><br><span class="line">                build_quadtree_kernel&lt;&lt;&lt;1, 32&gt;&gt;&gt;(</span><br><span class="line">                    &amp;children[i], points, next_params);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="dian-fen-lei-tong-ji-jie-duan" tabindex="-1" id="点分类（统计阶段）">点分类（统计阶段）</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">__device__ void count_points_in_children(</span><br><span class="line">    const Points &amp;in_points, int *smem, </span><br><span class="line">    int range_begin, int range_end, float2 center) &#123;</span><br><span class="line">    </span><br><span class="line">    // 初始化计数</span><br><span class="line">    if (threadIdx.x &lt; 4) &#123;</span><br><span class="line">        smem[threadIdx.x] = 0;</span><br><span class="line">    &#125;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    // 每个线程处理多个点</span><br><span class="line">    for (int iter = range_begin + threadIdx.x; </span><br><span class="line">         iter &lt; range_end; iter += blockDim.x) &#123;</span><br><span class="line">        float2 p = in_points.get_point(iter);</span><br><span class="line">        </span><br><span class="line">        if (p.x &lt; center.x &amp;&amp; p.y &gt;= center.y) &#123;</span><br><span class="line">            atomicAdd(&amp;smem[0], 1);  // 左上</span><br><span class="line">        &#125; else if (p.x &gt;= center.x &amp;&amp; p.y &gt;= center.y) &#123;</span><br><span class="line">            atomicAdd(&amp;smem[1], 1);  // 右上</span><br><span class="line">        &#125; else if (p.x &lt; center.x &amp;&amp; p.y &lt; center.y) &#123;</span><br><span class="line">            atomicAdd(&amp;smem[2], 1);  // 左下</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            atomicAdd(&amp;smem[3], 1);  // 右下</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    __syncthreads();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="shen-du-fen-xi" tabindex="-1" id="深度分析">深度分析</h3><p>假设初始有 64 个均匀分布的点：</p><table><thead><tr><th>深度</th><th>节点数</th><th>每节点点数</th></tr></thead><tbody><tr><td>0</td><td>1</td><td>64</td></tr><tr><td>1</td><td>4</td><td>16</td></tr><tr><td>2</td><td>16</td><td>4</td></tr><tr><td>3</td><td>64</td><td>1</td></tr></tbody></table><p>总共启动 1 + 4 + 16 = <strong>21</strong> 个子 kernel。</p><h2 id="xing-neng-kao-lu" tabindex="-1" id="性能考虑">性能考虑</h2><h3 id="qi-dong-kai-xiao" tabindex="-1" id="启动开销">启动开销</h3><p>子 kernel 启动有开销：</p><ul><li>资源分配</li><li>参数传递</li><li>调度延迟</li></ul><p><strong>建议</strong>：只在工作量足够大时使用动态并行。</p><h3 id="qian-tao-shen-du-xian-zhi" tabindex="-1" id="嵌套深度限制">嵌套深度限制</h3><p>CUDA 限制嵌套深度（通常 24 层）。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">// 检查支持的嵌套深度</span><br><span class="line">int max_depth;</span><br><span class="line">cudaDeviceGetAttribute(&amp;max_depth, </span><br><span class="line">    cudaDevAttrMaxDeviceRuntimeSynchronizationDepth, 0);</span><br></pre></td></tr></table></figure><h3 id="nei-cun-xiao-hao" tabindex="-1" id="内存消耗">内存消耗</h3><p>每层递归消耗栈空间。深度递归可能导致栈溢出。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// 增大栈大小</span><br><span class="line">cudaDeviceSetLimit(cudaLimitStackSize, 8192);</span><br></pre></td></tr></table></figure><h3 id="he-shi-shi-yong-dong-tai-bing-xing" tabindex="-1" id="何时使用动态并行">何时使用动态并行</h3><p><strong>适合使用</strong>：</p><ul><li>递归算法（树遍历、分治）</li><li>自适应细分（网格细化、LOD）</li><li>不规则数据（稀疏图、不平衡树）</li></ul><p><strong>不适合使用</strong>：</p><ul><li>规则的数据并行（矩阵运算）</li><li>子 kernel 工作量很小</li><li>需要极致性能的场景</li></ul><h2 id="diao-shi-yu-zui-jia-shi-jian" tabindex="-1" id="调试与最佳实践">调试与最佳实践</h2><h3 id="cuo-wu-chu-li" tabindex="-1" id="错误处理">错误处理</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">__global__ void parent_kernel() &#123;</span><br><span class="line">    cudaError_t err;</span><br><span class="line">    </span><br><span class="line">    child_kernel&lt;&lt;&lt;1, 32&gt;&gt;&gt;();</span><br><span class="line">    err = cudaGetLastError();</span><br><span class="line">    if (err != cudaSuccess) &#123;</span><br><span class="line">        printf(&quot;Child kernel launch failed: %s\n&quot;, </span><br><span class="line">               cudaGetErrorString(err));</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    err = cudaDeviceSynchronize();</span><br><span class="line">    if (err != cudaSuccess) &#123;</span><br><span class="line">        printf(&quot;Child kernel execution failed: %s\n&quot;, </span><br><span class="line">               cudaGetErrorString(err));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="bi-mian-guo-du-qian-tao" tabindex="-1" id="避免过度嵌套">避免过度嵌套</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">__global__ void recursive_kernel(int depth, int max_depth) &#123;</span><br><span class="line">    if (depth &gt;= max_depth) &#123;</span><br><span class="line">        return;  // 停止递归</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    recursive_kernel&lt;&lt;&lt;1, 32&gt;&gt;&gt;(depth + 1, max_depth);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="zi-yuan-guan-li" tabindex="-1" id="资源管理">资源管理</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">__global__ void parent_kernel() &#123;</span><br><span class="line">    float *temp;</span><br><span class="line">    cudaMalloc(&amp;temp, size);</span><br><span class="line">    </span><br><span class="line">    // 确保子 kernel 完成后再释放</span><br><span class="line">    child_kernel&lt;&lt;&lt;1, 32&gt;&gt;&gt;(temp);</span><br><span class="line">    cudaDeviceSynchronize();</span><br><span class="line">    </span><br><span class="line">    cudaFree(temp);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="xiao-jie" tabindex="-1" id="小结">小结</h2><p>第二十一章介绍了 CUDA 动态并行性这一高级特性：</p><p><strong>核心概念</strong>：GPU kernel 可以直接启动子 kernel，无需返回 CPU。这使得递归算法和自适应计算可以完全在 GPU 上执行。</p><p><strong>语法要点</strong>：</p><ul><li>在 <code>__global__</code> 函数中使用 <code>&lt;&lt;&lt;...&gt;&gt;&gt;</code> 启动子 kernel</li><li><code>cudaDeviceSynchronize()</code> 等待子 kernel 完成</li><li>可以在设备端使用 <code>cudaMalloc</code>/<code>cudaFree</code></li></ul><p><strong>内存可见性</strong>：</p><ul><li>全局、常量、纹理内存父子共享</li><li>共享内存和局部内存不能传递给子 kernel</li></ul><p><strong>流与并发</strong>：</p><ul><li>同一 Block 的默认流共享，子 kernel 串行执行</li><li>使用非阻塞流实现子 kernel 并发</li></ul><p><strong>应用场景</strong>：</p><ul><li>Bezier 曲线自适应细分：根据曲率动态决定采样密度</li><li>四叉树构建：递归划分空间</li></ul><p><strong>性能考虑</strong>：</p><ul><li>启动开销不可忽视</li><li>深度递归消耗栈空间</li><li>配置启动池大小</li></ul><p>动态并行性让 GPU 编程更加灵活，但要权衡使用——对于规则的数据并行任务，传统方式可能更高效。对于天然递归或自适应的问题，动态并行性是强大的工具。</p><h2 id="xia-yi-bu" tabindex="-1" id="🚀-下一步">🚀 下一步</h2><ul><li>实现 Bezier 曲线的自适应细分，体验动态并行性的优势</li><li>构建一个四叉树或八叉树，学习递归算法的 GPU 实现</li><li>探索其他递归算法：快速排序、归并排序、分治算法</li><li>学习动态并行性的性能调优：启动池配置、嵌套深度控制</li><li>对比动态并行性与传统方法的性能差异，理解适用场景</li><li>研究自适应网格细化（AMR）等高级应用</li></ul><hr><h2 id="can-kao-zi-liao" tabindex="-1" id="📚-参考资料">📚 参考资料</h2><ul><li>PMPP 第四版 Chapter 21</li><li><a href="https://smarter.xin/posts/pmmpp-chapter21-dynamic-parallelism/">第二十一章：CUDA动态并行性</a></li><li>Hwu, W., Kirk, D., &amp; El Hajj, I. (2022). <em>Programming Massively Parallel Processors: A Hands-on Approach</em> (4th Edition). Morgan Kaufmann.</li><li>NVIDIA. <em>CUDA C++ Programming Guide - Dynamic Parallelism</em>. <a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/">https://docs.nvidia.com/cuda/cuda-c-programming-guide/</a></li><li>NVIDIA. <em>CUDA Dynamic Parallelism</em>. <a href="https://developer.nvidia.com/blog/cuda-dynamic-parallelism-api-principles/">https://developer.nvidia.com/blog/cuda-dynamic-parallelism-api-principles/</a></li></ul><p><strong>学习愉快！</strong> 🎓</p><hr><blockquote><p><strong>本文 GitHub 仓库</strong>: <a href="https://github.com/psmarter/PMPP-Learning">https://github.com/psmarter/PMPP-Learning</a></p></blockquote>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h2 id=&quot;qian-yan&quot; tabindex=&quot;-1&quot; id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;第二十章介绍了多 GPU 集群编程。第二十一章回到单 GPU 的高级特性——&lt;strong&gt;动态并行性（Dynamic Parallelism）&lt;/strong&gt;。传统</summary>
        
      
    
    
    
    <category term="知识分享" scheme="https://smarter.xin/categories/knowledge-sharing/"/>
    
    
    <category term="CUDA" scheme="https://smarter.xin/tags/CUDA/"/>
    
    <category term="GPU编程" scheme="https://smarter.xin/tags/gpu-programming/"/>
    
    <category term="并行计算" scheme="https://smarter.xin/tags/parallel-computing/"/>
    
    <category term="PMPP" scheme="https://smarter.xin/tags/PMPP/"/>
    
    <category term="动态并行" scheme="https://smarter.xin/tags/dynamic-parallel/"/>
    
    <category term="递归算法" scheme="https://smarter.xin/tags/recursive-algorithm/"/>
    
    <category term="四叉树" scheme="https://smarter.xin/tags/quadtree/"/>
    
  </entry>
  
  <entry>
    <title>PMPP-第二十章：异构计算集群编程</title>
    <link href="https://smarter.xin/posts/9506dbb9/"/>
    <id>https://smarter.xin/posts/9506dbb9/</id>
    <published>2026-01-24T07:26:44.000Z</published>
    <updated>2026-01-24T11:47:21.462Z</updated>
    
    <content type="html"><![CDATA[<h2 id="qian-yan" tabindex="-1" id="前言">前言</h2><p>第十九章总结了并行编程的思维方法。第二十章将视野扩展到<strong>计算集群（Computing Cluster）</strong>——多台计算机通过高速网络连接，每台计算机可能配备多个 GPU。这是当今超级计算机和数据中心的典型架构。本章讨论如何使用 **MPI（Message Passing Interface，消息传递接口）**与 CUDA 结合，实现跨节点的异构并行计算。掌握这些技术，就能编写可扩展到数千个 GPU 的大规模并行程序。</p><blockquote><p><strong>📦 配套资源</strong>：本系列文章配有完整的 <a href="https://github.com/psmarter/PMPP-Learning">GitHub 仓库</a>，包含每章的练习题解答、CUDA 代码实现和详细注释。所有代码都经过测试，可以直接运行。</p></blockquote><h2 id="yi-gou-ji-suan-ji-qun-jia-gou" tabindex="-1" id="异构计算集群架构">异构计算集群架构</h2><h3 id="shi-yao-shi-yi-gou-ji-qun" tabindex="-1" id="什么是异构集群">什么是异构集群</h3><p><strong>异构集群</strong>：由多个计算节点组成，每个节点包含：</p><ul><li>CPU（主机）</li><li>一个或多个 GPU（加速器）</li><li>本地内存</li><li>网络接口</li></ul><p>节点之间通过高速网络（如 InfiniBand、NVLink）连接。</p><h3 id="dian-xing-jia-gou" tabindex="-1" id="典型架构">典型架构</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">┌─────────────────────────────────────────────────────────┐</span><br><span class="line">│                    计算集群                              │</span><br><span class="line">├─────────────────┬─────────────────┬─────────────────────┤</span><br><span class="line">│    节点 0       │    节点 1       │    节点 N-1         │</span><br><span class="line">│  ┌─────────┐   │  ┌─────────┐   │  ┌─────────┐        │</span><br><span class="line">│  │  CPU    │   │  │  CPU    │   │  │  CPU    │        │</span><br><span class="line">│  └────┬────┘   │  └────┬────┘   │  └────┬────┘        │</span><br><span class="line">│       │        │       │        │       │             │</span><br><span class="line">│  ┌────┴────┐   │  ┌────┴────┐   │  ┌────┴────┐        │</span><br><span class="line">│  │GPU0│GPU1│   │  │GPU0│GPU1│   │  │GPU0│GPU1│        │</span><br><span class="line">│  └─────────┘   │  └─────────┘   │  └─────────┘        │</span><br><span class="line">└────────┬───────┴────────┬───────┴────────┬────────────┘</span><br><span class="line">         │                │                │</span><br><span class="line">         └────────────────┴────────────────┘</span><br><span class="line">                    高速网络</span><br></pre></td></tr></table></figure><h3 id="bian-cheng-tiao-zhan" tabindex="-1" id="编程挑战">编程挑战</h3><ol><li><strong>分布式内存</strong>：每个节点有独立的内存空间，不能直接访问</li><li><strong>数据通信</strong>：需要显式地在节点间传递数据</li><li><strong>同步协调</strong>：多个进程需要协调工作</li><li><strong>故障容错</strong>：单个节点故障不应导致整个计算崩溃</li></ol><h2 id="mpi-ji-chu" tabindex="-1" id="MPI-基础">MPI 基础</h2><h3 id="shi-yao-shi-mpi" tabindex="-1" id="什么是-MPI">什么是 MPI</h3><p><strong>MPI（Message Passing Interface）</strong>：一种标准化的消息传递编程模型。</p><ul><li>定义了进程间通信的 API</li><li>支持点对点通信和集合通信</li><li>与硬件无关，可移植性好</li></ul><p>常见实现：OpenMPI、MPICH、Intel MPI。</p><h3 id="ji-ben-gai-nian" tabindex="-1" id="基本概念">基本概念</h3><p><strong>进程（Process）</strong>：MPI 程序的基本执行单元。每个进程有：</p><ul><li>唯一的<strong>秩（Rank）</strong>：0 到 N-1</li><li>独立的地址空间</li><li>可以运行在不同的物理节点上</li></ul><p><strong>通信子（Communicator）</strong>：定义参与通信的进程组。</p><ul><li><code>MPI_COMM_WORLD</code>：包含所有进程的默认通信子</li></ul><h3 id="mpi-cheng-xu-gu-jia" tabindex="-1" id="MPI-程序骨架">MPI 程序骨架</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;mpi.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> *argv[])</span> &#123;</span><br><span class="line">    <span class="type">int</span> rank, size;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 初始化 MPI</span></span><br><span class="line">    MPI_Init(&amp;argc, &amp;argv);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 获取当前进程的秩</span></span><br><span class="line">    MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 获取进程总数</span></span><br><span class="line">    MPI_Comm_size(MPI_COMM_WORLD, &amp;size);</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;进程 %d / %d\n&quot;</span>, rank, size);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 计算和通信...</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 结束 MPI</span></span><br><span class="line">    MPI_Finalize();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>运行方式</strong>：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mpirun -np 4 ./my_program   <span class="comment"># 启动 4 个进程</span></span><br></pre></td></tr></table></figure><h2 id="dian-dui-dian-tong-xin" tabindex="-1" id="点对点通信">点对点通信</h2><h3 id="ji-ben-fa-song-he-jie-shou" tabindex="-1" id="基本发送和接收">基本发送和接收</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 发送</span></span><br><span class="line">MPI_Send(</span><br><span class="line">    <span class="type">void</span> *buf,          <span class="comment">// 发送缓冲区</span></span><br><span class="line">    <span class="type">int</span> count,          <span class="comment">// 元素个数</span></span><br><span class="line">    MPI_Datatype dtype, <span class="comment">// 数据类型（MPI_FLOAT, MPI_INT 等）</span></span><br><span class="line">    <span class="type">int</span> dest,           <span class="comment">// 目标进程秩</span></span><br><span class="line">    <span class="type">int</span> tag,            <span class="comment">// 消息标签</span></span><br><span class="line">    MPI_Comm comm       <span class="comment">// 通信子</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 接收</span></span><br><span class="line">MPI_Recv(</span><br><span class="line">    <span class="type">void</span> *buf,          <span class="comment">// 接收缓冲区</span></span><br><span class="line">    <span class="type">int</span> count,          <span class="comment">// 最大元素个数</span></span><br><span class="line">    MPI_Datatype dtype, <span class="comment">// 数据类型</span></span><br><span class="line">    <span class="type">int</span> source,         <span class="comment">// 源进程秩</span></span><br><span class="line">    <span class="type">int</span> tag,            <span class="comment">// 消息标签</span></span><br><span class="line">    MPI_Comm comm,      <span class="comment">// 通信子</span></span><br><span class="line">    MPI_Status *status  <span class="comment">// 状态信息</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure><h3 id="zu-sai-yu-fei-zu-sai" tabindex="-1" id="阻塞与非阻塞">阻塞与非阻塞</h3><p><strong>阻塞通信</strong>：函数返回时，操作已完成或缓冲区可安全复用。</p><ul><li><code>MPI_Send</code>：可能阻塞直到接收方准备好（取决于实现）</li><li><code>MPI_Recv</code>：阻塞直到消息到达</li></ul><p><strong>非阻塞通信</strong>：函数立即返回，后续检查完成状态。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">MPI_Request request;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 非阻塞发送</span></span><br><span class="line">MPI_Isend(buf, count, dtype, dest, tag, comm, &amp;request);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 做其他事情...</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 等待完成</span></span><br><span class="line">MPI_Wait(&amp;request, &amp;status);</span><br></pre></td></tr></table></figure><h3 id="send-receive-zu-he" tabindex="-1" id="Send-Receive-组合">Send-Receive 组合</h3><p>避免死锁的常用模式：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">MPI_Sendrecv(</span><br><span class="line">    send_buf, send_count, send_type, dest, send_tag,</span><br><span class="line">    recv_buf, recv_count, recv_type, source, recv_tag,</span><br><span class="line">    comm, &amp;status</span><br><span class="line">);</span><br></pre></td></tr></table></figure><p>同时发送和接收，系统自动处理顺序。</p><h2 id="mpi-cuda-bian-cheng" tabindex="-1" id="MPI-CUDA-编程">MPI + CUDA 编程</h2><h3 id="ji-ben-ce-lue" tabindex="-1" id="基本策略">基本策略</h3><p>每个 MPI 进程管理一个或多个 GPU：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> rank;</span><br><span class="line">MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 每个进程选择不同的 GPU</span></span><br><span class="line"><span class="type">int</span> num_devices;</span><br><span class="line">cudaGetDeviceCount(&amp;num_devices);</span><br><span class="line">cudaSetDevice(rank % num_devices);</span><br></pre></td></tr></table></figure><h3 id="shu-ju-liu-mo-shi" tabindex="-1" id="数据流模式">数据流模式</h3><p>典型的 MPI + CUDA 计算流程：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1. MPI 进程接收输入数据（主机内存）</span><br><span class="line">2. 复制数据到 GPU（cudaMemcpy H2D）</span><br><span class="line">3. GPU 计算（kernel）</span><br><span class="line">4. 复制结果到主机（cudaMemcpy D2H）</span><br><span class="line">5. MPI 进程发送结果</span><br></pre></td></tr></table></figure><h3 id="shi-li-fen-bu-shi-xiang-liang-jia-fa" tabindex="-1" id="示例：分布式向量加法">示例：分布式向量加法</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">distributed_vector_add</span><span class="params">(<span class="type">float</span> *a, <span class="type">float</span> *b, <span class="type">float</span> *c, <span class="type">int</span> n, <span class="type">int</span> rank, <span class="type">int</span> size)</span> &#123;</span><br><span class="line">    <span class="type">int</span> local_n = n / size;</span><br><span class="line">    <span class="type">int</span> start = rank * local_n;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 分配 GPU 内存</span></span><br><span class="line">    <span class="type">float</span> *d_a, *d_b, *d_c;</span><br><span class="line">    cudaMalloc(&amp;d_a, local_n * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">    cudaMalloc(&amp;d_b, local_n * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">    cudaMalloc(&amp;d_c, local_n * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 复制本地数据到 GPU</span></span><br><span class="line">    cudaMemcpy(d_a, a + start, local_n * <span class="keyword">sizeof</span>(<span class="type">float</span>), cudaMemcpyHostToDevice);</span><br><span class="line">    cudaMemcpy(d_b, b + start, local_n * <span class="keyword">sizeof</span>(<span class="type">float</span>), cudaMemcpyHostToDevice);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// GPU 计算</span></span><br><span class="line">    <span class="type">int</span> block_size = <span class="number">256</span>;</span><br><span class="line">    <span class="type">int</span> grid_size = (local_n + block_size - <span class="number">1</span>) / block_size;</span><br><span class="line">    vector_add&lt;&lt;&lt;grid_size, block_size&gt;&gt;&gt;(d_a, d_b, d_c, local_n);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 复制结果回主机</span></span><br><span class="line">    cudaMemcpy(c + start, d_c, local_n * <span class="keyword">sizeof</span>(<span class="type">float</span>), cudaMemcpyDeviceToHost);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 收集所有结果到进程 0</span></span><br><span class="line">    MPI_Gather(c + start, local_n, MPI_FLOAT,</span><br><span class="line">               c, local_n, MPI_FLOAT,</span><br><span class="line">               <span class="number">0</span>, MPI_COMM_WORLD);</span><br><span class="line">    </span><br><span class="line">    cudaFree(d_a);</span><br><span class="line">    cudaFree(d_b);</span><br><span class="line">    cudaFree(d_c);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="halo-jiao-huan-yu-bian-jie-tong-xin" tabindex="-1" id="Halo-交换与边界通信">Halo 交换与边界通信</h2><h3 id="shi-yao-shi-halo" tabindex="-1" id="什么是-Halo">什么是 Halo</h3><p>在模板计算（stencil）、有限差分等应用中，每个点的计算依赖于邻近点。</p><p>当数据分布在多个进程时，边界点的计算需要<strong>相邻进程的数据</strong>。</p><p><strong>Halo（光晕/幽灵区域）</strong>：存储来自邻居进程的边界数据。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">进程 0 的数据        进程 1 的数据</span><br><span class="line">┌──────────────┐    ┌──────────────┐</span><br><span class="line">│              │    │              │</span><br><span class="line">│   内部区域   │    │   内部区域   │</span><br><span class="line">│              │    │              │</span><br><span class="line">├──────────────┤    ├──────────────┤</span><br><span class="line">│  右边界 →→→  │ ↔  │ ←←← 左 Halo │</span><br><span class="line">│ (发送给 P1)  │    │ (来自 P0)   │</span><br><span class="line">└──────────────┘    └──────────────┘</span><br></pre></td></tr></table></figure><h3 id="3-d-mo-ban-ji-suan-shi-li" tabindex="-1" id="3D-模板计算示例">3D 模板计算示例</h3><p>以 25 点模板为例（每个方向延伸 4 个点）：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 计算每个进程需要多少 Halo 点</span></span><br><span class="line"><span class="type">int</span> halo_size = <span class="number">4</span>;  <span class="comment">// 每侧 4 层</span></span><br><span class="line"><span class="type">int</span> num_halo_points = dimx * dimy * halo_size;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 分配包含 Halo 的数据</span></span><br><span class="line"><span class="type">int</span> total_z = local_dimz + <span class="number">2</span> * halo_size;</span><br><span class="line"><span class="type">float</span> *data = <span class="built_in">malloc</span>(dimx * dimy * total_z * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br></pre></td></tr></table></figure><h3 id="halo-jiao-huan-shi-xian" tabindex="-1" id="Halo-交换实现">Halo 交换实现</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">exchange_halos</span><span class="params">(<span class="type">float</span> *data, <span class="type">int</span> dimx, <span class="type">int</span> dimy, <span class="type">int</span> dimz,</span></span><br><span class="line"><span class="params">                     <span class="type">int</span> left_neighbor, <span class="type">int</span> right_neighbor)</span> &#123;</span><br><span class="line">    <span class="type">int</span> halo_size = <span class="number">4</span>;</span><br><span class="line">    <span class="type">int</span> num_halo_points = dimx * dimy * halo_size;</span><br><span class="line">    </span><br><span class="line">    <span class="type">float</span> *left_send = data + num_halo_points;  <span class="comment">// 左边界数据</span></span><br><span class="line">    <span class="type">float</span> *right_send = data + dimx * dimy * (dimz - halo_size);  <span class="comment">// 右边界数据</span></span><br><span class="line">    <span class="type">float</span> *left_recv = data;  <span class="comment">// 左 Halo 接收区</span></span><br><span class="line">    <span class="type">float</span> *right_recv = data + dimx * dimy * (dimz + halo_size);  <span class="comment">// 右 Halo 接收区</span></span><br><span class="line">    </span><br><span class="line">    MPI_Status status;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 发送到左邻居，从右邻居接收</span></span><br><span class="line">    MPI_Sendrecv(left_send, num_halo_points, MPI_FLOAT, left_neighbor, <span class="number">0</span>,</span><br><span class="line">                 right_recv, num_halo_points, MPI_FLOAT, right_neighbor, <span class="number">0</span>,</span><br><span class="line">                 MPI_COMM_WORLD, &amp;status);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 发送到右邻居，从左邻居接收</span></span><br><span class="line">    MPI_Sendrecv(right_send, num_halo_points, MPI_FLOAT, right_neighbor, <span class="number">1</span>,</span><br><span class="line">                 left_recv, num_halo_points, MPI_FLOAT, left_neighbor, <span class="number">1</span>,</span><br><span class="line">                 MPI_COMM_WORLD, &amp;status);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="ji-suan-yu-tong-xin-zhong-die" tabindex="-1" id="计算与通信重叠">计算与通信重叠</h2><h3 id="wen-ti" tabindex="-1" id="问题">问题</h3><p>通信需要时间，如果先计算完再通信，GPU 会空闲等待。</p><h3 id="jie-jue-fang-an" tabindex="-1" id="解决方案">解决方案</h3><p><strong>思路</strong>：重叠计算与通信。</p><ol><li>先计算边界区域（通信需要的数据）</li><li>边界计算完成后，开始通信</li><li>同时计算内部区域</li><li>通信完成后，所有计算都完成了</li></ol><h3 id="cuda-liu-shi-xian" tabindex="-1" id="CUDA-流实现">CUDA 流实现</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">cudaStream_t stream_boundary, stream_internal;</span><br><span class="line">cudaStreamCreate(&amp;stream_boundary);</span><br><span class="line">cudaStreamCreate(&amp;stream_internal);</span><br><span class="line"></span><br><span class="line">// 阶段 1：计算边界（在 stream_boundary 中）</span><br><span class="line">stencil_kernel&lt;&lt;&lt;grid_boundary, block, 0, stream_boundary&gt;&gt;&gt;(</span><br><span class="line">    d_output + left_offset, d_input + left_offset, dimx, dimy, 12);</span><br><span class="line">stencil_kernel&lt;&lt;&lt;grid_boundary, block, 0, stream_boundary&gt;&gt;&gt;(</span><br><span class="line">    d_output + right_offset, d_input + right_offset, dimx, dimy, 12);</span><br><span class="line"></span><br><span class="line">// 阶段 2：同时进行——</span><br><span class="line">// 2a: 计算内部区域（在 stream_internal 中）</span><br><span class="line">stencil_kernel&lt;&lt;&lt;grid_internal, block, 0, stream_internal&gt;&gt;&gt;(</span><br><span class="line">    d_output + internal_offset, d_input + internal_offset, dimx, dimy, dimz - 8);</span><br><span class="line"></span><br><span class="line">// 2b: 复制边界到主机，准备发送</span><br><span class="line">cudaMemcpyAsync(h_left_boundary, d_output + boundary_left,</span><br><span class="line">                num_halo_bytes, cudaMemcpyDeviceToHost, stream_boundary);</span><br><span class="line">cudaMemcpyAsync(h_right_boundary, d_output + boundary_right,</span><br><span class="line">                num_halo_bytes, cudaMemcpyDeviceToHost, stream_boundary);</span><br><span class="line"></span><br><span class="line">// 等待边界复制完成</span><br><span class="line">cudaStreamSynchronize(stream_boundary);</span><br><span class="line"></span><br><span class="line">// 阶段 3：MPI 通信</span><br><span class="line">MPI_Sendrecv(h_left_boundary, num_halo_points, MPI_FLOAT, left_neighbor, 0,</span><br><span class="line">             h_right_halo, num_halo_points, MPI_FLOAT, right_neighbor, 0,</span><br><span class="line">             MPI_COMM_WORLD, &amp;status);</span><br><span class="line">MPI_Sendrecv(h_right_boundary, num_halo_points, MPI_FLOAT, right_neighbor, 1,</span><br><span class="line">             h_left_halo, num_halo_points, MPI_FLOAT, left_neighbor, 1,</span><br><span class="line">             MPI_COMM_WORLD, &amp;status);</span><br><span class="line"></span><br><span class="line">// 复制 Halo 回 GPU</span><br><span class="line">cudaMemcpyAsync(d_output + left_halo_offset, h_left_halo,</span><br><span class="line">                num_halo_bytes, cudaMemcpyHostToDevice, stream_boundary);</span><br><span class="line">cudaMemcpyAsync(d_output + right_halo_offset, h_right_halo,</span><br><span class="line">                num_halo_bytes, cudaMemcpyHostToDevice, stream_boundary);</span><br><span class="line"></span><br><span class="line">// 等待所有操作完成</span><br><span class="line">cudaDeviceSynchronize();</span><br></pre></td></tr></table></figure><h3 id="shi-jian-xian-fen-xi" tabindex="-1" id="时间线分析">时间线分析</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">                    时间 →</span><br><span class="line">stream_boundary:  [边界计算][D2H][       ][H2D]</span><br><span class="line">stream_internal:  [           内部计算          ]</span><br><span class="line">MPI 通信:         [      ][Sendrecv][      ]</span><br><span class="line">                           ↑</span><br><span class="line">                     重叠区域：内部计算</span><br><span class="line">                     与 MPI 通信同时进行</span><br></pre></td></tr></table></figure><h2 id="cuda-aware-mpi" tabindex="-1" id="CUDA-Aware-MPI">CUDA-Aware MPI</h2><h3 id="chuan-tong-fang-shi-de-wen-ti" tabindex="-1" id="传统方式的问题">传统方式的问题</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 传统方式：必须经过主机内存</span></span><br><span class="line">cudaMemcpy(h_buf, d_buf, size, cudaMemcpyDeviceToHost);  <span class="comment">// GPU → CPU</span></span><br><span class="line">MPI_Send(h_buf, count, MPI_FLOAT, dest, tag, comm);       <span class="comment">// CPU → 网络</span></span><br><span class="line"><span class="comment">// 接收端</span></span><br><span class="line">MPI_Recv(h_buf, count, MPI_FLOAT, src, tag, comm, &amp;status);  <span class="comment">// 网络 → CPU  </span></span><br><span class="line">cudaMemcpy(d_buf, h_buf, size, cudaMemcpyHostToDevice);      <span class="comment">// CPU → GPU</span></span><br></pre></td></tr></table></figure><p><strong>问题</strong>：额外的内存拷贝开销。</p><h3 id="cuda-aware-mpi-1" tabindex="-1" id="CUDA-Aware-MPI-2">CUDA-Aware MPI</h3><p><strong>CUDA-Aware MPI</strong>：MPI 实现能直接识别 GPU 指针。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 直接传递 GPU 指针——不需要手动拷贝</span></span><br><span class="line">MPI_Send(d_buf, count, MPI_FLOAT, dest, tag, comm);</span><br><span class="line">MPI_Recv(d_buf, count, MPI_FLOAT, src, tag, comm, &amp;status);</span><br></pre></td></tr></table></figure><p>MPI 库自动处理：</p><ul><li>通过 GPUDirect RDMA 直接 GPU 到 GPU 传输</li><li>如果不支持，自动回退到经过主机的方式</li></ul><h3 id="huan-jing-pei-zhi" tabindex="-1" id="环境配置">环境配置</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 编译时链接 CUDA-Aware MPI</span></span><br><span class="line">mpicc -o my_prog my_prog.c -I<span class="variable">$&#123;CUDA_HOME&#125;</span>/include -L<span class="variable">$&#123;CUDA_HOME&#125;</span>/lib64 -lcudart</span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行前设置</span></span><br><span class="line"><span class="built_in">export</span> UCX_RNDV_SCHEME=cuda</span><br><span class="line"><span class="built_in">export</span> UCX_TLS=rc,cuda_copy,cuda_ipc</span><br></pre></td></tr></table></figure><h3 id="shi-yong-cuda-aware-mpi-gai-xie" tabindex="-1" id="使用-CUDA-Aware-MPI-改写">使用 CUDA-Aware MPI 改写</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 无需 host buffer，直接使用 device buffer</span></span><br><span class="line">MPI_Sendrecv(d_output + boundary_left, num_halo_points, MPI_FLOAT, left_neighbor, <span class="number">0</span>,</span><br><span class="line">             d_output + right_halo_offset, num_halo_points, MPI_FLOAT, right_neighbor, <span class="number">0</span>,</span><br><span class="line">             MPI_COMM_WORLD, &amp;status);</span><br></pre></td></tr></table></figure><p><strong>优势</strong>：</p><ul><li>减少内存拷贝</li><li>更低延迟</li><li>代码更简洁</li></ul><h2 id="shu-ju-fu-wu-qi-mo-shi" tabindex="-1" id="数据服务器模式">数据服务器模式</h2><h3 id="wen-ti-1" tabindex="-1" id="问题-2">问题</h3><p>大规模集群中，I/O 可能成为瓶颈。每个计算节点都从存储读数据会导致争用。</p><h3 id="jie-jue-fang-an-1" tabindex="-1" id="解决方案-2">解决方案</h3><p><strong>数据服务器模式</strong>：一个进程专门负责 I/O，其他进程专门计算。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">┌──────────────────────────────────────────────────────┐</span><br><span class="line">│  数据服务器 (Rank N-1)                               │</span><br><span class="line">│  - 读取输入数据                                      │</span><br><span class="line">│  - 分发数据给计算节点                                │</span><br><span class="line">│  - 收集计算结果                                      │</span><br><span class="line">│  - 写入输出                                          │</span><br><span class="line">└──────────────────────────────────────────────────────┘</span><br><span class="line">         ↓ 分发           ↑ 收集</span><br><span class="line">┌─────────┬─────────┬─────────┬─────────┐</span><br><span class="line">│ Rank 0  │ Rank 1  │ Rank 2  │   ...   │</span><br><span class="line">│ 计算    │ 计算    │ 计算    │         │</span><br><span class="line">└─────────┴─────────┴─────────┴─────────┘</span><br></pre></td></tr></table></figure><h3 id="shi-xian" tabindex="-1" id="实现">实现</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">data_server</span><span class="params">(<span class="type">int</span> dimx, <span class="type">int</span> dimy, <span class="type">int</span> dimz, <span class="type">int</span> nreps)</span> &#123;</span><br><span class="line">    <span class="type">int</span> np, num_comp_nodes;</span><br><span class="line">    MPI_Comm_size(MPI_COMM_WORLD, &amp;np);</span><br><span class="line">    num_comp_nodes = np - <span class="number">1</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 分配并初始化数据</span></span><br><span class="line">    <span class="type">float</span> *input = <span class="built_in">malloc</span>(dimx * dimy * dimz * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">    <span class="type">float</span> *output = <span class="built_in">malloc</span>(dimx * dimy * dimz * <span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">    initialize_data(input, dimx, dimy, dimz);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 计算每个节点的数据量</span></span><br><span class="line">    <span class="type">int</span> slice_per_node = dimz / num_comp_nodes;</span><br><span class="line">    <span class="type">int</span> halo_size = <span class="number">4</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 分发数据给计算节点</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> p = <span class="number">0</span>; p &lt; num_comp_nodes; p++) &#123;</span><br><span class="line">        <span class="type">int</span> start_z = p * slice_per_node - (p &gt; <span class="number">0</span> ? halo_size : <span class="number">0</span>);</span><br><span class="line">        <span class="type">int</span> num_slices = slice_per_node + (p &gt; <span class="number">0</span> ? halo_size : <span class="number">0</span>) </span><br><span class="line">                                        + (p &lt; num_comp_nodes - <span class="number">1</span> ? halo_size : <span class="number">0</span>);</span><br><span class="line">        <span class="type">int</span> num_points = dimx * dimy * num_slices;</span><br><span class="line">        </span><br><span class="line">        MPI_Send(input + start_z * dimx * dimy, num_points, MPI_FLOAT,</span><br><span class="line">                 p, <span class="number">0</span>, MPI_COMM_WORLD);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 等待计算完成</span></span><br><span class="line">    MPI_Barrier(MPI_COMM_WORLD);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 收集结果</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> p = <span class="number">0</span>; p &lt; num_comp_nodes; p++) &#123;</span><br><span class="line">        <span class="type">int</span> offset = p * slice_per_node * dimx * dimy;</span><br><span class="line">        <span class="type">int</span> num_points = slice_per_node * dimx * dimy;</span><br><span class="line">        </span><br><span class="line">        MPI_Recv(output + offset, num_points, MPI_FLOAT,</span><br><span class="line">                 p, DATA_COLLECT, MPI_COMM_WORLD, MPI_STATUS_IGNORE);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 保存结果</span></span><br><span class="line">    save_output(output, dimx, dimy, dimz);</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">free</span>(input);</span><br><span class="line">    <span class="built_in">free</span>(output);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="wan-zheng-shi-li-mpi-cuda-mo-ban-ji-suan" tabindex="-1" id="完整示例：MPI-CUDA-模板计算">完整示例：MPI + CUDA 模板计算</h2><h3 id="cheng-xu-jie-gou" tabindex="-1" id="程序结构">程序结构</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> *argv[])</span> &#123;</span><br><span class="line">    <span class="type">int</span> pid, np;</span><br><span class="line">    </span><br><span class="line">    MPI_Init(&amp;argc, &amp;argv);</span><br><span class="line">    MPI_Comm_rank(MPI_COMM_WORLD, &amp;pid);</span><br><span class="line">    MPI_Comm_size(MPI_COMM_WORLD, &amp;np);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (pid &lt; np - <span class="number">1</span>) &#123;</span><br><span class="line">        <span class="comment">// 计算节点：设置 GPU 并计算</span></span><br><span class="line">        <span class="type">int</span> device = pid % num_devices;</span><br><span class="line">        cudaSetDevice(device);</span><br><span class="line">        compute_node_stencil(dimx, dimy, dimz / (np - <span class="number">1</span>), nreps);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 数据服务器：I/O 和数据分发</span></span><br><span class="line">        data_server(dimx, dimy, dimz, nreps);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    MPI_Finalize();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="ji-suan-jie-dian-shi-xian" tabindex="-1" id="计算节点实现">计算节点实现</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">compute_node_stencil</span><span class="params">(<span class="type">int</span> dimx, <span class="type">int</span> dimy, <span class="type">int</span> dimz, <span class="type">int</span> nreps)</span> &#123;</span><br><span class="line">    <span class="type">int</span> pid, np;</span><br><span class="line">    MPI_Comm_rank(MPI_COMM_WORLD, &amp;pid);</span><br><span class="line">    MPI_Comm_size(MPI_COMM_WORLD, &amp;np);</span><br><span class="line">    </span><br><span class="line">    <span class="type">int</span> server = np - <span class="number">1</span>;</span><br><span class="line">    <span class="type">int</span> left_neighbor = (pid &gt; <span class="number">0</span>) ? (pid - <span class="number">1</span>) : MPI_PROC_NULL;</span><br><span class="line">    <span class="type">int</span> right_neighbor = (pid &lt; np - <span class="number">2</span>) ? (pid + <span class="number">1</span>) : MPI_PROC_NULL;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 分配内存</span></span><br><span class="line">    <span class="type">int</span> halo = <span class="number">4</span>;</span><br><span class="line">    <span class="type">int</span> total_z = dimz + <span class="number">2</span> * halo;</span><br><span class="line">    <span class="type">size_t</span> num_bytes = dimx * dimy * total_z * <span class="keyword">sizeof</span>(<span class="type">float</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="type">float</span> *h_input = <span class="built_in">malloc</span>(num_bytes);</span><br><span class="line">    <span class="type">float</span> *h_output = <span class="built_in">malloc</span>(num_bytes);</span><br><span class="line">    <span class="type">float</span> *d_input, *d_output;</span><br><span class="line">    cudaMalloc(&amp;d_input, num_bytes);</span><br><span class="line">    cudaMalloc(&amp;d_output, num_bytes);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Halo 缓冲区（固定内存，加速传输）</span></span><br><span class="line">    <span class="type">float</span> *h_left_boundary, *h_right_boundary;</span><br><span class="line">    <span class="type">float</span> *h_left_halo, *h_right_halo;</span><br><span class="line">    <span class="type">size_t</span> halo_bytes = dimx * dimy * halo * <span class="keyword">sizeof</span>(<span class="type">float</span>);</span><br><span class="line">    cudaHostAlloc(&amp;h_left_boundary, halo_bytes, cudaHostAllocDefault);</span><br><span class="line">    cudaHostAlloc(&amp;h_right_boundary, halo_bytes, cudaHostAllocDefault);</span><br><span class="line">    cudaHostAlloc(&amp;h_left_halo, halo_bytes, cudaHostAllocDefault);</span><br><span class="line">    cudaHostAlloc(&amp;h_right_halo, halo_bytes, cudaHostAllocDefault);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 创建 CUDA 流</span></span><br><span class="line">    cudaStream_t stream_boundary, stream_internal;</span><br><span class="line">    cudaStreamCreate(&amp;stream_boundary);</span><br><span class="line">    cudaStreamCreate(&amp;stream_internal);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 从数据服务器接收初始数据</span></span><br><span class="line">    MPI_Status status;</span><br><span class="line">    MPI_Recv(h_input, dimx * dimy * total_z, MPI_FLOAT,</span><br><span class="line">             server, MPI_ANY_TAG, MPI_COMM_WORLD, &amp;status);</span><br><span class="line">    cudaMemcpy(d_input, h_input, num_bytes, cudaMemcpyHostToDevice);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 迭代计算</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> iter = <span class="number">0</span>; iter &lt; nreps; iter++) &#123;</span><br><span class="line">        <span class="comment">// 阶段 1：边界计算</span></span><br><span class="line">        launch_boundary_kernel(d_output, d_input, dimx, dimy, stream_boundary);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 阶段 2：内部计算（与通信重叠）</span></span><br><span class="line">        launch_internal_kernel(d_output, d_input, dimx, dimy, dimz, stream_internal);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 复制边界到主机</span></span><br><span class="line">        copy_boundary_to_host(d_output, h_left_boundary, h_right_boundary,</span><br><span class="line">                               dimx, dimy, halo, stream_boundary);</span><br><span class="line">        cudaStreamSynchronize(stream_boundary);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// Halo 交换</span></span><br><span class="line">        MPI_Sendrecv(h_left_boundary, dimx * dimy * halo, MPI_FLOAT, left_neighbor, iter,</span><br><span class="line">                     h_right_halo, dimx * dimy * halo, MPI_FLOAT, right_neighbor, iter,</span><br><span class="line">                     MPI_COMM_WORLD, &amp;status);</span><br><span class="line">        MPI_Sendrecv(h_right_boundary, dimx * dimy * halo, MPI_FLOAT, right_neighbor, iter,</span><br><span class="line">                     h_left_halo, dimx * dimy * halo, MPI_FLOAT, left_neighbor, iter,</span><br><span class="line">                     MPI_COMM_WORLD, &amp;status);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 复制 Halo 回 GPU</span></span><br><span class="line">        copy_halo_to_device(d_output, h_left_halo, h_right_halo,</span><br><span class="line">                             dimx, dimy, dimz, halo, stream_boundary);</span><br><span class="line">        </span><br><span class="line">        cudaDeviceSynchronize();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 交换输入输出指针</span></span><br><span class="line">        <span class="type">float</span> *temp = d_output;</span><br><span class="line">        d_output = d_input;</span><br><span class="line">        d_input = temp;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 发送结果给数据服务器</span></span><br><span class="line">    cudaMemcpy(h_output, d_input, num_bytes, cudaMemcpyDeviceToHost);</span><br><span class="line">    MPI_Send(h_output + dimx * dimy * halo, dimx * dimy * dimz, MPI_FLOAT,</span><br><span class="line">             server, DATA_COLLECT, MPI_COMM_WORLD);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 清理</span></span><br><span class="line">    <span class="built_in">free</span>(h_input);</span><br><span class="line">    <span class="built_in">free</span>(h_output);</span><br><span class="line">    cudaFreeHost(h_left_boundary);</span><br><span class="line">    cudaFreeHost(h_right_boundary);</span><br><span class="line">    cudaFreeHost(h_left_halo);</span><br><span class="line">    cudaFreeHost(h_right_halo);</span><br><span class="line">    cudaFree(d_input);</span><br><span class="line">    cudaFree(d_output);</span><br><span class="line">    cudaStreamDestroy(stream_boundary);</span><br><span class="line">    cudaStreamDestroy(stream_internal);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="xing-neng-you-hua" tabindex="-1" id="性能优化">性能优化</h2><h3 id="tong-xin-you-hua" tabindex="-1" id="通信优化">通信优化</h3><table><thead><tr><th>技术</th><th>描述</th><th>效果</th></tr></thead><tbody><tr><td>非阻塞通信</td><td>使用 <code>MPI_Isend</code>/<code>MPI_Irecv</code></td><td>重叠通信与计算</td></tr><tr><td>集合通信</td><td>使用 <code>MPI_Allreduce</code> 而非循环 P2P</td><td>利用优化的算法</td></tr><tr><td>CUDA-Aware MPI</td><td>直接传递 GPU 指针</td><td>减少内存拷贝</td></tr><tr><td>固定内存</td><td><code>cudaHostAlloc</code></td><td>加速 H2D/D2H 传输</td></tr></tbody></table><h3 id="fu-zai-jun-heng" tabindex="-1" id="负载均衡">负载均衡</h3><p>确保每个节点的工作量大致相等：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 处理不能整除的情况</span></span><br><span class="line"><span class="type">int</span> base_slices = dimz / num_nodes;</span><br><span class="line"><span class="type">int</span> remainder = dimz % num_nodes;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> p = <span class="number">0</span>; p &lt; num_nodes; p++) &#123;</span><br><span class="line">    <span class="type">int</span> slices = base_slices + (p &lt; remainder ? <span class="number">1</span> : <span class="number">0</span>);</span><br><span class="line">    <span class="comment">// 分配 slices 给节点 p</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="ke-kuo-zhan-xing-fen-xi" tabindex="-1" id="可扩展性分析">可扩展性分析</h3><p>对于 25 点模板计算：</p><table><thead><tr><th>节点数</th><th>通信量（每节点）</th><th>计算量（每节点）</th><th>计算/通信比</th></tr></thead><tbody><tr><td>16</td><td>2×64×64×4 = 32K</td><td>64×64×128 = 512K</td><td>16:1</td></tr><tr><td>64</td><td>2×64×64×4 = 32K</td><td>64×64×32 = 128K</td><td>4:1</td></tr><tr><td>256</td><td>2×64×64×4 = 32K</td><td>64×64×8 = 32K</td><td>1:1</td></tr></tbody></table><p><strong>观察</strong>：节点越多，通信开销占比越高。这是<strong>强扩展</strong>的典型特征。</p><h2 id="chang-jian-wen-ti-yu-jie-jue" tabindex="-1" id="常见问题与解决">常见问题与解决</h2><h3 id="si-suo" tabindex="-1" id="死锁">死锁</h3><p><strong>原因</strong>：所有进程都在等待接收，没有进程发送。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 错误示例——会死锁！</span></span><br><span class="line"><span class="keyword">if</span> (rank == <span class="number">0</span>) &#123;</span><br><span class="line">    MPI_Recv(..., <span class="number">1</span>, ...);  <span class="comment">// 等待 rank 1</span></span><br><span class="line">    MPI_Send(..., <span class="number">1</span>, ...);</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    MPI_Recv(..., <span class="number">0</span>, ...);  <span class="comment">// 等待 rank 0</span></span><br><span class="line">    MPI_Send(..., <span class="number">0</span>, ...);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>解决</strong>：使用 <code>MPI_Sendrecv</code> 或非阻塞通信。</p><h3 id="gpu-nei-cun-bu-zu" tabindex="-1" id="GPU-内存不足">GPU 内存不足</h3><p><strong>原因</strong>：每个节点分配的数据太多。</p><p><strong>解决</strong>：</p><ul><li>增加节点数</li><li>使用统一内存自动管理</li><li>分批处理</li></ul><h3 id="xing-neng-bu-jia" tabindex="-1" id="性能不佳">性能不佳</h3><p><strong>诊断</strong>：使用 Nsight Systems 分析 MPI + CUDA 程序。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nsys profile --trace=cuda,mpi mpirun -np 4 ./my_program</span><br></pre></td></tr></table></figure><p>查看是否有：</p><ul><li>过长的 MPI 等待时间</li><li>未重叠的计算和通信</li><li>GPU 空闲时间</li></ul><h2 id="xiao-jie" tabindex="-1" id="小结">小结</h2><p>第二十章扩展了并行编程的视野，从单 GPU 扩展到多节点集群：</p><p><strong>异构集群架构</strong>：每个节点包含 CPU 和 GPU，节点间通过网络连接。分布式内存模型要求显式通信。</p><p><strong>MPI 基础</strong>：消息传递编程模型。进程通过发送/接收消息通信。点对点通信（Send/Recv）和集合通信（Broadcast/Reduce）。</p><p><strong>MPI + CUDA</strong>：每个 MPI 进程管理一个或多个 GPU。数据在主机内存和 GPU 内存之间传输，在进程间通过 MPI 传输。</p><p><strong>Halo 交换</strong>：模板计算中，边界数据需要与邻居进程交换。使用 Sendrecv 避免死锁。</p><p><strong>计算与通信重叠</strong>：利用 CUDA 流，边界计算完成后立即开始通信，同时进行内部计算。显著减少总执行时间。</p><p><strong>CUDA-Aware MPI</strong>：MPI 库直接接受 GPU 指针，利用 GPUDirect 技术减少内存拷贝。</p><p><strong>数据服务器模式</strong>：一个进程专门负责 I/O，减少存储争用。</p><p>掌握 MPI + CUDA 编程，你就能编写可扩展到数千 GPU 的应用程序——这是当今 AI 训练、科学计算、天气预报等领域的核心技术。</p><h2 id="xia-yi-bu" tabindex="-1" id="🚀-下一步">🚀 下一步</h2><ul><li>搭建一个简单的多节点 GPU 集群环境，配置 MPI 和 CUDA-Aware MPI</li><li>实现一个分布式矩阵乘法，学习数据分割和结果收集</li><li>掌握 Halo 交换模式，实现分布式模板计算（如热传导方程）</li><li>学习集合通信操作：Allreduce、Allgather、Alltoall</li><li>探索性能分析工具：Nsight Systems 分析 MPI + CUDA 程序的性能瓶颈</li><li>了解现代 HPC 框架：NCCL（多 GPU 通信）、Horovod（分布式深度学习）</li></ul><hr><h2 id="can-kao-zi-liao" tabindex="-1" id="📚-参考资料">📚 参考资料</h2><ul><li>PMPP 第四版 Chapter 20</li><li><a href="https://smarter.xin/posts/pmmpp-chapter20-heterogeneous-clusters/">第二十章：异构计算集群编程</a></li><li>Hwu, W., Kirk, D., &amp; El Hajj, I. (2022). <em>Programming Massively Parallel Processors: A Hands-on Approach</em> (4th Edition). Morgan Kaufmann.</li><li>MPI Forum. <em>MPI: A Message-Passing Interface Standard</em>. <a href="https://www.mpi-forum.org/">https://www.mpi-forum.org/</a></li><li>NVIDIA. <em>CUDA-Aware MPI</em>. <a href="https://developer.nvidia.com/blog/introduction-cuda-aware-mpi/">https://developer.nvidia.com/blog/introduction-cuda-aware-mpi/</a></li></ul><p><strong>学习愉快！</strong> 🎓</p><hr><blockquote><p><strong>本文 GitHub 仓库</strong>: <a href="https://github.com/psmarter/PMPP-Learning">https://github.com/psmarter/PMPP-Learning</a></p></blockquote>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h2 id=&quot;qian-yan&quot; tabindex=&quot;-1&quot; id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;第十九章总结了并行编程的思维方法。第二十章将视野扩展到&lt;strong&gt;计算集群（Computing</summary>
        
      
    
    
    
    <category term="知识分享" scheme="https://smarter.xin/categories/knowledge-sharing/"/>
    
    
    <category term="CUDA" scheme="https://smarter.xin/tags/CUDA/"/>
    
    <category term="GPU编程" scheme="https://smarter.xin/tags/gpu-programming/"/>
    
    <category term="并行计算" scheme="https://smarter.xin/tags/parallel-computing/"/>
    
    <category term="PMPP" scheme="https://smarter.xin/tags/PMPP/"/>
    
    <category term="MPI" scheme="https://smarter.xin/tags/MPI/"/>
    
    <category term="集群计算" scheme="https://smarter.xin/tags/cluster-computing/"/>
    
    <category term="CUDA流" scheme="https://smarter.xin/tags/cuda-stream/"/>
    
    <category term="分布式计算" scheme="https://smarter.xin/tags/distributed-computing/"/>
    
  </entry>
  
  <entry>
    <title>PMPP-第十九章：并行编程与计算思维</title>
    <link href="https://smarter.xin/posts/46b3d994/"/>
    <id>https://smarter.xin/posts/46b3d994/</id>
    <published>2026-01-24T04:29:59.000Z</published>
    <updated>2026-01-24T11:47:21.463Z</updated>
    
    <content type="html"><![CDATA[<h2 id="qian-yan" tabindex="-1" id="前言">前言</h2><p>经过前十八章的学习，我们掌握了 CUDA 编程的各种技术细节。第十九章是全书的总结与升华，从&quot;术&quot;上升到&quot;道&quot;——<strong>计算思维（Computational Thinking）</strong>。本章不再讲解具体的 API 或优化技巧，而是讨论<strong>如何思考并行问题</strong>、<strong>如何设计并行算法</strong>、<strong>如何权衡各种因素</strong>。这些思维方式将帮助读者应对未来的各种并行计算挑战。</p><blockquote><p><strong>📦 配套资源</strong>：本系列文章配有完整的 <a href="https://github.com/psmarter/PMPP-Learning">GitHub 仓库</a>，包含每章的练习题解答、CUDA 代码实现和详细注释。所有代码都经过测试，可以直接运行。</p></blockquote><h2 id="shi-yao-shi-ji-suan-si-wei" tabindex="-1" id="什么是计算思维">什么是计算思维</h2><h3 id="ding-yi" tabindex="-1" id="定义">定义</h3><p><strong>计算思维</strong>：用计算机科学的基本概念来解决问题、设计系统、理解人类行为。</p><p>——Jeannette Wing, 2006</p><p>在并行计算语境下，计算思维包括：</p><ul><li>识别问题的并行性</li><li>分解任务与数据</li><li>设计高效的通信模式</li><li>权衡各种资源约束</li></ul><h3 id="wei-shi-yao-zhong-yao" tabindex="-1" id="为什么重要">为什么重要</h3><p>硬件在变，但思维方式持久。</p><ul><li>CUDA 可能被其他技术取代</li><li>但并行思维的核心原则不变</li><li>掌握思维方式 &gt; 记住 API</li></ul><h2 id="wen-ti-fen-jie" tabindex="-1" id="问题分解">问题分解</h2><h3 id="ren-wu-bing-xing-vs-shu-ju-bing-xing" tabindex="-1" id="任务并行-vs-数据并行">任务并行 vs 数据并行</h3><p><strong>任务并行（Task Parallelism）</strong>：</p><ul><li>不同的处理器执行不同的任务</li><li>适合异构任务</li><li>例：流水线处理</li></ul><p><strong>数据并行（Data Parallelism）</strong>：</p><ul><li>相同的操作应用到不同的数据</li><li>适合同构任务</li><li>例：向量加法、矩阵乘法</li></ul><p><strong>GPU 偏好数据并行</strong>：</p><ul><li>SIMT 模型天然支持</li><li>数千线程执行相同代码</li><li>分支发散会降低效率</li></ul><h3 id="fen-jie-ce-lue" tabindex="-1" id="分解策略">分解策略</h3><p><strong>输出驱动</strong>：每个线程负责计算一个输出元素</p><ul><li>适合输出位置确定的问题</li><li>例：矩阵乘法、图像滤波</li></ul><p><strong>输入驱动</strong>：每个线程处理一个输入元素</p><ul><li>适合输出需要聚合的问题</li><li>例：直方图、归约</li></ul><p><strong>混合</strong>：根据问题特性灵活选择</p><ul><li>例：稀疏矩阵——每行一个线程或每 Warp 一行</li></ul><h2 id="suan-fa-she-ji-mo-shi" tabindex="-1" id="算法设计模式">算法设计模式</h2><h3 id="chang-jian-bing-xing-mo-shi" tabindex="-1" id="常见并行模式">常见并行模式</h3><p>经过前面章节的学习，你已经见过这些经典模式：</p><table><thead><tr><th>模式</th><th>描述</th><th>示例</th></tr></thead><tbody><tr><td>Map</td><td>一对一变换</td><td>ReLU、标量乘法</td></tr><tr><td>Reduce</td><td>多对一聚合</td><td>求和、最大值</td></tr><tr><td>Scan</td><td>前缀操作</td><td>流压缩、基数排序</td></tr><tr><td>Stencil</td><td>邻域模式</td><td>卷积、PDE 求解</td></tr><tr><td>Gather</td><td>间接读取</td><td>查表、稀疏访问</td></tr><tr><td>Scatter</td><td>间接写入</td><td>直方图、排序分桶</td></tr></tbody></table><h3 id="mo-shi-zu-he" tabindex="-1" id="模式组合">模式组合</h3><p>复杂算法通常是基本模式的组合：</p><p><strong>基数排序</strong> = Histogram + Scan + Scatter</p><p><strong>稀疏矩阵-向量乘</strong> = Gather + Reduce</p><p><strong>BFS</strong> = Gather + Scatter + Reduce</p><p>识别这些模式有助于快速设计并行算法。</p><h2 id="xing-neng-you-hua-si-wei" tabindex="-1" id="性能优化思维">性能优化思维</h2><h3 id="ping-jing-fen-xi" tabindex="-1" id="瓶颈分析">瓶颈分析</h3><p>任何程序都有瓶颈，优化要找对方向：</p><p><strong>计算瓶颈</strong>：</p><ul><li>算术操作是限制因素</li><li>优化：减少操作数、使用快速数学函数</li></ul><p><strong>内存瓶颈</strong>：</p><ul><li>数据传输是限制因素</li><li>优化：提高缓存利用、减少访问次数</li></ul><p><strong>延迟瓶颈</strong>：</p><ul><li>等待时间是限制因素</li><li>优化：增加并行度隐藏延迟</li></ul><h3 id="roofline-mo-xing" tabindex="-1" id="Roofline-模型">Roofline 模型</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">性能 = min(峰值算力, 带宽 × 算术强度)</span><br></pre></td></tr></table></figure><p><strong>算术强度</strong> = FLOP / Byte</p><table><thead><tr><th>算术强度</th><th>瓶颈类型</th><th>优化方向</th></tr></thead><tbody><tr><td>&lt; 10</td><td>内存受限</td><td>提高数据复用</td></tr><tr><td>&gt; 10</td><td>计算受限</td><td>优化计算效率</td></tr></tbody></table><h3 id="you-hua-ceng-ci" tabindex="-1" id="优化层次">优化层次</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">┌─────────────────────────────────────────┐</span><br><span class="line">│ 第四层：算法层                           │</span><br><span class="line">│   选择更高效的算法                       │</span><br><span class="line">│   减少总操作数                           │</span><br><span class="line">├─────────────────────────────────────────┤</span><br><span class="line">│ 第三层：并行策略层                       │</span><br><span class="line">│   任务分解方式                           │</span><br><span class="line">│   负载均衡                               │</span><br><span class="line">├─────────────────────────────────────────┤</span><br><span class="line">│ 第二层：内存层                           │</span><br><span class="line">│   全局/共享/寄存器的使用                 │</span><br><span class="line">│   访问模式优化                           │</span><br><span class="line">├─────────────────────────────────────────┤</span><br><span class="line">│ 第一层：指令层                           │</span><br><span class="line">│   循环展开                               │</span><br><span class="line">│   指令级并行                             │</span><br><span class="line">└─────────────────────────────────────────┘</span><br></pre></td></tr></table></figure><p><strong>从上往下优化</strong>：算法级改进的收益最大。</p><h2 id="quan-heng-yu-jue-ce" tabindex="-1" id="权衡与决策">权衡与决策</h2><h3 id="chang-jian-quan-heng" tabindex="-1" id="常见权衡">常见权衡</h3><p><strong>1. 并行度 vs 冗余计算</strong></p><p>增加并行度可能需要冗余计算：</p><ul><li>Tiling 需要 Halo 区域重叠</li><li>归约需要额外的合并操作</li></ul><p><strong>2. 内存使用 vs 计算效率</strong></p><ul><li>预计算查找表：省计算，费内存</li><li>实时计算：省内存，费计算</li></ul><p><strong>3. 通用性 vs 专用优化</strong></p><ul><li>通用代码易维护</li><li>专用优化性能好</li><li>模板/代码生成可以兼顾</li></ul><h3 id="jue-ce-kuang-jia" tabindex="-1" id="决策框架">决策框架</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">1. 理解问题</span><br><span class="line">   - 输入/输出特性</span><br><span class="line">   - 计算密度</span><br><span class="line">   - 数据依赖</span><br><span class="line"></span><br><span class="line">2. 选择算法</span><br><span class="line">   - 理论复杂度</span><br><span class="line">   - 并行友好度</span><br><span class="line">   - 实现复杂度</span><br><span class="line"></span><br><span class="line">3. 设计并行策略</span><br><span class="line">   - 分解方式</span><br><span class="line">   - 同步需求</span><br><span class="line">   - 通信模式</span><br><span class="line"></span><br><span class="line">4. 实现与优化</span><br><span class="line">   - 先正确，后优化</span><br><span class="line">   - Profile 驱动</span><br><span class="line">   - 迭代改进</span><br></pre></td></tr></table></figure><h2 id="ke-kuo-zhan-xing-si-wei" tabindex="-1" id="可扩展性思维">可扩展性思维</h2><h3 id="qiang-kuo-zhan-yu-ruo-kuo-zhan" tabindex="-1" id="强扩展与弱扩展">强扩展与弱扩展</h3><p><strong>强扩展（Strong Scaling）</strong>：</p><ul><li>问题规模固定</li><li>增加处理器，减少时间</li><li>受 Amdahl 定律限制</li></ul><p><strong>弱扩展（Weak Scaling）</strong>：</p><ul><li>每处理器负载固定</li><li>增加处理器，处理更大问题</li><li>受 Gustafson 定律指导</li></ul><h3 id="amdahl-ding-lu" tabindex="-1" id="Amdahl-定律">Amdahl 定律</h3><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>加速比</mtext><mo>=</mo><mfrac><mn>1</mn><mrow><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>P</mi><mo stretchy="false">)</mo><mo>+</mo><mfrac><mi>P</mi><mi>N</mi></mfrac></mrow></mfrac></mrow><annotation encoding="application/x-tex">加速比 = \frac{1}{(1-P) + \frac{P}{N}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord cjk_fallback">加速比</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4288em;vertical-align:-1.1073em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.2377em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8723em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.1073em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><p>其中 P 是可并行部分比例，N 是处理器数。</p><p><strong>启示</strong>：串行部分决定加速上限。</p><p><strong>例</strong>：95% 可并行，最大加速比 = 20×（无论多少 GPU）</p><h3 id="gustafson-ding-lu" tabindex="-1" id="Gustafson-定律">Gustafson 定律</h3><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>加速比</mtext><mo>=</mo><mi>N</mi><mo>−</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>P</mi><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>N</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">加速比 = N - (1-P)(N-1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord cjk_fallback">加速比</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mclose">)</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span></span></p><p><strong>启示</strong>：增大问题规模可以提高并行效率。</p><p><strong>例</strong>：95% 可并行，100 GPU，加速比 = 95×</p><h2 id="diao-shi-yu-yan-zheng" tabindex="-1" id="调试与验证">调试与验证</h2><h3 id="bing-xing-cheng-xu-diao-shi-tiao-zhan" tabindex="-1" id="并行程序调试挑战">并行程序调试挑战</h3><ul><li><strong>不确定性</strong>：竞态条件导致结果不可重复</li><li><strong>规模</strong>：数千线程难以逐一追踪</li><li><strong>隐蔽性</strong>：边界情况难以触发</li></ul><h3 id="ce-lue" tabindex="-1" id="策略">策略</h3><p><strong>1. 简化问题</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">先在小规模数据上测试</span><br><span class="line">1 个 Block → 多 Block</span><br><span class="line">1 个 Warp → 多 Warp</span><br></pre></td></tr></table></figure><p><strong>2. 串行参考</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 总是保留串行版本用于验证</span></span><br><span class="line"><span class="type">float</span> result_cpu = compute_cpu(data, n);</span><br><span class="line"><span class="type">float</span> result_gpu = compute_gpu(data, n);</span><br><span class="line">assert(<span class="built_in">abs</span>(result_cpu - result_gpu) &lt; epsilon);</span><br></pre></td></tr></table></figure><p><strong>3. 使用工具</strong></p><table><thead><tr><th>工具</th><th>用途</th></tr></thead><tbody><tr><td>cuda-memcheck</td><td>内存错误检测</td></tr><tr><td>Nsight Compute</td><td>性能分析</td></tr><tr><td>Nsight Systems</td><td>系统级分析</td></tr><tr><td>printf</td><td>简单调试（慎用）</td></tr></tbody></table><p><strong>4. 渐进式开发</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. 实现朴素版本，验证正确性</span><br><span class="line">2. 添加一个优化，验证正确性</span><br><span class="line">3. 重复直到满足性能需求</span><br></pre></td></tr></table></figure><h2 id="kua-ping-tai-si-wei" tabindex="-1" id="跨平台思维">跨平台思维</h2><h3 id="ying-jian-duo-yang-xing" tabindex="-1" id="硬件多样性">硬件多样性</h3><p>不同 GPU 架构有不同特性：</p><table><thead><tr><th>特性</th><th>Kepler</th><th>Pascal</th><th>Volta</th><th>Ampere</th></tr></thead><tbody><tr><td>SM 内存(KB)</td><td>64</td><td>64</td><td>96</td><td>164</td></tr><tr><td>L2 缓存(MB)</td><td>1.5</td><td>4</td><td>6</td><td>40</td></tr><tr><td>Tensor Core</td><td>无</td><td>无</td><td>有</td><td>有</td></tr></tbody></table><p><strong>策略</strong>：</p><ul><li>使用运行时查询能力</li><li>参数化关键常量</li><li>针对目标硬件调优</li></ul><h3 id="ke-yi-zhi-xing" tabindex="-1" id="可移植性">可移植性</h3><p><strong>CUDA 之外</strong>：</p><ul><li>OpenCL：跨厂商</li><li>SYCL：C++ 标准化</li><li>HIP：AMD GPU</li></ul><p><strong>抽象库</strong>：</p><ul><li>Thrust：STL 风格</li><li>CUB：低级原语</li><li>cuBLAS/cuDNN：领域特定</li></ul><h2 id="chi-xu-xue-xi" tabindex="-1" id="持续学习">持续学习</h2><h3 id="ji-zhu-yan-jin" tabindex="-1" id="技术演进">技术演进</h3><p>GPU 技术快速发展：</p><p><strong>过去</strong>：可编程着色器 → CUDA 诞生<br><strong>现在</strong>：Tensor Core、光线追踪<br><strong>未来</strong>：量子模拟？神经形态计算？</p><p><strong>保持学习</strong>：</p><ul><li>阅读最新论文</li><li>关注 GTC 大会</li><li>参与开源项目</li></ul><h3 id="she-qu-zi-yuan" tabindex="-1" id="社区资源">社区资源</h3><ul><li><strong>NVIDIA Developer Blog</strong>：技术文章</li><li><strong>CUDA Zone</strong>：官方资源</li><li><strong>GitHub</strong>：开源项目</li><li><strong>Stack Overflow</strong>：问题解答</li><li><strong>课程</strong>：UIUC、Stanford 公开课</li></ul><h2 id="zong-jie-bing-xing-bian-cheng-xin-fa" tabindex="-1" id="总结：并行编程心法">总结：并行编程心法</h2><h3 id="shi-tiao-yuan-ze" tabindex="-1" id="十条原则">十条原则</h3><ol><li><p><strong>理解硬件</strong>：了解你的 GPU 架构，扬长避短</p></li><li><p><strong>数据为王</strong>：并行程序性能通常受限于数据移动</p></li><li><p><strong>最大化并行</strong>：暴露足够的并行性隐藏延迟</p></li><li><p><strong>最小化同步</strong>：同步是性能杀手</p></li><li><p><strong>合并访问</strong>：让内存访问连续</p></li><li><p><strong>复用数据</strong>：共享内存是你最好的朋友</p></li><li><p><strong>避免发散</strong>：让同一 Warp 的线程走相同路径</p></li><li><p><strong>权衡取舍</strong>：没有银弹，只有适合具体问题的解</p></li><li><p><strong>Profile 优先</strong>：数据驱动优化，不要猜测</p></li><li><p><strong>渐进迭代</strong>：先正确，后优化，持续改进</p></li></ol><h3 id="cong-ji-zhu-dao-si-wei" tabindex="-1" id="从技术到思维">从技术到思维</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">初学者：学习 API 和语法</span><br><span class="line">         ↓</span><br><span class="line">进阶者：掌握优化技巧</span><br><span class="line">         ↓</span><br><span class="line">高手：形成并行思维</span><br><span class="line">         ↓</span><br><span class="line">专家：能设计新算法</span><br></pre></td></tr></table></figure><p>这本书带你走完了前两个阶段，后两个阶段需要通过实践和持续学习来达成。</p><h2 id="xiao-jie" tabindex="-1" id="小结">小结</h2><p>第十九章是全书的升华，总结了并行编程的核心思维：</p><p><strong>计算思维</strong>：用计算的视角看问题——分解、模式匹配、抽象、算法设计。</p><p><strong>问题分解</strong>：任务并行 vs 数据并行，输出驱动 vs 输入驱动。根据问题特性选择。</p><p><strong>设计模式</strong>：Map、Reduce、Scan、Stencil、Gather、Scatter——识别这些模式能快速构建解决方案。</p><p><strong>性能思维</strong>：瓶颈分析、Roofline 模型、分层优化。从算法层开始，逐层向下。</p><p><strong>权衡决策</strong>：没有完美方案，只有最适合当前约束的方案。理解各种权衡才能做出好决策。</p><p><strong>可扩展性</strong>：Amdahl vs Gustafson，强扩展 vs 弱扩展。理解极限有助于设定合理预期。</p><p>CUDA 只是工具，思维方式才是核心竞争力。希望这本书不仅教会你 CUDA 编程，更培养了你的并行计算思维。</p><hr><p><strong>参考资料：</strong></p><ul><li>Hwu, W., Kirk, D., &amp; El Hajj, I. (2022). <em>Programming Massively Parallel Processors: A Hands-on Approach</em> (4th Edition). Morgan Kaufmann.</li><li>Wing, J. M. (2006). <em>Computational Thinking</em>. Communications of the ACM.</li><li>Williams, S., et al. (2009). <em>Roofline: An Insightful Visual Performance Model</em>. Communications of the ACM.</li></ul><hr><blockquote><p><strong>本文 GitHub 仓库</strong>: <a href="https://github.com/psmarter/PMPP-Learning">https://github.com/psmarter/PMPP-Learning</a></p></blockquote>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h2 id=&quot;qian-yan&quot; tabindex=&quot;-1&quot; id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;经过前十八章的学习，我们掌握了 CUDA</summary>
        
      
    
    
    
    <category term="知识分享" scheme="https://smarter.xin/categories/knowledge-sharing/"/>
    
    
    <category term="CUDA" scheme="https://smarter.xin/tags/CUDA/"/>
    
    <category term="GPU编程" scheme="https://smarter.xin/tags/gpu-programming/"/>
    
    <category term="并行计算" scheme="https://smarter.xin/tags/parallel-computing/"/>
    
    <category term="PMPP" scheme="https://smarter.xin/tags/PMPP/"/>
    
    <category term="性能优化" scheme="https://smarter.xin/tags/performance-optimization/"/>
    
    <category term="计算思维" scheme="https://smarter.xin/tags/computational-thinking/"/>
    
    <category term="方法论" scheme="https://smarter.xin/tags/methodology/"/>
    
  </entry>
  
  <entry>
    <title>PMPP-第十八章：静电势能图</title>
    <link href="https://smarter.xin/posts/d7c6e6a8/"/>
    <id>https://smarter.xin/posts/d7c6e6a8/</id>
    <published>2026-01-23T02:05:17.000Z</published>
    <updated>2026-01-24T11:47:21.463Z</updated>
    
    <content type="html"><![CDATA[<h2 id="qian-yan" tabindex="-1" id="前言">前言</h2><p>第十七章探索了 MRI 重建这一医学影像应用。第十八章转向另一个重要的科学计算领域——<strong>分子动力学（Molecular Dynamics）<strong>中的静电势能计算。静电相互作用是分子模拟的核心，理解分子如何通过电荷相互作用，对药物设计、蛋白质折叠研究等具有重要意义。本章将展示如何利用 GPU 的并行能力高效计算</strong>静电势能图（Electrostatic Potential Map）</strong>。</p><blockquote><p><strong>📦 配套资源</strong>：本系列文章配有完整的 <a href="https://github.com/psmarter/PMPP-Learning">GitHub 仓库</a>，包含每章的练习题解答、CUDA 代码实现和详细注释。所有代码都经过测试，可以直接运行。</p></blockquote><h2 id="jing-dian-shi-neng-ji-chu" tabindex="-1" id="静电势能基础">静电势能基础</h2><h3 id="ku-lun-ding-lu" tabindex="-1" id="库仑定律">库仑定律</h3><p>两个点电荷之间的静电势能：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>V</mi><mo>=</mo><mfrac><mrow><mi>k</mi><mo>⋅</mo><mi>q</mi></mrow><mi>r</mi></mfrac></mrow><annotation encoding="application/x-tex">V = \frac{k \cdot q}{r}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.0574em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><p>其中：</p><ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span>：库仑常数</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span></span></span></span>：电荷量</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span>：距离</li></ul><h3 id="fen-zi-zhong-de-jing-dian-shi-neng" tabindex="-1" id="分子中的静电势能">分子中的静电势能</h3><p>一个分子由多个原子组成，每个原子携带部分电荷。空间中任意一点的静电势是所有原子贡献的总和：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>V</mi><mo stretchy="false">(</mo><mi mathvariant="bold">p</mi><mo stretchy="false">)</mo><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mfrac><mrow><mi>k</mi><mo>⋅</mo><msub><mi>q</mi><mi>i</mi></msub></mrow><mrow><mi mathvariant="normal">∣</mi><mi mathvariant="bold">p</mi><mo>−</mo><msub><mi mathvariant="bold">r</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">V(\mathbf{p}) = \sum_{i=1}^{N} \frac{k \cdot q_i}{|\mathbf{p} - \mathbf{r}_i|}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mopen">(</span><span class="mord mathbf">p</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.106em;vertical-align:-1.2777em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">∣</span><span class="mord mathbf">p</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathbf">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><p>其中：</p><ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">p</mi></mrow><annotation encoding="application/x-tex">\mathbf{p}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.1944em;"></span><span class="mord mathbf">p</span></span></span></span>：空间中的网格点</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">r</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{r}_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5944em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathbf">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>：第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span> 个原子的位置</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">q_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>：第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span> 个原子的部分电荷</li></ul><h3 id="jing-dian-shi-neng-tu" tabindex="-1" id="静电势能图">静电势能图</h3><p><strong>静电势能图</strong>：在分子周围的 3D 网格上，计算每个网格点的静电势能值。</p><p>典型规模：</p><ul><li>网格：256³ = 1670 万个点</li><li>原子：数千到数万个</li></ul><p><strong>计算量</strong>：网格点数 × 原子数 = 数千亿次运算</p><h2 id="zhi-jie-qiu-he-fa" tabindex="-1" id="直接求和法">直接求和法</h2><h3 id="ji-ben-suan-fa" tabindex="-1" id="基本算法">基本算法</h3><p>最直接的方法——对每个网格点，遍历所有原子求和：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">compute_potential_cpu</span><span class="params">(</span></span><br><span class="line"><span class="params">    <span class="type">float</span> *potential,     <span class="comment">// 输出：[Gx, Gy, Gz]</span></span></span><br><span class="line"><span class="params">    <span class="type">float</span> *atoms,         <span class="comment">// 原子坐标：[N, 3]</span></span></span><br><span class="line"><span class="params">    <span class="type">float</span> *charges,       <span class="comment">// 原子电荷：[N]</span></span></span><br><span class="line"><span class="params">    <span class="type">int</span> N,                <span class="comment">// 原子数</span></span></span><br><span class="line"><span class="params">    <span class="type">int</span> Gx, <span class="type">int</span> Gy, <span class="type">int</span> Gz,  <span class="comment">// 网格尺寸</span></span></span><br><span class="line"><span class="params">    <span class="type">float</span> grid_spacing)</span> &#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> gx = <span class="number">0</span>; gx &lt; Gx; gx++) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> gy = <span class="number">0</span>; gy &lt; Gy; gy++) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> gz = <span class="number">0</span>; gz &lt; Gz; gz++) &#123;</span><br><span class="line">                <span class="type">float</span> px = gx * grid_spacing;</span><br><span class="line">                <span class="type">float</span> py = gy * grid_spacing;</span><br><span class="line">                <span class="type">float</span> pz = gz * grid_spacing;</span><br><span class="line">                </span><br><span class="line">                <span class="type">float</span> sum = <span class="number">0.0f</span>;</span><br><span class="line">                <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; i++) &#123;</span><br><span class="line">                    <span class="type">float</span> dx = px - atoms[i * <span class="number">3</span> + <span class="number">0</span>];</span><br><span class="line">                    <span class="type">float</span> dy = py - atoms[i * <span class="number">3</span> + <span class="number">1</span>];</span><br><span class="line">                    <span class="type">float</span> dz = pz - atoms[i * <span class="number">3</span> + <span class="number">2</span>];</span><br><span class="line">                    <span class="type">float</span> r = sqrtf(dx*dx + dy*dy + dz*dz);</span><br><span class="line">                    <span class="keyword">if</span> (r &gt; <span class="number">0.001f</span>) &#123;  <span class="comment">// 避免除以零</span></span><br><span class="line">                        sum += charges[i] / r;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                potential[gx * Gy * Gz + gy * Gz + gz] = sum;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>复杂度</strong>：O(G³ × N)，对于 256³ 网格和 10000 个原子 ≈ 10¹¹ 次操作。</p><h3 id="gpu-po-su-shi-xian" tabindex="-1" id="GPU-朴素实现">GPU 朴素实现</h3><p>每个线程计算一个网格点：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">__global__ void compute_potential_naive(</span><br><span class="line">    float *potential,</span><br><span class="line">    float *atoms,     // [N, 3]</span><br><span class="line">    float *charges,   // [N]</span><br><span class="line">    int N,</span><br><span class="line">    int Gx, int Gy, int Gz,</span><br><span class="line">    float grid_spacing) &#123;</span><br><span class="line">    </span><br><span class="line">    int gx = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    int gy = blockIdx.y * blockDim.y + threadIdx.y;</span><br><span class="line">    int gz = blockIdx.z * blockDim.z + threadIdx.z;</span><br><span class="line">    </span><br><span class="line">    if (gx &gt;= Gx || gy &gt;= Gy || gz &gt;= Gz) return;</span><br><span class="line">    </span><br><span class="line">    float px = gx * grid_spacing;</span><br><span class="line">    float py = gy * grid_spacing;</span><br><span class="line">    float pz = gz * grid_spacing;</span><br><span class="line">    </span><br><span class="line">    float sum = 0.0f;</span><br><span class="line">    for (int i = 0; i &lt; N; i++) &#123;</span><br><span class="line">        float dx = px - atoms[i * 3 + 0];</span><br><span class="line">        float dy = py - atoms[i * 3 + 1];</span><br><span class="line">        float dz = pz - atoms[i * 3 + 2];</span><br><span class="line">        float r = sqrtf(dx*dx + dy*dy + dz*dz);</span><br><span class="line">        if (r &gt; 0.001f) &#123;</span><br><span class="line">            sum += charges[i] / r;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    potential[gx * Gy * Gz + gy * Gz + gz] = sum;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>问题</strong>：每个线程都要读取所有原子数据——大量重复的全局内存访问。</p><h2 id="gong-xiang-nei-cun-you-hua" tabindex="-1" id="共享内存优化">共享内存优化</h2><h3 id="yuan-zi-shu-ju-fen-kuai" tabindex="-1" id="原子数据分块">原子数据分块</h3><p>把原子数据分成小块，每块加载到共享内存，复用于 Block 内所有线程：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">#define TILE_SIZE 128</span><br><span class="line"></span><br><span class="line">__global__ void compute_potential_tiled(</span><br><span class="line">    float *potential,</span><br><span class="line">    float *atoms,</span><br><span class="line">    float *charges,</span><br><span class="line">    int N,</span><br><span class="line">    int Gx, int Gy, int Gz,</span><br><span class="line">    float grid_spacing) &#123;</span><br><span class="line">    </span><br><span class="line">    __shared__ float s_atoms[TILE_SIZE * 3];</span><br><span class="line">    __shared__ float s_charges[TILE_SIZE];</span><br><span class="line">    </span><br><span class="line">    int gx = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    int gy = blockIdx.y * blockDim.y + threadIdx.y;</span><br><span class="line">    int gz = blockIdx.z * blockDim.z + threadIdx.z;</span><br><span class="line">    </span><br><span class="line">    float px = gx * grid_spacing;</span><br><span class="line">    float py = gy * grid_spacing;</span><br><span class="line">    float pz = gz * grid_spacing;</span><br><span class="line">    </span><br><span class="line">    float sum = 0.0f;</span><br><span class="line">    </span><br><span class="line">    // 分块处理原子</span><br><span class="line">    for (int tile = 0; tile &lt; N; tile += TILE_SIZE) &#123;</span><br><span class="line">        // 协作加载原子数据到共享内存</span><br><span class="line">        int tid = threadIdx.x + threadIdx.y * blockDim.x + threadIdx.z * blockDim.x * blockDim.y;</span><br><span class="line">        int num_threads = blockDim.x * blockDim.y * blockDim.z;</span><br><span class="line">        </span><br><span class="line">        for (int i = tid; i &lt; TILE_SIZE &amp;&amp; (tile + i) &lt; N; i += num_threads) &#123;</span><br><span class="line">            int atom_idx = tile + i;</span><br><span class="line">            s_atoms[i * 3 + 0] = atoms[atom_idx * 3 + 0];</span><br><span class="line">            s_atoms[i * 3 + 1] = atoms[atom_idx * 3 + 1];</span><br><span class="line">            s_atoms[i * 3 + 2] = atoms[atom_idx * 3 + 2];</span><br><span class="line">            s_charges[i] = charges[atom_idx];</span><br><span class="line">        &#125;</span><br><span class="line">        __syncthreads();</span><br><span class="line">        </span><br><span class="line">        // 计算这一块原子的贡献</span><br><span class="line">        int tile_atoms = min(TILE_SIZE, N - tile);</span><br><span class="line">        for (int i = 0; i &lt; tile_atoms; i++) &#123;</span><br><span class="line">            float dx = px - s_atoms[i * 3 + 0];</span><br><span class="line">            float dy = py - s_atoms[i * 3 + 1];</span><br><span class="line">            float dz = pz - s_atoms[i * 3 + 2];</span><br><span class="line">            float r = sqrtf(dx*dx + dy*dy + dz*dz);</span><br><span class="line">            if (r &gt; 0.001f) &#123;</span><br><span class="line">                sum += s_charges[i] / r;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        __syncthreads();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    if (gx &lt; Gx &amp;&amp; gy &lt; Gy &amp;&amp; gz &lt; Gz) &#123;</span><br><span class="line">        potential[gx * Gy * Gz + gy * Gz + gz] = sum;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="xing-neng-fen-xi" tabindex="-1" id="性能分析">性能分析</h3><table><thead><tr><th>版本</th><th>全局内存读取次数</th><th>加速比</th></tr></thead><tbody><tr><td>朴素</td><td>G³ × N</td><td>1×</td></tr><tr><td>Tiled</td><td>G³ × N / B + N</td><td>~10×</td></tr></tbody></table><p>其中 B 是 Block 内线程数。</p><h2 id="chang-liang-nei-cun-you-hua" tabindex="-1" id="常量内存优化">常量内存优化</h2><h3 id="yuan-zi-shu-ju-fang-ru-chang-liang-nei-cun" tabindex="-1" id="原子数据放入常量内存">原子数据放入常量内存</h3><p>如果原子数不太多（&lt; 16K），可以放入常量内存：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">#define MAX_ATOMS 16000</span><br><span class="line"></span><br><span class="line">__constant__ float c_atoms[MAX_ATOMS * 4];  // x, y, z, charge</span><br><span class="line"></span><br><span class="line">void setup_atoms(float *atoms, float *charges, int N) &#123;</span><br><span class="line">    float atoms_packed[MAX_ATOMS * 4];</span><br><span class="line">    for (int i = 0; i &lt; N; i++) &#123;</span><br><span class="line">        atoms_packed[i * 4 + 0] = atoms[i * 3 + 0];</span><br><span class="line">        atoms_packed[i * 4 + 1] = atoms[i * 3 + 1];</span><br><span class="line">        atoms_packed[i * 4 + 2] = atoms[i * 3 + 2];</span><br><span class="line">        atoms_packed[i * 4 + 3] = charges[i];</span><br><span class="line">    &#125;</span><br><span class="line">    cudaMemcpyToSymbol(c_atoms, atoms_packed, N * 4 * sizeof(float));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">__global__ void compute_potential_const(</span><br><span class="line">    float *potential,</span><br><span class="line">    int N,</span><br><span class="line">    int Gx, int Gy, int Gz,</span><br><span class="line">    float grid_spacing) &#123;</span><br><span class="line">    </span><br><span class="line">    // ... 网格点坐标计算 ...</span><br><span class="line">    </span><br><span class="line">    float sum = 0.0f;</span><br><span class="line">    for (int i = 0; i &lt; N; i++) &#123;</span><br><span class="line">        float ax = c_atoms[i * 4 + 0];</span><br><span class="line">        float ay = c_atoms[i * 4 + 1];</span><br><span class="line">        float az = c_atoms[i * 4 + 2];</span><br><span class="line">        float q  = c_atoms[i * 4 + 3];</span><br><span class="line">        </span><br><span class="line">        float dx = px - ax;</span><br><span class="line">        float dy = py - ay;</span><br><span class="line">        float dz = pz - az;</span><br><span class="line">        float r = sqrtf(dx*dx + dy*dy + dz*dz);</span><br><span class="line">        if (r &gt; 0.001f) &#123;</span><br><span class="line">            sum += q / r;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    // ... 写入结果 ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>优势</strong>：</p><ul><li>常量内存有专用缓存</li><li>广播机制：Warp 内线程访问同一地址只需一次读取</li></ul><h2 id="jie-duan-fang-fa" tabindex="-1" id="截断方法">截断方法</h2><h3 id="wei-shi-yao-jie-duan" tabindex="-1" id="为什么截断">为什么截断</h3><p>真实分子模拟中，远距离原子的贡献很小。可以设置<strong>截断半径</strong>，只计算距离小于截断半径的原子。</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>V</mi><mo stretchy="false">(</mo><mi mathvariant="bold">p</mi><mo stretchy="false">)</mo><mo>=</mo><munder><mo>∑</mo><mrow><mi mathvariant="normal">∣</mi><mi mathvariant="bold">p</mi><mo>−</mo><msub><mi mathvariant="bold">r</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi><mo>&lt;</mo><msub><mi>r</mi><mrow><mi>c</mi><mi>u</mi><mi>t</mi></mrow></msub></mrow></munder><mfrac><mrow><mi>k</mi><mo>⋅</mo><msub><mi>q</mi><mi>i</mi></msub></mrow><mrow><mi mathvariant="normal">∣</mi><mi mathvariant="bold">p</mi><mo>−</mo><msub><mi mathvariant="bold">r</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">V(\mathbf{p}) = \sum_{|\mathbf{p} - \mathbf{r}_i| &lt; r_{cut}} \frac{k \cdot q_i}{|\mathbf{p} - \mathbf{r}_i|}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mopen">(</span><span class="mord mathbf">p</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.8874em;vertical-align:-1.516em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.809em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∣</span><span class="mord mathbf mtight">p</span><span class="mbin mtight">−</span><span class="mord mtight"><span class="mord mathbf mtight">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mord mtight">∣</span><span class="mrel mtight">&lt;</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2963em;"><span style="top:-2.357em;margin-left:-0.0278em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.516em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">∣</span><span class="mord mathbf">p</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathbf">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><h3 id="kong-jian-fen-qu" tabindex="-1" id="空间分区">空间分区</h3><p>为了快速找到&quot;附近&quot;的原子，使用<strong>空间哈希</strong>或<strong>Cell List</strong>：</p><ol><li>把空间划分成小格子（边长 = 截断半径）</li><li>每个原子分配到所在格子</li><li>计算网格点时，只遍历邻近 27 个格子中的原子</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">__global__ void compute_potential_cutoff(</span><br><span class="line">    float *potential,</span><br><span class="line">    int *cell_start,    // [Cx, Cy, Cz] 每个格子的原子起始索引</span><br><span class="line">    int *cell_count,    // [Cx, Cy, Cz] 每个格子的原子数</span><br><span class="line">    float *sorted_atoms,</span><br><span class="line">    float *sorted_charges,</span><br><span class="line">    float cutoff,</span><br><span class="line">    int Gx, int Gy, int Gz,</span><br><span class="line">    int Cx, int Cy, int Cz,</span><br><span class="line">    float grid_spacing,</span><br><span class="line">    float cell_size) &#123;</span><br><span class="line">    </span><br><span class="line">    int gx = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    int gy = blockIdx.y * blockDim.y + threadIdx.y;</span><br><span class="line">    int gz = blockIdx.z * blockDim.z + threadIdx.z;</span><br><span class="line">    </span><br><span class="line">    if (gx &gt;= Gx || gy &gt;= Gy || gz &gt;= Gz) return;</span><br><span class="line">    </span><br><span class="line">    float px = gx * grid_spacing;</span><br><span class="line">    float py = gy * grid_spacing;</span><br><span class="line">    float pz = gz * grid_spacing;</span><br><span class="line">    </span><br><span class="line">    // 确定所在格子</span><br><span class="line">    int cx = (int)(px / cell_size);</span><br><span class="line">    int cy = (int)(py / cell_size);</span><br><span class="line">    int cz = (int)(pz / cell_size);</span><br><span class="line">    </span><br><span class="line">    float sum = 0.0f;</span><br><span class="line">    </span><br><span class="line">    // 遍历邻近 27 个格子</span><br><span class="line">    for (int dcx = -1; dcx &lt;= 1; dcx++) &#123;</span><br><span class="line">        for (int dcy = -1; dcy &lt;= 1; dcy++) &#123;</span><br><span class="line">            for (int dcz = -1; dcz &lt;= 1; dcz++) &#123;</span><br><span class="line">                int ncx = cx + dcx;</span><br><span class="line">                int ncy = cy + dcy;</span><br><span class="line">                int ncz = cz + dcz;</span><br><span class="line">                </span><br><span class="line">                if (ncx &lt; 0 || ncx &gt;= Cx || ncy &lt; 0 || ncy &gt;= Cy || ncz &lt; 0 || ncz &gt;= Cz)</span><br><span class="line">                    continue;</span><br><span class="line">                </span><br><span class="line">                int cell_idx = ncx * Cy * Cz + ncy * Cz + ncz;</span><br><span class="line">                int start = cell_start[cell_idx];</span><br><span class="line">                int count = cell_count[cell_idx];</span><br><span class="line">                </span><br><span class="line">                for (int i = 0; i &lt; count; i++) &#123;</span><br><span class="line">                    int atom_idx = start + i;</span><br><span class="line">                    float dx = px - sorted_atoms[atom_idx * 3 + 0];</span><br><span class="line">                    float dy = py - sorted_atoms[atom_idx * 3 + 1];</span><br><span class="line">                    float dz = pz - sorted_atoms[atom_idx * 3 + 2];</span><br><span class="line">                    float r = sqrtf(dx*dx + dy*dy + dz*dz);</span><br><span class="line">                    </span><br><span class="line">                    if (r &gt; 0.001f &amp;&amp; r &lt; cutoff) &#123;</span><br><span class="line">                        sum += sorted_charges[atom_idx] / r;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    potential[gx * Gy * Gz + gy * Gz + gz] = sum;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="fu-za-du-fen-xi" tabindex="-1" id="复杂度分析">复杂度分析</h3><table><thead><tr><th>方法</th><th>复杂度</th><th>适用场景</th></tr></thead><tbody><tr><td>直接求和</td><td>O(G³ × N)</td><td>小系统</td></tr><tr><td>截断 + Cell</td><td>O(G³ × ρ × r³)</td><td>大系统</td></tr></tbody></table><p>其中 ρ 是原子密度，r 是截断半径。</p><h2 id="duo-ceng-wang-ge-fang-fa" tabindex="-1" id="多层网格方法">多层网格方法</h2><h3 id="ewald-qiu-he" tabindex="-1" id="Ewald-求和">Ewald 求和</h3><p>对于周期性边界条件，需要考虑<strong>所有周期镜像</strong>的贡献。</p><p><strong>Ewald 方法</strong>将求和分成两部分：</p><ol><li><strong>实空间</strong>：截断求和（短程）</li><li><strong>倒空间</strong>：FFT 求和（长程）</li></ol><h3 id="pme-particle-mesh-ewald" tabindex="-1" id="PME（Particle-Mesh-Ewald）">PME（Particle Mesh Ewald）</h3><p>PME 是 Ewald 的高效变体：</p><ol><li>把电荷分配到网格</li><li>对网格做 FFT</li><li>在倒空间计算势能</li><li>做 IFFT</li><li>插值回原子位置</li></ol><p><strong>复杂度</strong>：O(N log N) vs 直接 Ewald 的 O(N^1.5)</p><h3 id="gpu-shang-de-pme" tabindex="-1" id="GPU-上的-PME">GPU 上的 PME</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">void pme_potential(</span><br><span class="line">    float *potential,</span><br><span class="line">    float *atoms,</span><br><span class="line">    float *charges,</span><br><span class="line">    int N,</span><br><span class="line">    int grid_size) &#123;</span><br><span class="line">    </span><br><span class="line">    // 1. 电荷分配到网格（B-spline 插值）</span><br><span class="line">    charge_spreading&lt;&lt;&lt;...&gt;&gt;&gt;(charges, atoms, grid_charges, N, grid_size);</span><br><span class="line">    </span><br><span class="line">    // 2. 3D FFT</span><br><span class="line">    cufftExecC2C(plan, grid_charges, grid_kspace, CUFFT_FORWARD);</span><br><span class="line">    </span><br><span class="line">    // 3. 倒空间操作（乘以 Green 函数）</span><br><span class="line">    reciprocal_kernel&lt;&lt;&lt;...&gt;&gt;&gt;(grid_kspace, grid_size);</span><br><span class="line">    </span><br><span class="line">    // 4. 3D IFFT</span><br><span class="line">    cufftExecC2C(plan, grid_kspace, grid_potential, CUFFT_INVERSE);</span><br><span class="line">    </span><br><span class="line">    // 5. 插值回网格点</span><br><span class="line">    interpolate_kernel&lt;&lt;&lt;...&gt;&gt;&gt;(grid_potential, potential, grid_size);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="duo-gpu-shi-xian" tabindex="-1" id="多-GPU-实现">多 GPU 实现</h2><h3 id="shu-ju-bing-xing" tabindex="-1" id="数据并行">数据并行</h3><p>对于大网格，可以将网格分割到多个 GPU：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">void multi_gpu_potential(</span><br><span class="line">    float *potential,</span><br><span class="line">    float *atoms,</span><br><span class="line">    float *charges,</span><br><span class="line">    int N,</span><br><span class="line">    int Gx, int Gy, int Gz,</span><br><span class="line">    int num_gpus) &#123;</span><br><span class="line">    </span><br><span class="line">    int slices_per_gpu = Gx / num_gpus;</span><br><span class="line">    </span><br><span class="line">    #pragma omp parallel for num_threads(num_gpus)</span><br><span class="line">    for (int gpu = 0; gpu &lt; num_gpus; gpu++) &#123;</span><br><span class="line">        cudaSetDevice(gpu);</span><br><span class="line">        </span><br><span class="line">        int gx_start = gpu * slices_per_gpu;</span><br><span class="line">        int gx_end = (gpu == num_gpus - 1) ? Gx : (gpu + 1) * slices_per_gpu;</span><br><span class="line">        </span><br><span class="line">        compute_potential_kernel&lt;&lt;&lt;...&gt;&gt;&gt;(</span><br><span class="line">            potential + gx_start * Gy * Gz,</span><br><span class="line">            atoms_d[gpu], charges_d[gpu], N,</span><br><span class="line">            gx_start, gx_end, Gy, Gz, grid_spacing);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    // 收集结果</span><br><span class="line">    // ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="zhu-yi-shi-xiang" tabindex="-1" id="注意事项">注意事项</h3><ul><li>每个 GPU 需要完整的原子数据副本</li><li>边界区域可能需要重叠计算</li><li>使用 NCCL 高效通信</li></ul><h2 id="ying-yong-fen-zi-dui-jie" tabindex="-1" id="应用：分子对接">应用：分子对接</h2><h3 id="yao-wu-she-ji-zhong-de-ying-yong" tabindex="-1" id="药物设计中的应用">药物设计中的应用</h3><p>静电势能图用于<strong>分子对接</strong>：预测配体分子与蛋白质靶点的结合方式。</p><p><strong>流程</strong>：</p><ol><li>计算蛋白质的静电势能图</li><li>配体在势能图中搜索最优位置</li><li>评估结合亲和力</li></ol><h3 id="shi-shi-ke-shi-hua" tabindex="-1" id="实时可视化">实时可视化</h3><p>GPU 计算的静电势能图可以实时渲染：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">// 将势能图转换为颜色</span><br><span class="line">__global__ void potential_to_color(</span><br><span class="line">    float *potential,</span><br><span class="line">    uchar4 *colors,</span><br><span class="line">    float min_val, float max_val,</span><br><span class="line">    int num_points) &#123;</span><br><span class="line">    </span><br><span class="line">    int idx = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    if (idx &gt;= num_points) return;</span><br><span class="line">    </span><br><span class="line">    float val = potential[idx];</span><br><span class="line">    float normalized = (val - min_val) / (max_val - min_val);</span><br><span class="line">    </span><br><span class="line">    // 红色表示正电势，蓝色表示负电势</span><br><span class="line">    colors[idx].x = (unsigned char)(255 * fmaxf(normalized, 0.0f));</span><br><span class="line">    colors[idx].y = 0;</span><br><span class="line">    colors[idx].z = (unsigned char)(255 * fmaxf(-normalized, 0.0f));</span><br><span class="line">    colors[idx].w = 255;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="xing-neng-zong-jie" tabindex="-1" id="性能总结">性能总结</h2><h3 id="ge-you-hua-de-jia-su-xiao-guo" tabindex="-1" id="各优化的加速效果">各优化的加速效果</h3><table><thead><tr><th>优化技术</th><th>相对加速</th><th>累计加速</th></tr></thead><tbody><tr><td>GPU 朴素</td><td>50×</td><td>50×</td></tr><tr><td>共享内存 Tiling</td><td>10×</td><td>500×</td></tr><tr><td>常量内存</td><td>1.5×</td><td>750×</td></tr><tr><td>截断 + Cell</td><td>5-20×</td><td>3000×+</td></tr></tbody></table><h3 id="shi-ji-xing-neng" tabindex="-1" id="实际性能">实际性能</h3><p>256³ 网格，10000 个原子：</p><ul><li>CPU（单核）：~600 秒</li><li>GPU（V100）：~0.2 秒</li></ul><p><strong>加速比</strong>：3000× 以上</p><h2 id="xiao-jie" tabindex="-1" id="小结">小结</h2><p>第十八章展示了静电势能计算的 GPU 加速：</p><p><strong>问题本质</strong>：N-body 类型的全对问题，每个网格点需要遍历所有原子。直接计算复杂度 O(G³ × N)。</p><p><strong>共享内存优化</strong>：把原子数据分块加载到共享内存，Block 内线程共享，大幅减少全局内存访问。</p><p><strong>常量内存</strong>：对于小规模原子数据，利用常量缓存和广播机制进一步加速。</p><p><strong>截断方法</strong>：利用物理特性（远场贡献小）减少计算量。Cell List 数据结构快速查找邻近原子。</p><p><strong>PME 方法</strong>：对于周期性系统，用 FFT 处理长程相互作用，复杂度降至 O(N log N)。</p><p><strong>多 GPU 扩展</strong>：网格天然可分割，适合数据并行。</p><p>静电势能计算是分子动力学模拟的核心组件。掌握本章技术，就能理解 GROMACS、AMBER 等分子动力学软件的 GPU 加速原理。</p><h2 id="xia-yi-bu" tabindex="-1" id="🚀-下一步">🚀 下一步</h2><ul><li>实现一个完整的静电势能计算程序，从直接求和开始，逐步优化到共享内存和截断方法</li><li>学习 PME 方法，实现基于 FFT 的长程相互作用计算</li><li>探索其他 N-body 问题：引力模拟、流体动力学中的粒子方法</li><li>了解分子动力学模拟的完整流程：力场计算、积分器、温度/压力控制</li><li>研究 GROMACS 或 AMBER 的 GPU 加速实现，学习工业级优化技巧</li></ul><hr><h2 id="can-kao-zi-liao" tabindex="-1" id="📚-参考资料">📚 参考资料</h2><ul><li>PMPP 第四版 Chapter 18</li><li><a href="https://smarter.xin/posts/pmmpp-chapter18-electrostatic-potential/">第十八章：静电势能图</a></li><li>Hwu, W., Kirk, D., &amp; El Hajj, I. (2022). <em>Programming Massively Parallel Processors: A Hands-on Approach</em> (4th Edition). Morgan Kaufmann.</li><li>Stone, J. E., et al. (2007). <em>Accelerating Molecular Modeling Applications with GPU Computing</em>. JCC.</li><li>Darden, T., et al. (1993). <em>Particle Mesh Ewald: An N·log(N) Method for Ewald Sums</em>. JCP.</li></ul><p><strong>学习愉快！</strong> 🎓</p><hr><blockquote><p><strong>本文 GitHub 仓库</strong>: <a href="https://github.com/psmarter/PMPP-Learning">https://github.com/psmarter/PMPP-Learning</a></p></blockquote>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h2 id=&quot;qian-yan&quot; tabindex=&quot;-1&quot; id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;第十七章探索了 MRI 重建这一医学影像应用。第十八章转向另一个重要的科学计算领域——&lt;strong&gt;分子动力学（Molecular</summary>
        
      
    
    
    
    <category term="知识分享" scheme="https://smarter.xin/categories/knowledge-sharing/"/>
    
    
    <category term="CUDA" scheme="https://smarter.xin/tags/CUDA/"/>
    
    <category term="GPU编程" scheme="https://smarter.xin/tags/gpu-programming/"/>
    
    <category term="并行计算" scheme="https://smarter.xin/tags/parallel-computing/"/>
    
    <category term="PMPP" scheme="https://smarter.xin/tags/PMPP/"/>
    
    <category term="分子动力学" scheme="https://smarter.xin/tags/molecular-dynamics/"/>
    
    <category term="静电势能" scheme="https://smarter.xin/tags/electrostatic-potential/"/>
    
    <category term="科学计算" scheme="https://smarter.xin/tags/scientific-computing/"/>
    
  </entry>
  
  <entry>
    <title>PMPP-第十七章：迭代式磁共振成像重建</title>
    <link href="https://smarter.xin/posts/fab0715b/"/>
    <id>https://smarter.xin/posts/fab0715b/</id>
    <published>2026-01-23T01:08:10.000Z</published>
    <updated>2026-01-24T11:47:21.463Z</updated>
    
    <content type="html"><![CDATA[<h2 id="qian-yan" tabindex="-1" id="前言">前言</h2><p>前面的章节主要讨论了通用的并行算法和深度学习应用。第十七章转向一个具体的应用领域——<strong>医学影像（Medical Imaging）</strong>，特别是**磁共振成像（MRI，Magnetic Resonance Imaging）**的图像重建。MRI 重建是计算密集型任务，涉及大量的傅里叶变换和迭代优化，是 GPU 加速的理想场景。本章将展示如何将前面学到的并行技术（FFT、矩阵运算、迭代求解）综合应用于实际问题。</p><blockquote><p><strong>📦 配套资源</strong>：本系列文章配有完整的 <a href="https://github.com/psmarter/PMPP-Learning">GitHub 仓库</a>，包含每章的练习题解答、CUDA 代码实现和详细注释。所有代码都经过测试，可以直接运行。</p></blockquote><h2 id="mri-cheng-xiang-ji-chu" tabindex="-1" id="MRI-成像基础">MRI 成像基础</h2><h3 id="mri-wu-li-yuan-li-jian-shu" tabindex="-1" id="MRI-物理原理简述">MRI 物理原理简述</h3><p>MRI 利用人体中氢原子核的磁共振现象成像：</p><ol><li><strong>激发</strong>：射频脉冲激发氢原子核</li><li><strong>弛豫</strong>：原子核恢复平衡时发出信号</li><li><strong>采集</strong>：接收线圈采集信号</li><li><strong>编码</strong>：梯度磁场对空间位置进行编码</li></ol><p>采集到的信号位于<strong>k 空间（k-space）</strong>——图像的傅里叶变换域。</p><h3 id="cong-k-kong-jian-dao-tu-xiang" tabindex="-1" id="从-k-空间到图像">从 k 空间到图像</h3><p><strong>基本公式</strong>：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>s</mi><mo stretchy="false">(</mo><msub><mi>k</mi><mi>x</mi></msub><mo separator="true">,</mo><msub><mi>k</mi><mi>y</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mo>∫</mo><mo>∫</mo><mi>m</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>⋅</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>i</mi><mn>2</mn><mi>π</mi><mo stretchy="false">(</mo><msub><mi>k</mi><mi>x</mi></msub><mi>x</mi><mo>+</mo><msub><mi>k</mi><mi>y</mi></msub><mi>y</mi><mo stretchy="false">)</mo></mrow></msup><mi>d</mi><mi>x</mi><mi>d</mi><mi>y</mi></mrow><annotation encoding="application/x-tex">s(k_x, k_y) = \int \int m(x, y) \cdot e^{-i2\pi(k_x x + k_y y)} dx dy</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord mathnormal">s</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0315em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0315em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.2222em;vertical-align:-0.8622em;"></span><span class="mop op-symbol large-op" style="margin-right:0.44445em;position:relative;top:-0.0011em;">∫∫</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">m</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1324em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathnormal mtight">i</span><span class="mord mtight">2</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">π</span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1645em;"><span style="top:-2.357em;margin-left:-0.0315em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mord mathnormal mtight">x</span><span class="mbin mtight">+</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1645em;"><span style="top:-2.357em;margin-left:-0.0315em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2819em;"><span></span></span></span></span></span></span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mord mathnormal">d</span><span class="mord mathnormal">x</span><span class="mord mathnormal">d</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span></span></span></p><p>其中：</p><ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mo stretchy="false">(</mo><msub><mi>k</mi><mi>x</mi></msub><mo separator="true">,</mo><msub><mi>k</mi><mi>y</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">s(k_x, k_y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord mathnormal">s</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0315em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0315em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>：k 空间信号</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">m(x, y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">m</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span>：图像（磁化强度分布）</li></ul><p><strong>重建</strong>就是从 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi></mrow><annotation encoding="application/x-tex">s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">s</span></span></span></span> 恢复 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">m</span></span></span></span>，即<strong>逆傅里叶变换</strong>。</p><h3 id="di-qia-er-cai-yang-vs-fei-di-qia-er-cai-yang" tabindex="-1" id="笛卡尔采样-vs-非笛卡尔采样">笛卡尔采样 vs 非笛卡尔采样</h3><p><strong>笛卡尔采样</strong>：k 空间数据在规则网格上采集。</p><ul><li>优点：直接用 FFT 重建</li><li>缺点：采集速度受限</li></ul><p><strong>非笛卡尔采样</strong>（如螺旋、径向）：</p><ul><li>优点：采集更快，对运动不敏感</li><li>缺点：不能直接 FFT，需要特殊处理</li></ul><h2 id="zhi-jie-zhong-jian-yu-die-dai-zhong-jian" tabindex="-1" id="直接重建与迭代重建">直接重建与迭代重建</h2><h3 id="zhi-jie-zhong-jian" tabindex="-1" id="直接重建">直接重建</h3><p>对于笛卡尔采样的全采样数据：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">图像 = IFFT(k空间数据)</span><br></pre></td></tr></table></figure><p>简单快速，但有两个问题：</p><ol><li><strong>欠采样</strong>：为加速扫描，往往只采集部分 k 空间数据</li><li><strong>非笛卡尔轨迹</strong>：数据不在网格上</li></ol><h3 id="qian-cai-yang-de-wen-ti" tabindex="-1" id="欠采样的问题">欠采样的问题</h3><p>根据奈奎斯特定理，欠采样会导致<strong>混叠伪影（Aliasing）</strong>。</p><p>直接 IFFT 重建欠采样数据会产生严重的图像失真。</p><h3 id="die-dai-zhong-jian" tabindex="-1" id="迭代重建">迭代重建</h3><p><strong>思路</strong>：把重建建模为<strong>优化问题</strong>。</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mover accent="true"><mi>m</mi><mo>^</mo></mover><mo>=</mo><mi>arg</mi><mo>⁡</mo><munder><mrow><mi>min</mi><mo>⁡</mo></mrow><mi>m</mi></munder><mfrac><mn>1</mn><mn>2</mn></mfrac><mi mathvariant="normal">∥</mi><mi>A</mi><mi>m</mi><mo>−</mo><mi>s</mi><msubsup><mi mathvariant="normal">∥</mi><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mi>λ</mi><mi>R</mi><mo stretchy="false">(</mo><mi>m</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\hat{m} = \arg\min_m \frac{1}{2}\|Am - s\|_2^2 + \lambda R(m)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">m</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.25em;"><span class="mord">^</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.0214em;vertical-align:-0.7em;"></span><span class="mop">ar<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6679em;"><span style="top:-2.4em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop">min</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord">∥</span><span class="mord mathnormal">A</span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1141em;vertical-align:-0.25em;"></span><span class="mord mathnormal">s</span><span class="mord"><span class="mord">∥</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">λ</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mopen">(</span><span class="mord mathnormal">m</span><span class="mclose">)</span></span></span></span></span></p><p>其中：</p><ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span>：前向模型（编码矩阵）</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi></mrow><annotation encoding="application/x-tex">s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">s</span></span></span></span>：采集的 k 空间数据</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo stretchy="false">(</mo><mi>m</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">R(m)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mopen">(</span><span class="mord mathnormal">m</span><span class="mclose">)</span></span></span></span>：正则化项（先验约束）</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">λ</span></span></span></span>：正则化权重</li></ul><p><strong>迭代求解</strong>：通过梯度下降、共轭梯度等方法逐步逼近最优解。</p><h2 id="fei-jun-yun-fu-li-xie-bian-huan-nufft" tabindex="-1" id="非均匀傅里叶变换（NUFFT）">非均匀傅里叶变换（NUFFT）</h2><h3 id="wen-ti" tabindex="-1" id="问题">问题</h3><p>非笛卡尔采样的数据不在规则网格上，不能直接用 FFT。</p><p><strong>非均匀离散傅里叶变换（NUDFT）</strong>：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>s</mi><mo stretchy="false">(</mo><msub><mi>k</mi><mi>j</mi></msub><mo stretchy="false">)</mo><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mi>m</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>⋅</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>i</mi><mn>2</mn><mi>π</mi><msub><mi>k</mi><mi>j</mi></msub><msub><mi>x</mi><mi>i</mi></msub></mrow></msup></mrow><annotation encoding="application/x-tex">s(k_j) = \sum_{i=1}^{N} m(x_i) \cdot e^{-i2\pi k_j x_i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord mathnormal">s</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0315em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.106em;vertical-align:-1.2777em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">m</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8991em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathnormal mtight">i</span><span class="mord mtight">2</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">π</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.0315em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2819em;"><span></span></span></span></span></span></span><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p>直接计算复杂度 O(MN)，太慢。</p><h3 id="nufft-suan-fa" tabindex="-1" id="NUFFT-算法">NUFFT 算法</h3><p><strong>核心思想</strong>：先插值到规则网格，再用 FFT。</p><p><strong>Type-1 NUFFT（非均匀到均匀）</strong>：</p><ol><li>把非均匀点的值&quot;散布&quot;到规则网格（卷积/插值）</li><li>对规则网格执行 FFT</li><li>去卷积校正</li></ol><p><strong>Type-2 NUFFT（均匀到非均匀）</strong>：</p><ol><li>对规则网格执行 IFFT</li><li>在非均匀点插值采样</li></ol><h3 id="gpu-shi-xian-yao-dian" tabindex="-1" id="GPU-实现要点">GPU 实现要点</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">__global__ void gridding_kernel(</span><br><span class="line">    cuComplex *non_uniform_data,  // 非均匀采样数据</span><br><span class="line">    float2 *trajectory,            // 采样轨迹 (kx, ky)</span><br><span class="line">    cuComplex *grid,               // 输出网格</span><br><span class="line">    int num_samples,</span><br><span class="line">    int grid_size,</span><br><span class="line">    float kernel_width) &#123;</span><br><span class="line">    </span><br><span class="line">    int idx = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    if (idx &gt;= num_samples) return;</span><br><span class="line">    </span><br><span class="line">    float kx = trajectory[idx].x;</span><br><span class="line">    float ky = trajectory[idx].y;</span><br><span class="line">    cuComplex val = non_uniform_data[idx];</span><br><span class="line">    </span><br><span class="line">    // 找到影响的网格点范围</span><br><span class="line">    int x_start = max(0, (int)(kx - kernel_width));</span><br><span class="line">    int x_end = min(grid_size - 1, (int)(kx + kernel_width));</span><br><span class="line">    int y_start = max(0, (int)(ky - kernel_width));</span><br><span class="line">    int y_end = min(grid_size - 1, (int)(ky + kernel_width));</span><br><span class="line">    </span><br><span class="line">    // 散布到网格</span><br><span class="line">    for (int gx = x_start; gx &lt;= x_end; gx++) &#123;</span><br><span class="line">        for (int gy = y_start; gy &lt;= y_end; gy++) &#123;</span><br><span class="line">            float weight = kaiser_bessel(kx - gx, ky - gy, kernel_width);</span><br><span class="line">            atomicAdd(&amp;grid[gy * grid_size + gx].x, val.x * weight);</span><br><span class="line">            atomicAdd(&amp;grid[gy * grid_size + gx].y, val.y * weight);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>关键优化</strong>：</p><ul><li>使用 Kaiser-Bessel 窗函数插值</li><li>原子操作处理网格冲突</li><li>过采样网格减少误差</li></ul><h2 id="gong-e-ti-du-fa-cg" tabindex="-1" id="共轭梯度法（CG）">共轭梯度法（CG）</h2><h3 id="suan-fa-gai-shu" tabindex="-1" id="算法概述">算法概述</h3><p>共轭梯度法求解线性系统 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi>x</mi><mo>=</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">Ax = b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">b</span></span></span></span>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">初始化：x_0, r_0 = b - A*x_0, p_0 = r_0</span><br><span class="line"></span><br><span class="line">循环：</span><br><span class="line">    alpha_k = (r_k·r_k) / (p_k·A*p_k)</span><br><span class="line">    x_&#123;k+1&#125; = x_k + alpha_k * p_k</span><br><span class="line">    r_&#123;k+1&#125; = r_k - alpha_k * A*p_k</span><br><span class="line">    beta_k = (r_&#123;k+1&#125;·r_&#123;k+1&#125;) / (r_k·r_k)</span><br><span class="line">    p_&#123;k+1&#125; = r_&#123;k+1&#125; + beta_k * p_k</span><br></pre></td></tr></table></figure><h3 id="gpu-shi-xian" tabindex="-1" id="GPU-实现">GPU 实现</h3><p>CG 的主要操作：</p><ol><li><strong>矩阵-向量乘</strong>：A*p（使用 NUFFT）</li><li><strong>向量内积</strong>：r·r（归约）</li><li><strong>向量加法</strong>：x + alpha*p（逐元素）</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">void cg_solve(</span><br><span class="line">    cuComplex *x,      // 解（图像）</span><br><span class="line">    cuComplex *b,      // 右端项（k空间数据）</span><br><span class="line">    int max_iter,</span><br><span class="line">    float tol) &#123;</span><br><span class="line">    </span><br><span class="line">    // 分配中间变量</span><br><span class="line">    cuComplex *r, *p, *Ap;</span><br><span class="line">    </span><br><span class="line">    // r = b - A*x</span><br><span class="line">    apply_forward_model(x, Ap);</span><br><span class="line">    vector_subtract(b, Ap, r, n);</span><br><span class="line">    vector_copy(r, p, n);</span><br><span class="line">    </span><br><span class="line">    float rr = vector_dot(r, r, n);</span><br><span class="line">    </span><br><span class="line">    for (int k = 0; k &lt; max_iter &amp;&amp; rr &gt; tol; k++) &#123;</span><br><span class="line">        // Ap = A * p</span><br><span class="line">        apply_forward_model(p, Ap);</span><br><span class="line">        </span><br><span class="line">        // alpha = rr / (p·Ap)</span><br><span class="line">        float pAp = vector_dot(p, Ap, n);</span><br><span class="line">        float alpha = rr / pAp;</span><br><span class="line">        </span><br><span class="line">        // x = x + alpha * p</span><br><span class="line">        vector_axpy(alpha, p, x, n);</span><br><span class="line">        </span><br><span class="line">        // r = r - alpha * Ap</span><br><span class="line">        vector_axpy(-alpha, Ap, r, n);</span><br><span class="line">        </span><br><span class="line">        // beta = rr_new / rr_old</span><br><span class="line">        float rr_new = vector_dot(r, r, n);</span><br><span class="line">        float beta = rr_new / rr;</span><br><span class="line">        </span><br><span class="line">        // p = r + beta * p</span><br><span class="line">        vector_xpay(r, beta, p, n);</span><br><span class="line">        </span><br><span class="line">        rr = rr_new;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="nufft-zuo-wei-qian-xiang-mo-xing" tabindex="-1" id="NUFFT-作为前向模型">NUFFT 作为前向模型</h3><p>在 MRI 重建中，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span> 不是显式存储的矩阵，而是通过 NUFFT 计算：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">void apply_forward_model(cuComplex *image, cuComplex *kspace) &#123;</span><br><span class="line">    // 1. 图像空间 → k空间（Type-2 NUFFT）</span><br><span class="line">    nufft_type2(image, kspace, trajectory, num_samples, grid_size);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void apply_adjoint_model(cuComplex *kspace, cuComplex *image) &#123;</span><br><span class="line">    // 2. k空间 → 图像空间（Type-1 NUFFT，共轭转置）</span><br><span class="line">    nufft_type1(kspace, image, trajectory, num_samples, grid_size);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>共轭梯度中的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>A</mi><mi>H</mi></msup><mi>A</mi></mrow><annotation encoding="application/x-tex">A^H A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.08125em;">H</span></span></span></span></span></span></span></span><span class="mord mathnormal">A</span></span></span></span> 操作变成：NUFFT^H · NUFFT。</p><h2 id="zheng-ze-hua" tabindex="-1" id="正则化">正则化</h2><h3 id="wei-shi-yao-xu-yao-zheng-ze-hua" tabindex="-1" id="为什么需要正则化">为什么需要正则化</h3><p>欠采样导致问题<strong>欠定</strong>：方程数少于未知数。</p><p>需要额外约束来选择&quot;好&quot;的解。</p><h3 id="chang-jian-zheng-ze-hua-xiang" tabindex="-1" id="常见正则化项">常见正则化项</h3><p><strong>Tikhonov 正则化（L2）</strong>：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>R</mi><mo stretchy="false">(</mo><mi>m</mi><mo stretchy="false">)</mo><mo>=</mo><mi mathvariant="normal">∥</mi><mi>m</mi><msubsup><mi mathvariant="normal">∥</mi><mn>2</mn><mn>2</mn></msubsup></mrow><annotation encoding="application/x-tex">R(m) = \|m\|_2^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mopen">(</span><span class="mord mathnormal">m</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1141em;vertical-align:-0.25em;"></span><span class="mord">∥</span><span class="mord mathnormal">m</span><span class="mord"><span class="mord">∥</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span></span></p><p>促进解的平滑，抑制噪声。</p><p><strong>全变分（TV）</strong>：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>R</mi><mo stretchy="false">(</mo><mi>m</mi><mo stretchy="false">)</mo><mo>=</mo><munder><mo>∑</mo><mi>i</mi></munder><msqrt><mrow><mo stretchy="false">(</mo><msub><mi mathvariant="normal">∇</mi><mi>x</mi></msub><msub><mi>m</mi><mi>i</mi></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy="false">(</mo><msub><mi mathvariant="normal">∇</mi><mi>y</mi></msub><msub><mi>m</mi><mi>i</mi></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow></msqrt></mrow><annotation encoding="application/x-tex">R(m) = \sum_i \sqrt{(\nabla_x m_i)^2 + (\nabla_y m_i)^2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mopen">(</span><span class="mord mathnormal">m</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.5435em;vertical-align:-1.2777em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.2658em;"><span class="svg-align" style="top:-3.8em;"><span class="pstrut" style="height:3.8em;"></span><span class="mord" style="padding-left:1em;"><span class="mopen">(</span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7401em;"><span style="top:-2.989em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mopen">(</span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7401em;"><span style="top:-2.989em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span><span style="top:-3.2258em;"><span class="pstrut" style="height:3.8em;"></span><span class="hide-tail" style="min-width:1.02em;height:1.88em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.88em" viewBox="0 0 400000 1944" preserveAspectRatio="xMinYMin slice"><path d="M983 90l0 -0c4,-6.7,10,-10,18,-10 H400000v40H1013.1s-83.4,268,-264.1,840c-180.7,572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7s-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744c-10,12,-21,25,-33,39s-32,39,-32,39c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30c26.7,-32.7,52,-63,76,-91s52,-60,52,-60s208,722,208,722c56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,-658.5c53.7,-170.3,84.5,-266.8,92.5,-289.5zM1001 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5742em;"><span></span></span></span></span></span></span></span></span></span></p><p>保留边缘的同时抑制噪声。</p><p><strong>小波稀疏</strong>：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>R</mi><mo stretchy="false">(</mo><mi>m</mi><mo stretchy="false">)</mo><mo>=</mo><mi mathvariant="normal">∥</mi><mi mathvariant="normal">Ψ</mi><mi>m</mi><msub><mi mathvariant="normal">∥</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">R(m) = \|\Psi m\|_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mopen">(</span><span class="mord mathnormal">m</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∥Ψ</span><span class="mord mathnormal">m</span><span class="mord"><span class="mord">∥</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p><p>利用图像在小波域的稀疏性。</p><h3 id="gpu-shi-xian-tv-zheng-ze-hua" tabindex="-1" id="GPU-实现-TV-正则化">GPU 实现 TV 正则化</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">__global__ void gradient_kernel(float *image, float *grad_x, float *grad_y,</span><br><span class="line">                                  int H, int W) &#123;</span><br><span class="line">    int x = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    int y = blockIdx.y * blockDim.y + threadIdx.y;</span><br><span class="line">    </span><br><span class="line">    if (x &lt; W &amp;&amp; y &lt; H) &#123;</span><br><span class="line">        int idx = y * W + x;</span><br><span class="line">        </span><br><span class="line">        // 前向差分</span><br><span class="line">        grad_x[idx] = (x &lt; W - 1) ? image[idx + 1] - image[idx] : 0;</span><br><span class="line">        grad_y[idx] = (y &lt; H - 1) ? image[idx + W] - image[idx] : 0;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">__global__ void tv_proximal_kernel(float *grad_x, float *grad_y,</span><br><span class="line">                                     float lambda, int H, int W) &#123;</span><br><span class="line">    int x = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    int y = blockIdx.y * blockDim.y + threadIdx.y;</span><br><span class="line">    </span><br><span class="line">    if (x &lt; W &amp;&amp; y &lt; H) &#123;</span><br><span class="line">        int idx = y * W + x;</span><br><span class="line">        </span><br><span class="line">        float gx = grad_x[idx];</span><br><span class="line">        float gy = grad_y[idx];</span><br><span class="line">        float norm = sqrtf(gx * gx + gy * gy) + 1e-8f;</span><br><span class="line">        </span><br><span class="line">        // 软阈值</span><br><span class="line">        float shrink = fmaxf(1.0f - lambda / norm, 0.0f);</span><br><span class="line">        grad_x[idx] = gx * shrink;</span><br><span class="line">        grad_y[idx] = gy * shrink;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="duo-xian-quan-cheng-xiang" tabindex="-1" id="多线圈成像">多线圈成像</h2><h3 id="bing-xing-cheng-xiang" tabindex="-1" id="并行成像">并行成像</h3><p>现代 MRI 使用<strong>多接收线圈</strong>，每个线圈有不同的灵敏度分布：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>s</mi><mi>c</mi></msub><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo><mo>=</mo><mo>∫</mo><msub><mi>S</mi><mi>c</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>⋅</mo><mi>m</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>⋅</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>i</mi><mn>2</mn><mi>π</mi><mi>k</mi><mo>⋅</mo><mi>x</mi></mrow></msup><mi>d</mi><mi>x</mi></mrow><annotation encoding="application/x-tex">s_c(k) = \int S_c(x) \cdot m(x) \cdot e^{-i2\pi k \cdot x} dx</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.2222em;vertical-align:-0.8622em;"></span><span class="mop op-symbol large-op" style="margin-right:0.44445em;position:relative;top:-0.0011em;">∫</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">m</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8991em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathnormal mtight">i</span><span class="mord mtight">2</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">πk</span><span class="mbin mtight">⋅</span><span class="mord mathnormal mtight">x</span></span></span></span></span></span></span></span></span><span class="mord mathnormal">d</span><span class="mord mathnormal">x</span></span></span></span></span></p><p>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">S_c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 是第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi></mrow><annotation encoding="application/x-tex">c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">c</span></span></span></span> 个线圈的灵敏度。</p><h3 id="sense-zhong-jian" tabindex="-1" id="SENSE-重建">SENSE 重建</h3><p><strong>SENSE（Sensitivity Encoding）</strong>：利用线圈灵敏度差异解混叠。</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mover accent="true"><mi>m</mi><mo>^</mo></mover><mo>=</mo><mi>arg</mi><mo>⁡</mo><munder><mrow><mi>min</mi><mo>⁡</mo></mrow><mi>m</mi></munder><munder><mo>∑</mo><mi>c</mi></munder><mi mathvariant="normal">∥</mi><mi>A</mi><msub><mi>S</mi><mi>c</mi></msub><mi>m</mi><mo>−</mo><msub><mi>s</mi><mi>c</mi></msub><msubsup><mi mathvariant="normal">∥</mi><mn>2</mn><mn>2</mn></msubsup></mrow><annotation encoding="application/x-tex">\hat{m} = \arg\min_m \sum_c \|A S_c m - s_c\|_2^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">m</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.25em;"><span class="mord">^</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.3em;vertical-align:-1.25em;"></span><span class="mop">ar<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6679em;"><span style="top:-2.4em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop">min</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.9em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.25em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">∥</span><span class="mord mathnormal">A</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1141em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord">∥</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span></span></p><h3 id="gpu-shi-xian-1" tabindex="-1" id="GPU-实现-2">GPU 实现</h3><p>多线圈增加了计算量，但也增加了并行度：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">void sense_cg_iteration(</span><br><span class="line">    cuComplex *image,           // [H, W]</span><br><span class="line">    cuComplex **coil_data,      // [num_coils][num_samples]</span><br><span class="line">    cuComplex **sensitivity,    // [num_coils][H, W]</span><br><span class="line">    int num_coils) &#123;</span><br><span class="line">    </span><br><span class="line">    // 并行处理每个线圈</span><br><span class="line">    for (int c = 0; c &lt; num_coils; c++) &#123;</span><br><span class="line">        // 应用灵敏度</span><br><span class="line">        elementwise_multiply(image, sensitivity[c], coil_image, H * W);</span><br><span class="line">        </span><br><span class="line">        // NUFFT</span><br><span class="line">        nufft_forward(coil_image, coil_kspace, trajectory);</span><br><span class="line">        </span><br><span class="line">        // 累加</span><br><span class="line">        vector_add(residual, coil_residual, residual, num_samples);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>线圈间<strong>完全独立</strong>，适合 GPU 并行。</p><h2 id="ya-suo-gan-zhi-mri" tabindex="-1" id="压缩感知-MRI">压缩感知 MRI</h2><h3 id="ji-ben-yuan-li" tabindex="-1" id="基本原理">基本原理</h3><p><strong>压缩感知（Compressed Sensing）</strong>：如果信号在某个域是稀疏的，可以用远少于奈奎斯特采样数的测量重建。</p><p><strong>MRI 中的稀疏性</strong>：</p><ul><li>图像在小波域稀疏</li><li>图像梯度稀疏（分段平滑）</li></ul><h3 id="cs-mri-you-hua-wen-ti" tabindex="-1" id="CS-MRI-优化问题">CS-MRI 优化问题</h3><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mover accent="true"><mi>m</mi><mo>^</mo></mover><mo>=</mo><mi>arg</mi><mo>⁡</mo><munder><mrow><mi>min</mi><mo>⁡</mo></mrow><mi>m</mi></munder><mfrac><mn>1</mn><mn>2</mn></mfrac><mi mathvariant="normal">∥</mi><mi>A</mi><mi>m</mi><mo>−</mo><mi>s</mi><msubsup><mi mathvariant="normal">∥</mi><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><msub><mi>λ</mi><mn>1</mn></msub><mi mathvariant="normal">∥</mi><mi mathvariant="normal">Ψ</mi><mi>m</mi><msub><mi mathvariant="normal">∥</mi><mn>1</mn></msub><mo>+</mo><msub><mi>λ</mi><mn>2</mn></msub><mi>T</mi><mi>V</mi><mo stretchy="false">(</mo><mi>m</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\hat{m} = \arg\min_m \frac{1}{2}\|Am - s\|_2^2 + \lambda_1 \|\Psi m\|_1 + \lambda_2 TV(m)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">m</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.25em;"><span class="mord">^</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.0214em;vertical-align:-0.7em;"></span><span class="mop">ar<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6679em;"><span style="top:-2.4em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop">min</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord">∥</span><span class="mord mathnormal">A</span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1141em;vertical-align:-0.25em;"></span><span class="mord mathnormal">s</span><span class="mord"><span class="mord">∥</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∥Ψ</span><span class="mord mathnormal">m</span><span class="mord"><span class="mord">∥</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mopen">(</span><span class="mord mathnormal">m</span><span class="mclose">)</span></span></span></span></span></p><h3 id="admm-qiu-jie" tabindex="-1" id="ADMM-求解">ADMM 求解</h3><p>**交替方向乘子法（ADMM）**将问题分解为子问题：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1. 数据保真度子问题（CG 求解）</span><br><span class="line">2. 小波稀疏子问题（软阈值）</span><br><span class="line">3. TV 子问题（TV 去噪）</span><br><span class="line">4. 更新拉格朗日乘子</span><br></pre></td></tr></table></figure><p>每个子问题都可以高效并行。</p><h2 id="xing-neng-you-hua" tabindex="-1" id="性能优化">性能优化</h2><h3 id="nei-cun-guan-li" tabindex="-1" id="内存管理">内存管理</h3><p>MRI 数据量大（3D、多线圈、多时相）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">4 线圈 × 256³ 复数 = 4 × 256³ × 8 = 512 MB</span><br></pre></td></tr></table></figure><p><strong>策略</strong>：</p><ul><li>流水线处理时相</li><li>压缩存储低秩数据</li><li>使用统一内存自动管理</li></ul><h3 id="ji-suan-you-hua" tabindex="-1" id="计算优化">计算优化</h3><table><thead><tr><th>操作</th><th>优化策略</th></tr></thead><tbody><tr><td>FFT</td><td>使用 cuFFT，批量处理</td></tr><tr><td>NUFFT</td><td>纹理缓存加速插值</td></tr><tr><td>规约</td><td>Warp Shuffle 高效求和</td></tr><tr><td>TV</td><td>共享内存差分模板</td></tr></tbody></table><h3 id="duo-gpu" tabindex="-1" id="多-GPU">多 GPU</h3><p>MRI 重建天然适合多 GPU：</p><ul><li>线圈间并行</li><li>切片间并行</li><li>时相间并行</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#pragma omp parallel for</span><br><span class="line">for (int c = 0; c &lt; num_coils; c++) &#123;</span><br><span class="line">    int device = c % num_gpus;</span><br><span class="line">    cudaSetDevice(device);</span><br><span class="line">    process_coil(c);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="shi-ji-ying-yong" tabindex="-1" id="实际应用">实际应用</h2><h3 id="jia-su-bei-shu" tabindex="-1" id="加速倍数">加速倍数</h3><table><thead><tr><th>技术</th><th>加速倍数</th></tr></thead><tbody><tr><td>并行成像</td><td>2-4×</td></tr><tr><td>压缩感知</td><td>4-8×</td></tr><tr><td>两者结合</td><td>8-16×</td></tr></tbody></table><p><strong>临床意义</strong>：扫描时间从 10 分钟缩短到 1 分钟，减少患者不适，提高通量。</p><h3 id="gpu-jia-su-xiao-guo" tabindex="-1" id="GPU-加速效果">GPU 加速效果</h3><table><thead><tr><th>平台</th><th>256³ 重建时间</th></tr></thead><tbody><tr><td>单核 CPU</td><td>~300 秒</td></tr><tr><td>多核 CPU (8)</td><td>~40 秒</td></tr><tr><td>GPU (V100)</td><td>~2 秒</td></tr></tbody></table><p><strong>加速比</strong>：150× 以上。</p><h2 id="xiao-jie" tabindex="-1" id="小结">小结</h2><p>第十七章展示了 GPU 在医学影像领域的强大能力：</p><p><strong>MRI 重建本质</strong>：从 k 空间数据恢复图像，涉及傅里叶变换和优化问题。</p><p><strong>NUFFT</strong>：处理非笛卡尔采样的核心算法。GPU 的网格化和 FFT 实现比 CPU 快两个数量级。</p><p><strong>迭代重建</strong>：共轭梯度 + 正则化解决欠采样问题。每次迭代包含 NUFFT、规约、逐元素操作——都是 GPU 擅长的。</p><p><strong>多线圈 + 压缩感知</strong>：进一步加速采集，但计算量增加。GPU 的并行能力正好应对。</p><p><strong>综合应用</strong>：本章综合了前面学的 FFT、矩阵运算、规约、迭代求解等技术，展示了实际问题中如何组合使用这些工具。</p><p>MRI 重建只是医学影像的冰山一角。CT 重建、PET 重建、超声成像都有类似的计算密集型任务，GPU 正在改变整个医学影像领域。</p><h2 id="xia-yi-bu" tabindex="-1" id="🚀-下一步">🚀 下一步</h2><ul><li>实现一个简单的 NUFFT，从 Type-1 和 Type-2 开始，理解网格化和插值的过程</li><li>学习共轭梯度法的 GPU 实现，掌握迭代求解器的优化技巧</li><li>探索不同的正则化方法：TV、小波稀疏、字典学习</li><li>研究压缩感知 MRI，了解稀疏重建的理论基础</li><li>了解其他医学影像重建方法：CT 重建（FBP、迭代重建）、PET 重建</li></ul><hr><h2 id="can-kao-zi-liao" tabindex="-1" id="📚-参考资料">📚 参考资料</h2><ul><li>PMPP 第四版 Chapter 17</li><li><a href="https://smarter.xin/posts/pmmpp-chapter17-mri-reconstruction/">第十七章：迭代式磁共振成像重建</a></li><li>Hwu, W., Kirk, D., &amp; El Hajj, I. (2022). <em>Programming Massively Parallel Processors: A Hands-on Approach</em> (4th Edition). Morgan Kaufmann.</li><li>Lustig, M., Donoho, D., &amp; Pauly, J. M. (2007). <em>Sparse MRI: The Application of Compressed Sensing for Rapid MR Imaging</em>. MRM.</li><li>Fessler, J. A., &amp; Sutton, B. P. (2003). <em>Nonuniform Fast Fourier Transforms Using Min-Max Interpolation</em>. IEEE TSP.</li></ul><p><strong>学习愉快！</strong> 🎓</p><hr><blockquote><p><strong>本文 GitHub 仓库</strong>: <a href="https://github.com/psmarter/PMPP-Learning">https://github.com/psmarter/PMPP-Learning</a></p></blockquote>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h2 id=&quot;qian-yan&quot; tabindex=&quot;-1&quot; id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;前面的章节主要讨论了通用的并行算法和深度学习应用。第十七章转向一个具体的应用领域——&lt;strong&gt;医学影像（Medical</summary>
        
      
    
    
    
    <category term="知识分享" scheme="https://smarter.xin/categories/knowledge-sharing/"/>
    
    
    <category term="CUDA" scheme="https://smarter.xin/tags/CUDA/"/>
    
    <category term="GPU编程" scheme="https://smarter.xin/tags/gpu-programming/"/>
    
    <category term="并行计算" scheme="https://smarter.xin/tags/parallel-computing/"/>
    
    <category term="PMPP" scheme="https://smarter.xin/tags/PMPP/"/>
    
    <category term="MRI" scheme="https://smarter.xin/tags/MRI/"/>
    
    <category term="医学影像" scheme="https://smarter.xin/tags/medical-imaging/"/>
    
    <category term="迭代重建" scheme="https://smarter.xin/tags/iterative-reconstruction/"/>
    
  </entry>
  
  <entry>
    <title>PMPP-第十六章：深度学习</title>
    <link href="https://smarter.xin/posts/feaca34d/"/>
    <id>https://smarter.xin/posts/feaca34d/</id>
    <published>2026-01-19T15:07:59.000Z</published>
    <updated>2026-01-24T11:47:21.463Z</updated>
    
    <content type="html"><![CDATA[<h2 id="qian-yan" tabindex="-1" id="前言">前言</h2><p>前面的章节学习了各种并行算法原语：归约、扫描、排序、稀疏矩阵、图遍历。这些技术在深度学习中都有应用。第十六章将这些技术串联起来，展示 GPU 如何加速<strong>深度学习（Deep Learning）</strong>——当今 GPU 最重要的应用领域之一。本章不深入讲解神经网络理论，而是聚焦于<strong>计算视角</strong>：神经网络的核心操作是什么？GPU 如何高效实现这些操作？</p><blockquote><p><strong>📦 配套资源</strong>：本系列文章配有完整的 <a href="https://github.com/psmarter/PMPP-Learning">GitHub 仓库</a>，包含每章的练习题解答、CUDA 代码实现和详细注释。所有代码都经过测试，可以直接运行。</p></blockquote><h2 id="shen-du-xue-xi-ji-chu" tabindex="-1" id="深度学习基础">深度学习基础</h2><h3 id="shen-jing-wang-luo-de-ji-suan-ben-zhi" tabindex="-1" id="神经网络的计算本质">神经网络的计算本质</h3><p>无论是全连接层、卷积层还是注意力层，神经网络的核心操作都是：</p><ol><li><strong>线性变换</strong>：矩阵乘法（GEMM）</li><li><strong>非线性激活</strong>：ReLU、Sigmoid、Softmax 等</li><li><strong>归约操作</strong>：Pooling、Normalization</li></ol><p><strong>计算量分布</strong>（以 ResNet-50 为例）：</p><ul><li>卷积层：~95% 的计算量</li><li>全连接层：~4%</li><li>其他：~1%</li></ul><p>卷积才是 GPU 优化的主战场。</p><h3 id="shen-du-xue-xi-wei-shi-yao-xu-yao-gpu" tabindex="-1" id="深度学习为什么需要-GPU">深度学习为什么需要 GPU</h3><table><thead><tr><th>特性</th><th>CPU</th><th>GPU</th></tr></thead><tbody><tr><td>核心数</td><td>8-64</td><td>数千</td></tr><tr><td>时钟频率</td><td>3-5 GHz</td><td>1-2 GHz</td></tr><tr><td>峰值算力(FP32)</td><td>~1 TFLOPS</td><td>~30 TFLOPS</td></tr><tr><td>内存带宽</td><td>~100 GB/s</td><td>~1000 GB/s</td></tr></tbody></table><p>深度学习的计算是<strong>高度并行</strong>的：</p><ul><li>批量处理（Batch）：独立样本并行</li><li>空间并行：图像不同位置并行</li><li>通道并行：不同特征图并行</li></ul><p>这是 GPU 的理想场景。</p><h2 id="juan-ji-ceng-de-gpu-shi-xian" tabindex="-1" id="卷积层的-GPU-实现">卷积层的 GPU 实现</h2><h3 id="juan-ji-de-ji-suan-fu-za-du" tabindex="-1" id="卷积的计算复杂度">卷积的计算复杂度</h3><p>给定输入张量 <code>[N, C_in, H, W]</code> 和卷积核 <code>[C_out, C_in, K, K]</code>：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>FLOPs</mtext><mo>=</mo><mn>2</mn><mo>×</mo><mi>N</mi><mo>×</mo><msub><mi>C</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo>×</mo><msub><mi>H</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo>×</mo><msub><mi>W</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo>×</mo><msub><mi>C</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><mo>×</mo><mi>K</mi><mo>×</mo><mi>K</mi></mrow><annotation encoding="application/x-tex">\text{FLOPs} = 2 \times N \times C_{out} \times H_{out} \times W_{out} \times C_{in} \times K \times K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord text"><span class="mord">FLOPs</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0813em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">in</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span></span></p><p>对于 ResNet-50 的第一个卷积层：</p><ul><li>输入：<code>[1, 3, 224, 224]</code></li><li>卷积核：<code>[64, 3, 7, 7]</code></li><li>FLOPs ≈ 1.2 亿次</li></ul><p>整个网络约需 40 亿次浮点操作。</p><h3 id="zhi-jie-juan-ji" tabindex="-1" id="直接卷积">直接卷积</h3><p>最直观的实现，第七章已详细讲过：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">__global__ void conv2d_direct(float *input, float *kernel, float *output,</span><br><span class="line">                               int N, int C_in, int H, int W, </span><br><span class="line">                               int C_out, int K) &#123;</span><br><span class="line">    int n = blockIdx.z;</span><br><span class="line">    int c_out = blockIdx.y;</span><br><span class="line">    int h_out = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    int w_out = blockIdx.x * blockDim.y + threadIdx.y;</span><br><span class="line">    </span><br><span class="line">    if (h_out &lt; H_out &amp;&amp; w_out &lt; W_out) &#123;</span><br><span class="line">        float sum = 0.0f;</span><br><span class="line">        for (int c_in = 0; c_in &lt; C_in; c_in++) &#123;</span><br><span class="line">            for (int kh = 0; kh &lt; K; kh++) &#123;</span><br><span class="line">                for (int kw = 0; kw &lt; K; kw++) &#123;</span><br><span class="line">                    int h_in = h_out + kh - K/2;</span><br><span class="line">                    int w_in = w_out + kw - K/2;</span><br><span class="line">                    if (h_in &gt;= 0 &amp;&amp; h_in &lt; H &amp;&amp; w_in &gt;= 0 &amp;&amp; w_in &lt; W) &#123;</span><br><span class="line">                        sum += input[...] * kernel[...];</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        output[...] = sum;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>问题</strong>：循环太多，内存访问不规则，效率低。</p><h3 id="im-2-col-gemm" tabindex="-1" id="Im2col-GEMM">Im2col + GEMM</h3><p><strong>核心思想</strong>：把卷积转化为矩阵乘法。</p><p><strong>Im2col</strong>：把输入的每个滑动窗口展开成一列。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">输入图像 [C_in, H, W]，卷积核 [K, K]</span><br><span class="line"></span><br><span class="line">Im2col 后：</span><br><span class="line">  列数 = H_out × W_out</span><br><span class="line">  行数 = C_in × K × K</span><br><span class="line"></span><br><span class="line">每一列对应一个滑动窗口的展开</span><br></pre></td></tr></table></figure><p><strong>转换后</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输出 = Kernel × Im2col(Input)</span><br><span class="line">[C_out, H_out×W_out] = [C_out, C_in×K×K] × [C_in×K×K, H_out×W_out]</span><br></pre></td></tr></table></figure><p>这是标准的 GEMM！可以调用高度优化的 cuBLAS。</p><p><strong>代价</strong>：Im2col 需要额外内存，约为原输入的 K² 倍。</p><h3 id="winograd-juan-ji" tabindex="-1" id="Winograd-卷积">Winograd 卷积</h3><p><strong>核心思想</strong>：用更多加法换更少乘法。</p><p>对于 3×3 卷积，Winograd F(2×2, 3×3) 可以把乘法次数从 36 减少到 16。</p><p><strong>公式</strong>：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>Y</mi><mo>=</mo><msup><mi>A</mi><mi>T</mi></msup><mrow><mo fence="true">[</mo><mo stretchy="false">(</mo><mi>G</mi><mo>⋅</mo><mi>g</mi><mo>⋅</mo><msup><mi>G</mi><mi>T</mi></msup><mo stretchy="false">)</mo><mo>⊙</mo><mo stretchy="false">(</mo><msup><mi>B</mi><mi>T</mi></msup><mo>⋅</mo><mi>d</mi><mo>⋅</mo><mi>B</mi><mo stretchy="false">)</mo><mo fence="true">]</mo></mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">Y = A^T \left[ (G \cdot g \cdot G^T) \odot (B^T \cdot d \cdot B) \right] A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2413em;vertical-align:-0.35em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">[</span></span><span class="mopen">(</span><span class="mord mathnormal">G</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⊙</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal">d</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mclose">)</span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">]</span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">A</span></span></span></span></span></p><p>其中：</p><ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi></mrow><annotation encoding="application/x-tex">g</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span></span></span>：卷积核</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">d</span></span></span></span>：输入 Tile</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo separator="true">,</mo><mi>B</mi><mo separator="true">,</mo><mi>A</mi></mrow><annotation encoding="application/x-tex">G, B, A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">G</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">A</span></span></span></span>：变换矩阵</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⊙</mo></mrow><annotation encoding="application/x-tex">\odot</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord">⊙</span></span></span></span>：逐元素乘法</li></ul><p><strong>优势</strong>：计算量减少 2.25 倍（理论上）。</p><p><strong>限制</strong>：</p><ul><li>只适合小卷积核（3×3 最常用）</li><li>数值稳定性问题</li><li>实现复杂</li></ul><h3 id="fft-juan-ji" tabindex="-1" id="FFT-卷积">FFT 卷积</h3><p><strong>核心思想</strong>：卷积定理——时域卷积 = 频域逐元素乘法。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Output = IFFT(FFT(Input) ⊙ FFT(Kernel))</span><br></pre></td></tr></table></figure><p><strong>复杂度</strong>：O(N² log N) vs 直接卷积的 O(N² K²)</p><p><strong>适用场景</strong>：大卷积核（K &gt; 7）。深度学习中卷积核通常很小（1×1, 3×3），所以 FFT 卷积较少使用。</p><h3 id="cu-dnn-ce-lue-xuan-ze" tabindex="-1" id="cuDNN-策略选择">cuDNN 策略选择</h3><p>cuDNN 内置多种卷积算法，会根据问题规模自动选择：</p><table><thead><tr><th>算法</th><th>适用场景</th></tr></thead><tbody><tr><td>IMPLICIT_GEMM</td><td>通用</td></tr><tr><td>IMPLICIT_PRECOMP_GEMM</td><td>大 Batch</td></tr><tr><td>GEMM</td><td>小卷积核</td></tr><tr><td>WINOGRAD</td><td>3×3 卷积</td></tr><tr><td>FFT</td><td>大卷积核</td></tr></tbody></table><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cudnnConvolutionFwdAlgoPerf_t perfResults[8];</span><br><span class="line">cudnnFindConvolutionForwardAlgorithm(</span><br><span class="line">    handle, inputDesc, filterDesc, convDesc, outputDesc,</span><br><span class="line">    8, &amp;returnedAlgoCount, perfResults);</span><br><span class="line"></span><br><span class="line">// 选择最快的算法</span><br><span class="line">cudnnConvolutionFwdAlgo_t algo = perfResults[0].algo;</span><br></pre></td></tr></table></figure><h2 id="quan-lian-jie-ceng" tabindex="-1" id="全连接层">全连接层</h2><h3 id="ben-zhi-ju-zhen-cheng-fa" tabindex="-1" id="本质：矩阵乘法">本质：矩阵乘法</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y = W × x + b</span><br><span class="line">[out_features] = [out_features, in_features] × [in_features] + [out_features]</span><br></pre></td></tr></table></figure><p>批量处理：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Y = X × W^T + B</span><br><span class="line">[batch, out] = [batch, in] × [in, out] + [batch, out]</span><br></pre></td></tr></table></figure><p>直接调用 cuBLAS GEMM 即可。</p><h3 id="you-hua-tensor-core" tabindex="-1" id="优化：Tensor-Core">优化：Tensor Core</h3><p>从 Volta 架构开始，GPU 有专门的 Tensor Core：</p><table><thead><tr><th>操作</th><th>CUDA Core</th><th>Tensor Core</th></tr></thead><tbody><tr><td>4×4 矩阵乘加</td><td>128 FLOPs</td><td>1 周期</td></tr><tr><td>精度</td><td>FP32</td><td>FP16/BF16</td></tr><tr><td>峰值算力(A100)</td><td>19 TFLOPS</td><td>312 TFLOPS</td></tr></tbody></table><p>使用 Tensor Core 需要：</p><ol><li>数据类型为 FP16 或 BF16</li><li>矩阵维度是 8 或 16 的倍数</li><li>使用 cuBLAS 或 WMMA API</li></ol><h2 id="ji-huo-han-shu" tabindex="-1" id="激活函数">激活函数</h2><h3 id="re-lu" tabindex="-1" id="ReLU">ReLU</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">__global__ void relu(float *x, int n) &#123;</span><br><span class="line">    int i = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    if (i &lt; n) &#123;</span><br><span class="line">        x[i] = max(x[i], 0.0f);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>计算简单，属于 <strong>Memory-Bound</strong>：访存时间远大于计算时间。</p><p><strong>Fusion 优化</strong>：把 ReLU 融合到卷积 Kernel 中，避免额外的内存读写。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// 卷积结果直接应用 ReLU</span><br><span class="line">output[idx] = max(conv_result, 0.0f);</span><br></pre></td></tr></table></figure><h3 id="softmax" tabindex="-1" id="Softmax">Softmax</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">// 数值稳定版本</span><br><span class="line">__global__ void softmax(float *x, float *y, int n) &#123;</span><br><span class="line">    // 1. 找最大值（规约）</span><br><span class="line">    float max_val = reduce_max(x, n);</span><br><span class="line">    </span><br><span class="line">    // 2. exp(x - max) 并求和（规约）</span><br><span class="line">    float sum = 0;</span><br><span class="line">    for (int i = threadIdx.x; i &lt; n; i += blockDim.x) &#123;</span><br><span class="line">        sum += expf(x[i] - max_val);</span><br><span class="line">    &#125;</span><br><span class="line">    sum = reduce_sum(sum);</span><br><span class="line">    </span><br><span class="line">    // 3. 归一化</span><br><span class="line">    for (int i = threadIdx.x; i &lt; n; i += blockDim.x) &#123;</span><br><span class="line">        y[i] = expf(x[i] - max_val) / sum;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>需要两次归约，三次遍历数据。</p><h2 id="pooling-ceng" tabindex="-1" id="Pooling-层">Pooling 层</h2><h3 id="max-pooling" tabindex="-1" id="Max-Pooling">Max Pooling</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">__global__ void max_pool2d(float *input, float *output,</span><br><span class="line">                            int H, int W, int pool_size, int stride) &#123;</span><br><span class="line">    int h_out = blockIdx.y * blockDim.y + threadIdx.y;</span><br><span class="line">    int w_out = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    </span><br><span class="line">    float max_val = -FLT_MAX;</span><br><span class="line">    for (int ph = 0; ph &lt; pool_size; ph++) &#123;</span><br><span class="line">        for (int pw = 0; pw &lt; pool_size; pw++) &#123;</span><br><span class="line">            int h_in = h_out * stride + ph;</span><br><span class="line">            int w_in = w_out * stride + pw;</span><br><span class="line">            max_val = max(max_val, input[h_in * W + w_in]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    output[h_out * W_out + w_out] = max_val;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>类似于卷积，但用 max 替代加权和。</p><h3 id="global-average-pooling" tabindex="-1" id="Global-Average-Pooling">Global Average Pooling</h3><p>对整个特征图求平均：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">// 就是一个 2D 归约！</span><br><span class="line">float sum = reduce_2d(feature_map, H, W);</span><br><span class="line">output = sum / (H * W);</span><br></pre></td></tr></table></figure><p>第十章的归约技术直接适用。</p><h2 id="batch-normalization" tabindex="-1" id="Batch-Normalization">Batch Normalization</h2><h3 id="ji-suan-guo-cheng" tabindex="-1" id="计算过程">计算过程</h3><ol><li><strong>计算均值</strong>：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi><mo>=</mo><mfrac><mn>1</mn><mi>m</mi></mfrac><mo>∑</mo><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\mu = \frac{1}{m} \sum x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">μ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>（归约）</li><li><strong>计算方差</strong>：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>σ</mi><mn>2</mn></msup><mo>=</mo><mfrac><mn>1</mn><mi>m</mi></mfrac><mo>∑</mo><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>−</mo><mi>μ</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\sigma^2 = \frac{1}{m} \sum (x_i - \mu)^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord mathnormal">μ</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>（归约）</li><li><strong>归一化</strong>：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>x</mi><mo>^</mo></mover><mo>=</mo><mfrac><mrow><mi>x</mi><mo>−</mo><mi>μ</mi></mrow><msqrt><mrow><msup><mi>σ</mi><mn>2</mn></msup><mo>+</mo><mi>ϵ</mi></mrow></msqrt></mfrac></mrow><annotation encoding="application/x-tex">\hat{x} = \frac{x - \mu}{\sqrt{\sigma^2 + \epsilon}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">x</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.3924em;vertical-align:-0.538em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8544em;"><span style="top:-2.5445em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord sqrt mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9221em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mtight" style="padding-left:0.833em;"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7463em;"><span style="top:-2.786em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">ϵ</span></span></span><span style="top:-2.8821em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail mtight" style="min-width:0.853em;height:1.08em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,-221l0 -0c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47zM834 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1179em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.4461em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight">μ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.538em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>（逐元素）</li><li><strong>缩放平移</strong>：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>=</mo><mi>γ</mi><mover accent="true"><mi>x</mi><mo>^</mo></mover><mo>+</mo><mi>β</mi></mrow><annotation encoding="application/x-tex">y = \gamma \hat{x} + \beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">x</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span></span></span></span>（逐元素）</li></ol><h3 id="gpu-shi-xian-yao-dian" tabindex="-1" id="GPU-实现要点">GPU 实现要点</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">__global__ void batch_norm(float *x, float *y, </span><br><span class="line">                           float *gamma, float *beta,</span><br><span class="line">                           int N, int C, int H, int W) &#123;</span><br><span class="line">    int c = blockIdx.x;  // 每个 Block 处理一个通道</span><br><span class="line">    </span><br><span class="line">    // 1. 计算该通道的均值和方差</span><br><span class="line">    float mean = compute_mean(x, c, N, H, W);</span><br><span class="line">    float var = compute_var(x, c, mean, N, H, W);</span><br><span class="line">    </span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    // 2. 归一化并缩放</span><br><span class="line">    for (int i = threadIdx.x; i &lt; N * H * W; i += blockDim.x) &#123;</span><br><span class="line">        float val = x[index(i, c)];</span><br><span class="line">        y[index(i, c)] = gamma[c] * (val - mean) / sqrtf(var + 1e-5f) + beta[c];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>关键是<strong>按通道归约</strong>，每个通道独立处理。</p><h2 id="fan-xiang-chuan-bo" tabindex="-1" id="反向传播">反向传播</h2><h3 id="ji-suan-tu-yu-zi-dong-wei-fen" tabindex="-1" id="计算图与自动微分">计算图与自动微分</h3><p>深度学习框架（PyTorch、TensorFlow）通过<strong>计算图</strong>追踪操作，自动计算梯度。</p><p><strong>前向传播</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x → Conv → ReLU → Pool → FC → Softmax → Loss</span><br></pre></td></tr></table></figure><p><strong>反向传播</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dLoss/dL ← dL/dFC ← dFC/dPool ← dPool/dReLU ← dReLU/dConv ← dConv/dx</span><br></pre></td></tr></table></figure><p>每个操作都有对应的梯度计算 Kernel。</p><h3 id="juan-ji-de-fan-xiang-chuan-bo" tabindex="-1" id="卷积的反向传播">卷积的反向传播</h3><p>卷积的梯度计算也是卷积！</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 对输入的梯度</span><br><span class="line">dL/dInput = Convolution(dL/dOutput, Kernel^T)</span><br><span class="line"></span><br><span class="line"># 对权重的梯度</span><br><span class="line">dL/dKernel = Convolution(Input, dL/dOutput)</span><br></pre></td></tr></table></figure><p>所以卷积的优化同样适用于反向传播。</p><h2 id="cu-dnn-jie-kou" tabindex="-1" id="cuDNN-接口">cuDNN 接口</h2><h3 id="ji-ben-shi-yong" tabindex="-1" id="基本使用">基本使用</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;cudnn.h&gt;</span><br><span class="line"></span><br><span class="line">// 1. 创建句柄</span><br><span class="line">cudnnHandle_t handle;</span><br><span class="line">cudnnCreate(&amp;handle);</span><br><span class="line"></span><br><span class="line">// 2. 创建张量描述符</span><br><span class="line">cudnnTensorDescriptor_t inputDesc, outputDesc;</span><br><span class="line">cudnnCreateTensorDescriptor(&amp;inputDesc);</span><br><span class="line">cudnnSetTensor4dDescriptor(inputDesc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT,</span><br><span class="line">                           N, C, H, W);</span><br><span class="line"></span><br><span class="line">// 3. 创建卷积描述符</span><br><span class="line">cudnnConvolutionDescriptor_t convDesc;</span><br><span class="line">cudnnCreateConvolutionDescriptor(&amp;convDesc);</span><br><span class="line">cudnnSetConvolution2dDescriptor(convDesc, pad, pad, stride, stride, 1, 1,</span><br><span class="line">                                 CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT);</span><br><span class="line"></span><br><span class="line">// 4. 查询工作空间大小</span><br><span class="line">size_t workspaceSize;</span><br><span class="line">cudnnGetConvolutionForwardWorkspaceSize(handle, inputDesc, filterDesc,</span><br><span class="line">                                         convDesc, outputDesc, algo, &amp;workspaceSize);</span><br><span class="line"></span><br><span class="line">// 5. 分配工作空间并执行</span><br><span class="line">void *workspace;</span><br><span class="line">cudaMalloc(&amp;workspace, workspaceSize);</span><br><span class="line"></span><br><span class="line">float alpha = 1.0f, beta = 0.0f;</span><br><span class="line">cudnnConvolutionForward(handle, &amp;alpha, inputDesc, input,</span><br><span class="line">                        filterDesc, filter, convDesc, algo,</span><br><span class="line">                        workspace, workspaceSize,</span><br><span class="line">                        &amp;beta, outputDesc, output);</span><br></pre></td></tr></table></figure><h3 id="chang-yong-cao-zuo" tabindex="-1" id="常用操作">常用操作</h3><table><thead><tr><th>操作</th><th>函数</th></tr></thead><tbody><tr><td>卷积前向</td><td>cudnnConvolutionForward</td></tr><tr><td>卷积反向（数据）</td><td>cudnnConvolutionBackwardData</td></tr><tr><td>卷积反向（权重）</td><td>cudnnConvolutionBackwardFilter</td></tr><tr><td>池化</td><td>cudnnPoolingForward/Backward</td></tr><tr><td>激活</td><td>cudnnActivationForward/Backward</td></tr><tr><td>BatchNorm</td><td>cudnnBatchNormForward/Backward</td></tr><tr><td>Softmax</td><td>cudnnSoftmaxForward/Backward</td></tr></tbody></table><h2 id="hun-he-jing-du-xun-lian" tabindex="-1" id="混合精度训练">混合精度训练</h2><h3 id="fp-16-de-you-shi" tabindex="-1" id="FP16-的优势">FP16 的优势</h3><table><thead><tr><th>精度</th><th>存储</th><th>带宽</th><th>算力(A100)</th></tr></thead><tbody><tr><td>FP32</td><td>4 字节</td><td>1×</td><td>19 TFLOPS</td></tr><tr><td>FP16</td><td>2 字节</td><td>2×</td><td>312 TFLOPS</td></tr></tbody></table><h3 id="zi-dong-hun-he-jing-du-amp" tabindex="-1" id="自动混合精度（AMP）">自动混合精度（AMP）</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># PyTorch 示例</span></span><br><span class="line"><span class="keyword">from</span> torch.cuda.amp <span class="keyword">import</span> autocast, GradScaler</span><br><span class="line"></span><br><span class="line">scaler = GradScaler()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> data, target <span class="keyword">in</span> dataloader:</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> autocast():  <span class="comment"># 自动转换到 FP16</span></span><br><span class="line">        output = model(data)</span><br><span class="line">        loss = criterion(output, target)</span><br><span class="line">    </span><br><span class="line">    scaler.scale(loss).backward()  <span class="comment"># 梯度缩放</span></span><br><span class="line">    scaler.step(optimizer)</span><br><span class="line">    scaler.update()</span><br></pre></td></tr></table></figure><p><strong>Loss Scaling</strong>：防止 FP16 梯度下溢，先放大 Loss，计算完梯度后缩小。</p><h2 id="xiao-jie" tabindex="-1" id="小结">小结</h2><p>第十六章展示了深度学习与 GPU 并行计算的紧密联系：</p><p><strong>核心操作</strong>：深度学习的计算本质是矩阵乘法（GEMM）和卷积。这两个操作占据了 95% 以上的计算量。</p><p><strong>卷积实现</strong>：直接卷积简单但低效；Im2col + GEMM 转化为矩阵乘法；Winograd 减少乘法次数；cuDNN 自动选择最优策略。</p><p><strong>融合优化</strong>：把多个操作融合到一个 Kernel 中，减少内存访问。ReLU、BatchNorm 等常与卷积融合。</p><p><strong>Tensor Core</strong>：专用硬件加速矩阵运算，FP16 峰值算力是 FP32 的 16 倍。混合精度训练已成为标准做法。</p><p><strong>cuDNN</strong>：封装了所有优化，是深度学习框架的底层依赖。理解其原理有助于调优和调试。</p><p>深度学习是 GPU 计算的&quot;杀手级应用&quot;，正是这一需求推动了 GPU 硬件和软件的飞速发展。掌握本章内容，你就能理解 PyTorch、TensorFlow 在底层是如何工作的。</p><h2 id="xia-yi-bu" tabindex="-1" id="🚀-下一步">🚀 下一步</h2><ul><li>深入学习 cuDNN 的 API，尝试手动调用不同的卷积算法并对比性能</li><li>实现一个简单的卷积神经网络，从零开始构建前向和反向传播</li><li>探索混合精度训练，了解 FP16/BF16 的使用场景和注意事项</li><li>学习 Tensor Core 编程，使用 WMMA API 实现自定义的矩阵乘法</li><li>研究算子融合技术，将多个操作合并到一个 Kernel 中</li></ul><hr><h2 id="can-kao-zi-liao" tabindex="-1" id="📚-参考资料">📚 参考资料</h2><ul><li>PMPP 第四版 Chapter 16</li><li><a href="https://smarter.xin/posts/pmmpp-chapter16-deep-learning/">第十六章：深度学习</a></li><li>Hwu, W., Kirk, D., &amp; El Hajj, I. (2022). <em>Programming Massively Parallel Processors: A Hands-on Approach</em> (4th Edition). Morgan Kaufmann.</li><li><a href="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/">NVIDIA cuDNN Developer Guide</a></li><li>Lavin, A., &amp; Gray, S. (2016). <em>Fast Algorithms for Convolutional Neural Networks</em>. CVPR.</li></ul><p><strong>学习愉快！</strong> 🎓</p><hr><blockquote><p><strong>本文 GitHub 仓库</strong>: <a href="https://github.com/psmarter/PMPP-Learning">https://github.com/psmarter/PMPP-Learning</a></p></blockquote>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h2 id=&quot;qian-yan&quot; tabindex=&quot;-1&quot; id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;前面的章节学习了各种并行算法原语：归约、扫描、排序、稀疏矩阵、图遍历。这些技术在深度学习中都有应用。第十六章将这些技术串联起来，展示 GPU</summary>
        
      
    
    
    
    <category term="知识分享" scheme="https://smarter.xin/categories/knowledge-sharing/"/>
    
    
    <category term="深度学习" scheme="https://smarter.xin/tags/deep-learning/"/>
    
    <category term="CUDA" scheme="https://smarter.xin/tags/CUDA/"/>
    
    <category term="GPU编程" scheme="https://smarter.xin/tags/gpu-programming/"/>
    
    <category term="并行计算" scheme="https://smarter.xin/tags/parallel-computing/"/>
    
    <category term="PMPP" scheme="https://smarter.xin/tags/PMPP/"/>
    
    <category term="卷积神经网络" scheme="https://smarter.xin/tags/convolutional-neural-network/"/>
    
    <category term="cuDNN" scheme="https://smarter.xin/tags/cuDNN/"/>
    
  </entry>
  
  <entry>
    <title>PMPP-第十五章：图遍历</title>
    <link href="https://smarter.xin/posts/70b05668/"/>
    <id>https://smarter.xin/posts/70b05668/</id>
    <published>2026-01-19T08:12:39.000Z</published>
    <updated>2026-01-24T11:47:21.463Z</updated>
    
    <content type="html"><![CDATA[<h2 id="qian-yan" tabindex="-1" id="前言">前言</h2><p>第十四章我们学习了稀疏矩阵，那一章的重点是 SpMV（稀疏矩阵-向量乘法）。其实，<strong>图（Graph）<strong>和稀疏矩阵是一体两面的：图的邻接矩阵通常就是稀疏矩阵。第十五章我们将深入探讨图算法的核心——<strong>图遍历</strong>，特别是</strong>广度优先搜索（BFS）</strong>。BFS 是最短路径、连通分量、最大流等众多图算法的基础，也是 GPU 处理不规则数据结构的典型案例。</p><blockquote><p><strong>📦 配套资源</strong>：本系列文章配有完整的 <a href="https://github.com/psmarter/PMPP-Learning">GitHub 仓库</a>，包含每章的练习题解答、CUDA 代码实现和详细注释。所有代码都经过测试，可以直接运行。</p></blockquote><h2 id="tu-de-biao-shi" tabindex="-1" id="图的表示">图的表示</h2><h3 id="cong-xian-shi-shi-jie-dao-tu" tabindex="-1" id="从现实世界到图">从现实世界到图</h3><p>图由节点（Vertex）和边（Edge）组成。</p><ul><li><strong>社交网络</strong>：节点是人，边是关注/好友关系。</li><li><strong>道路网</strong>：节点是路口，边是道路。</li><li><strong>引用网络</strong>：节点是论文，边是引用关系。</li></ul><p>这些图通常是<strong>稀疏</strong>的（每个节点平均只连接少数其他节点）且<strong>无标度</strong>的（少数节点有极多连接，俗称&quot;大V&quot;）。</p><h3 id="cun-chu-ge-shi-csr" tabindex="-1" id="存储格式：CSR">存储格式：CSR</h3><p>上一章介绍的 <strong>CSR (Compressed Sparse Row)</strong> 格式不仅适合 SpMV，也是存储图的标准格式。</p><p>对于一个有 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span> 个节点、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi></mrow><annotation encoding="application/x-tex">E</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span></span></span></span> 条边的图：</p><ul><li><strong>row_ptr</strong> (长度 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">V+1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span>)：<code>row_ptr[i]</code> 指向节点 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span> 的邻居列表在 <code>col_idx</code> 中的起始位置。</li><li><strong>col_idx</strong> (长度 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi></mrow><annotation encoding="application/x-tex">E</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span></span></span></span>)：存储所有边的目标节点。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">节点 0 的邻居：col_idx[row_ptr[0]] ... col_idx[row_ptr[1]-1]</span><br><span class="line">节点 i 的邻居数：row_ptr[i+1] - row_ptr[i]</span><br></pre></td></tr></table></figure><h2 id="yan-du-you-xian-sou-suo-bfs" tabindex="-1" id="广度优先搜索-BFS">广度优先搜索 (BFS)</h2><h3 id="wen-ti-ding-yi" tabindex="-1" id="问题定义">问题定义</h3><p>给定起点 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span>，BFS 需要访问所有可达节点，并计算从 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span> 到每个节点的最短距离（层数）。</p><h3 id="chuan-xing-bfs" tabindex="-1" id="串行-BFS">串行 BFS</h3><p>经典实现使用<strong>队列（Queue）</strong>：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">BFS_sequential</span><span class="params">(<span class="type">int</span> S, <span class="type">int</span> *row_ptr, <span class="type">int</span> *col_idx, <span class="type">int</span> *level, <span class="type">int</span> num_nodes)</span> </span>&#123;</span><br><span class="line">    std::queue&lt;<span class="type">int</span>&gt; q;</span><br><span class="line">    q.<span class="built_in">push</span>(S);</span><br><span class="line">    level[S] = <span class="number">0</span>; <span class="comment">// 初始化其他为 -1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (!q.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">        <span class="type">int</span> u = q.<span class="built_in">front</span>(); q.<span class="built_in">pop</span>();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 遍历所有邻居 v</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = row_ptr[u]; i &lt; row_ptr[u<span class="number">+1</span>]; i++) &#123;</span><br><span class="line">            <span class="type">int</span> v = col_idx[i];</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 如果 v 未被访问</span></span><br><span class="line">            <span class="keyword">if</span> (level[v] == <span class="number">-1</span>) &#123;</span><br><span class="line">                level[v] = level[u] + <span class="number">1</span>;</span><br><span class="line">                q.<span class="built_in">push</span>(v);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="bing-xing-hua-de-tiao-zhan" tabindex="-1" id="并行化的挑战">并行化的挑战</h3><ol><li><strong>不规则访问</strong>：每个节点的邻居数量差异巨大（负载不均衡）。</li><li><strong>动态工作集</strong>：每一层的节点数都在变化。</li><li><strong>并发冲突</strong>：多个节点可能同时尝试访问同一个邻居。</li></ol><h2 id="bing-xing-bfs-an-ceng-tong-bu" tabindex="-1" id="并行-BFS：按层同步">并行 BFS：按层同步</h2><p>GPU 适合解决可以分层的任务。BFS 天然分层：<br>第 0 层（起点） → 第 1 层邻居 → 第 2 层邻居 → …</p><p>我们可以采用**按层同步（Level Synchronous）**的方法：</p><ol><li>维护一个**前沿（Frontier）**数组，标记当前层需要扩展的节点</li><li>并行处理 Frontier 中的每个节点，找到下一层的邻居</li><li>更新 Frontier，进入下一轮迭代</li></ol><h3 id="fang-fa-yi-bu-er-qian-yan-shu-zu" tabindex="-1" id="方法一：布尔前沿数组">方法一：布尔前沿数组</h3><p>用一个布尔数组 <code>F</code> 表示当前层节点，<code>next_F</code> 表示下一层。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">__global__ void BFS_kernel_boolean(int *row_ptr, int *col_idx, int *level, </span><br><span class="line">                                   bool *F, bool *next_F, int num_nodes, </span><br><span class="line">                                   int current_depth) &#123;</span><br><span class="line">    int tid = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    </span><br><span class="line">    if (tid &lt; num_nodes &amp;&amp; F[tid]) &#123;</span><br><span class="line">        // 遍历邻居</span><br><span class="line">        int start = row_ptr[tid];</span><br><span class="line">        int end = row_ptr[tid + 1];</span><br><span class="line">        </span><br><span class="line">        for (int i = start; i &lt; end; i++) &#123;</span><br><span class="line">            int neighbor = col_idx[i];</span><br><span class="line">            </span><br><span class="line">            // 使用原子比较交换确保只更新一次</span><br><span class="line">            if (atomicCAS(&amp;level[neighbor], -1, current_depth + 1) == -1) &#123;</span><br><span class="line">                next_F[neighbor] = true;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>Host 端循环</strong>：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">bool</span> *d_F, *d_next_F;</span><br><span class="line"><span class="built_in">cudaMalloc</span>(&amp;d_F, num_nodes * <span class="built_in">sizeof</span>(<span class="type">bool</span>));</span><br><span class="line"><span class="built_in">cudaMalloc</span>(&amp;d_next_F, num_nodes * <span class="built_in">sizeof</span>(<span class="type">bool</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 初始化：只有源节点在前沿</span></span><br><span class="line"><span class="built_in">cudaMemset</span>(d_F, <span class="number">0</span>, num_nodes * <span class="built_in">sizeof</span>(<span class="type">bool</span>));</span><br><span class="line"><span class="built_in">cudaMemset</span>(d_next_F, <span class="number">0</span>, num_nodes * <span class="built_in">sizeof</span>(<span class="type">bool</span>));</span><br><span class="line"><span class="type">bool</span> h_start = <span class="literal">true</span>;</span><br><span class="line"><span class="built_in">cudaMemcpy</span>(&amp;d_F[source], &amp;h_start, <span class="built_in">sizeof</span>(<span class="type">bool</span>), cudaMemcpyHostToDevice);</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> depth = <span class="number">0</span>;</span><br><span class="line"><span class="type">bool</span> frontier_not_empty = <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> (frontier_not_empty) &#123;</span><br><span class="line">    <span class="type">int</span> grid_size = (num_nodes + <span class="number">255</span>) / <span class="number">256</span>;</span><br><span class="line">    BFS_kernel_boolean&lt;&lt;&lt;grid_size, <span class="number">256</span>&gt;&gt;&gt;(</span><br><span class="line">        d_row_ptr, d_col_idx, d_level, d_F, d_next_F, num_nodes, depth</span><br><span class="line">    );</span><br><span class="line">    <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 检查是否还有节点在前沿</span></span><br><span class="line">    <span class="comment">// （简化版，实际应该用 thrust::reduce 或自定义 kernel）</span></span><br><span class="line">    <span class="type">bool</span> h_F[num_nodes];</span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(h_F, d_next_F, num_nodes * <span class="built_in">sizeof</span>(<span class="type">bool</span>), cudaMemcpyDeviceToHost);</span><br><span class="line">    frontier_not_empty = <span class="literal">false</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; num_nodes; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (h_F[i]) &#123;</span><br><span class="line">            frontier_not_empty = <span class="literal">true</span>;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 交换前沿</span></span><br><span class="line">    std::<span class="built_in">swap</span>(d_F, d_next_F);</span><br><span class="line">    <span class="built_in">cudaMemset</span>(d_next_F, <span class="number">0</span>, num_nodes * <span class="built_in">sizeof</span>(<span class="type">bool</span>));</span><br><span class="line">    depth++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>优点</strong>：</p><ul><li>实现简单直观</li><li>每层的并行度很高</li></ul><p><strong>缺点</strong>：</p><ul><li>每层都启动 num_nodes 个线程，工作效率低</li><li>前沿稀疏时浪费严重</li><li>需要频繁的内存拷贝检查终止条件</li></ul><h2 id="you-hua-yi-xi-shu-qian-yan-dui-lie" tabindex="-1" id="优化一：稀疏前沿队列">优化一：稀疏前沿队列</h2><h3 id="gong-zuo-xiao-lu-wen-ti" tabindex="-1" id="工作效率问题">工作效率问题</h3><p>布尔数组方法有一个严重的<strong>工作效率</strong>问题：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">假设图有 100 万个节点，当前层只有 10 个节点在前沿</span><br><span class="line">布尔方法：启动 100 万个线程，其中 99.999% 的线程立即退出</span><br><span class="line">真正工作的线程：10 个</span><br><span class="line">浪费的调度开销：极大</span><br></pre></td></tr></table></figure><p><strong>稀疏前沿（Sparse Frontier）</strong>：<br>只存储当前层节点的 ID，用紧凑的队列表示。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">布尔前沿：[false, true, false, false, false, true, ...]  // 100万个元素</span><br><span class="line">稀疏队列：[1, 5, ...]  // 只有10个元素</span><br></pre></td></tr></table></figure><p>只需启动 <code>frontier_size</code> 个线程，而不是 <code>num_nodes</code> 个。</p><h3 id="fang-fa-er-dui-lie-ban-ben-po-su" tabindex="-1" id="方法二：队列版本（朴素）">方法二：队列版本（朴素）</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">__global__ void BFS_kernel_queue(int *row_ptr, int *col_idx, int *level,</span><br><span class="line">                                  int *current_queue, int current_size,</span><br><span class="line">                                  int *next_queue, int *next_size,</span><br><span class="line">                                  int current_depth) &#123;</span><br><span class="line">    int tid = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    </span><br><span class="line">    if (tid &lt; current_size) &#123;</span><br><span class="line">        int u = current_queue[tid];  // 从队列取节点</span><br><span class="line">        </span><br><span class="line">        // 遍历邻居</span><br><span class="line">        int start = row_ptr[u];</span><br><span class="line">        int end = row_ptr[u + 1];</span><br><span class="line">        </span><br><span class="line">        for (int i = start; i &lt; end; i++) &#123;</span><br><span class="line">            int v = col_idx[i];</span><br><span class="line">            </span><br><span class="line">            // 只有第一个访问的线程能成功更新</span><br><span class="line">            if (atomicCAS(&amp;level[v], -1, current_depth + 1) == -1) &#123;</span><br><span class="line">                // 原子地获取队列位置并插入</span><br><span class="line">                int pos = atomicAdd(next_size, 1);</span><br><span class="line">                next_queue[pos] = v;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>Host 端循环</strong>：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> *d_queue1, *d_queue2;</span><br><span class="line"><span class="type">int</span> *d_queue_size1, *d_queue_size2;</span><br><span class="line"></span><br><span class="line"><span class="built_in">cudaMalloc</span>(&amp;d_queue1, num_nodes * <span class="built_in">sizeof</span>(<span class="type">int</span>));</span><br><span class="line"><span class="built_in">cudaMalloc</span>(&amp;d_queue2, num_nodes * <span class="built_in">sizeof</span>(<span class="type">int</span>));</span><br><span class="line"><span class="built_in">cudaMalloc</span>(&amp;d_queue_size1, <span class="built_in">sizeof</span>(<span class="type">int</span>));</span><br><span class="line"><span class="built_in">cudaMalloc</span>(&amp;d_queue_size2, <span class="built_in">sizeof</span>(<span class="type">int</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 初始化</span></span><br><span class="line"><span class="type">int</span> h_size = <span class="number">1</span>;</span><br><span class="line"><span class="built_in">cudaMemcpy</span>(d_queue1, &amp;source, <span class="built_in">sizeof</span>(<span class="type">int</span>), cudaMemcpyHostToDevice);</span><br><span class="line"><span class="built_in">cudaMemcpy</span>(d_queue_size1, &amp;h_size, <span class="built_in">sizeof</span>(<span class="type">int</span>), cudaMemcpyHostToDevice);</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> depth = <span class="number">0</span>;</span><br><span class="line"><span class="type">int</span> *current_queue = d_queue1;</span><br><span class="line"><span class="type">int</span> *next_queue = d_queue2;</span><br><span class="line"><span class="type">int</span> *current_size = d_queue_size1;</span><br><span class="line"><span class="type">int</span> *next_size = d_queue_size2;</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">    <span class="comment">// 获取当前前沿大小</span></span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(&amp;h_size, current_size, <span class="built_in">sizeof</span>(<span class="type">int</span>), cudaMemcpyDeviceToHost);</span><br><span class="line">    <span class="keyword">if</span> (h_size == <span class="number">0</span>) <span class="keyword">break</span>;  <span class="comment">// 没有节点了，结束</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 重置下一层计数器</span></span><br><span class="line">    <span class="built_in">cudaMemset</span>(next_size, <span class="number">0</span>, <span class="built_in">sizeof</span>(<span class="type">int</span>));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 启动 kernel</span></span><br><span class="line">    <span class="type">int</span> grid_size = (h_size + <span class="number">255</span>) / <span class="number">256</span>;</span><br><span class="line">    BFS_kernel_queue&lt;&lt;&lt;grid_size, <span class="number">256</span>&gt;&gt;&gt;(</span><br><span class="line">        d_row_ptr, d_col_idx, d_level,</span><br><span class="line">        current_queue, h_size, next_queue, next_size, depth</span><br><span class="line">    );</span><br><span class="line">    <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 交换队列</span></span><br><span class="line">    std::<span class="built_in">swap</span>(current_queue, next_queue);</span><br><span class="line">    std::<span class="built_in">swap</span>(current_size, next_size);</span><br><span class="line">    depth++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>优点</strong>：</p><ul><li>只启动必要的线程数</li><li>工作效率大幅提升</li></ul><p><strong>缺点</strong>：</p><ul><li>全局原子操作 <code>atomicAdd(next_size, 1)</code> 成为严重瓶颈</li><li>所有线程争用同一个计数器</li><li>高度数节点会导致大量原子操作</li></ul><h2 id="you-hua-er-si-you-hua-dui-lie" tabindex="-1" id="优化二：私有化队列">优化二：私有化队列</h2><h3 id="jian-shao-yuan-zi-cao-zuo-zheng-yong" tabindex="-1" id="减少原子操作争用">减少原子操作争用</h3><p>类似于第九章的直方图优化，我们可以使用**私有化（Privatization）**技术。</p><p><strong>核心思想</strong>：</p><ol><li>每个 Block 在共享内存维护局部队列</li><li>线程先写入局部队列（只有 Block 内争用）</li><li>Block 结束时一次性申请全局空间</li><li>批量拷贝局部队列到全局</li></ol><h3 id="wan-zheng-shi-xian" tabindex="-1" id="完整实现">完整实现</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line">#define BLOCK_SIZE 256</span><br><span class="line">#define WARP_SIZE 32</span><br><span class="line"></span><br><span class="line">__global__ void BFS_kernel_privatized(</span><br><span class="line">    int *row_ptr, int *col_idx, int *level,</span><br><span class="line">    int *current_queue, int current_size,</span><br><span class="line">    int *next_queue, int *next_size,</span><br><span class="line">    int current_depth) &#123;</span><br><span class="line">    </span><br><span class="line">    __shared__ int s_queue[BLOCK_SIZE * 2];  // 局部队列（预留2倍空间）</span><br><span class="line">    __shared__ int s_tail;                    // 局部队列计数器</span><br><span class="line">    </span><br><span class="line">    // 初始化局部队列</span><br><span class="line">    if (threadIdx.x == 0) &#123;</span><br><span class="line">        s_tail = 0;</span><br><span class="line">    &#125;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    int tid = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    </span><br><span class="line">    if (tid &lt; current_size) &#123;</span><br><span class="line">        int u = current_queue[tid];</span><br><span class="line">        </span><br><span class="line">        // 遍历邻居</span><br><span class="line">        int start = row_ptr[u];</span><br><span class="line">        int end = row_ptr[u + 1];</span><br><span class="line">        </span><br><span class="line">        for (int i = start; i &lt; end; i++) &#123;</span><br><span class="line">            int v = col_idx[i];</span><br><span class="line">            </span><br><span class="line">            // 尝试更新距离</span><br><span class="line">            if (atomicCAS(&amp;level[v], -1, current_depth + 1) == -1) &#123;</span><br><span class="line">                // 成功更新，加入局部队列</span><br><span class="line">                int s_pos = atomicAdd(&amp;s_tail, 1);</span><br><span class="line">                if (s_pos &lt; BLOCK_SIZE * 2) &#123;</span><br><span class="line">                    s_queue[s_pos] = v;</span><br><span class="line">                &#125; else &#123;</span><br><span class="line">                    // 局部队列满了，直接写全局（降级）</span><br><span class="line">                    int g_pos = atomicAdd(next_size, 1);</span><br><span class="line">                    next_queue[g_pos] = v;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    // Block 内线程协作：将局部队列拷贝到全局</span><br><span class="line">    int num_local = min(s_tail, BLOCK_SIZE * 2);</span><br><span class="line">    </span><br><span class="line">    if (num_local &gt; 0) &#123;</span><br><span class="line">        __shared__ int g_offset;</span><br><span class="line">        </span><br><span class="line">        // 一次性申请全局空间</span><br><span class="line">        if (threadIdx.x == 0) &#123;</span><br><span class="line">            g_offset = atomicAdd(next_size, num_local);</span><br><span class="line">        &#125;</span><br><span class="line">        __syncthreads();</span><br><span class="line">        </span><br><span class="line">        // 并行拷贝</span><br><span class="line">        for (int i = threadIdx.x; i &lt; num_local; i += BLOCK_SIZE) &#123;</span><br><span class="line">            next_queue[g_offset + i] = s_queue[i];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>性能分析</strong>：</p><table><thead><tr><th>操作</th><th>布尔方法</th><th>队列朴素</th><th>队列私有化</th></tr></thead><tbody><tr><td>启动线程数</td><td>num_nodes</td><td>frontier 大小</td><td>frontier 大小</td></tr><tr><td>全局原子操作</td><td>0（但有竞争）</td><td>每条边</td><td>每 Block</td></tr><tr><td>共享内存原子</td><td>0</td><td>0</td><td>每条边</td></tr><tr><td>工作效率</td><td>极低</td><td>中等</td><td>高</td></tr><tr><td>相对性能</td><td>1×</td><td>5×</td><td>15×</td></tr></tbody></table><p><strong>关键改进</strong>：</p><ul><li>全局原子操作从 O(边数) 降到 O(Block数)</li><li>共享内存原子操作比全局快 20 倍</li><li>批量拷贝提高内存带宽利用率</li></ul><h2 id="you-hua-san-fang-xiang-you-hua-bfs" tabindex="-1" id="优化三：方向优化-BFS">优化三：方向优化 BFS</h2><h3 id="top-down-vs-bottom-up" tabindex="-1" id="Top-Down-vs-Bottom-Up">Top-Down vs Bottom-Up</h3><p>这是 BFS 优化中最重要的策略之一，源自 Scott Beamer 等人的开创性工作。</p><h3 id="top-down-push-mo-shi" tabindex="-1" id="Top-Down（Push）模式">Top-Down（Push）模式</h3><p>传统的 BFS 是**推（Push）**模式：从前沿节点出发，推送更新到邻居。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">__global__ void BFS_top_down(int *row_ptr, int *col_idx, int *level,</span><br><span class="line">                              int *frontier, int frontier_size,</span><br><span class="line">                              int *next_frontier, int *next_size,</span><br><span class="line">                              int depth) &#123;</span><br><span class="line">    int tid = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    </span><br><span class="line">    if (tid &lt; frontier_size) &#123;</span><br><span class="line">        int u = frontier[tid];</span><br><span class="line">        </span><br><span class="line">        // Push：检查 u 的所有邻居</span><br><span class="line">        for (int i = row_ptr[u]; i &lt; row_ptr[u + 1]; i++) &#123;</span><br><span class="line">            int v = col_idx[i];</span><br><span class="line">            if (atomicCAS(&amp;level[v], -1, depth + 1) == -1) &#123;</span><br><span class="line">                int pos = atomicAdd(next_size, 1);</span><br><span class="line">                next_frontier[pos] = v;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>工作量</strong>：</p><ul><li>遍历前沿节点的所有出边</li><li>工作量 = frontier中节点的总度数</li></ul><p><strong>适用场景</strong>：</p><ul><li>前沿很小（图的早期层）</li><li>平均度数不高</li></ul><h3 id="bottom-up-pull-mo-shi" tabindex="-1" id="Bottom-Up（Pull）模式">Bottom-Up（Pull）模式</h3><p>反向思考：从未访问节点出发，拉取父节点信息。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">__global__ void BFS_bottom_up(int *row_ptr, int *col_idx, int *level,</span><br><span class="line">                               bool *frontier_map, int num_nodes,</span><br><span class="line">                               bool *next_frontier_map, int *found_count,</span><br><span class="line">                               int depth) &#123;</span><br><span class="line">    int v = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    </span><br><span class="line">    if (v &lt; num_nodes &amp;&amp; level[v] == -1) &#123;  // 未访问节点</span><br><span class="line">        // Pull：检查 v 的邻居中是否有在前沿的</span><br><span class="line">        int start = row_ptr[v];</span><br><span class="line">        int end = row_ptr[v + 1];</span><br><span class="line">        </span><br><span class="line">        for (int i = start; i &lt; end; i++) &#123;</span><br><span class="line">            int u = col_idx[i];</span><br><span class="line">            </span><br><span class="line">            // 如果邻居 u 在当前前沿</span><br><span class="line">            if (frontier_map[u]) &#123;</span><br><span class="line">                level[v] = depth + 1;</span><br><span class="line">                next_frontier_map[v] = true;</span><br><span class="line">                atomicAdd(found_count, 1);</span><br><span class="line">                break;  // 找到一个就够了，不需要继续</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>关键差异</strong>：</p><ul><li>Top-Down：遍历 frontier 节点的出边</li><li>Bottom-Up：遍历未访问节点的入边</li><li>Bottom-Up 找到一个父节点就可以停止</li></ul><p><strong>工作量</strong>：</p><ul><li>检查所有未访问节点的入边</li><li>最坏情况：所有未访问节点的总度数</li><li>最好情况：每个节点只检查一条边就找到父节点</li></ul><p><strong>适用场景</strong>：</p><ul><li>前沿很大（覆盖大部分节点）</li><li>图密集度较高</li></ul><h3 id="fang-xiang-qie-huan-ce-lue" tabindex="-1" id="方向切换策略">方向切换策略</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">void BFS_direction_optimizing(Graph &amp;graph, int source, int *level) &#123;</span><br><span class="line">    // 初始化</span><br><span class="line">    cudaMemset(level, -1, num_nodes * sizeof(int));</span><br><span class="line">    // ...</span><br><span class="line">    </span><br><span class="line">    int depth = 0;</span><br><span class="line">    bool use_top_down = true;</span><br><span class="line">    </span><br><span class="line">    while (frontier_not_empty) &#123;</span><br><span class="line">        int frontier_size = get_frontier_size();</span><br><span class="line">        int unvisited_count = num_nodes - visited_count;</span><br><span class="line">        int frontier_edges = estimate_frontier_edges(frontier);</span><br><span class="line">        </span><br><span class="line">        // 方向切换启发式</span><br><span class="line">        if (use_top_down) &#123;</span><br><span class="line">            // 切换到 Bottom-Up 的条件：</span><br><span class="line">            // 前沿边数 &gt; 未访问节点边数的一定比例</span><br><span class="line">            if (frontier_edges &gt; unvisited_count * ALPHA) &#123;</span><br><span class="line">                use_top_down = false;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            // 切回 Top-Down 的条件：</span><br><span class="line">            // 前沿节点数 &lt; 总节点数的一定比例</span><br><span class="line">            if (frontier_size &lt; num_nodes * BETA) &#123;</span><br><span class="line">                use_top_down = true;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        if (use_top_down) &#123;</span><br><span class="line">            BFS_top_down&lt;&lt;&lt;...&gt;&gt;&gt;(...);</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            BFS_bottom_up&lt;&lt;&lt;...&gt;&gt;&gt;(...);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        depth++;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>典型参数</strong>：</p><ul><li>ALPHA = 14（前沿边数超过未访问边数的14倍时切换）</li><li>BETA = 0.001（前沿小于总节点数的0.1%时切回）</li></ul><p><strong>性能提升</strong>：</p><table><thead><tr><th>图类型</th><th>Top-Down</th><th>Bottom-Up</th><th>混合策略</th></tr></thead><tbody><tr><td>社交网络</td><td>1×</td><td>0.8×</td><td>3×</td></tr><tr><td>路网</td><td>1×</td><td>0.5×</td><td>1.2×</td></tr><tr><td>随机图</td><td>1×</td><td>1.5×</td><td>2×</td></tr><tr><td>无标度网络</td><td>1×</td><td>0.6×</td><td>4×</td></tr></tbody></table><p>混合策略在各种图上都有显著提升。</p><h2 id="you-hua-si-fu-zai-jun-heng-ce-lue" tabindex="-1" id="优化四：负载均衡策略">优化四：负载均衡策略</h2><h3 id="wu-biao-du-wang-luo-de-tiao-zhan" tabindex="-1" id="无标度网络的挑战">无标度网络的挑战</h3><p>真实世界的图（社交网络、互联网）通常是**无标度（Scale-Free）**的：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">度数分布：</span><br><span class="line">节点数 | 度数范围</span><br><span class="line">-------|----------</span><br><span class="line">90%    | 1-10</span><br><span class="line">9%     | 10-100</span><br><span class="line">0.9%   | 100-1000</span><br><span class="line">0.1%   | 1000+（高度数&quot;Hub&quot;节点）</span><br></pre></td></tr></table></figure><p><strong>问题</strong>：一个线程处理一个节点导致严重的负载不均衡。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Warp 0:</span><br><span class="line">线程 0: 处理节点度数 = 3     （3次迭代）</span><br><span class="line">线程 1: 处理节点度数 = 100000 （10万次迭代）</span><br><span class="line">线程 2-31: 处理节点度数 = 5   （5次迭代）</span><br><span class="line"></span><br><span class="line">→ 整个 Warp 等待线程 1 完成</span><br><span class="line">→ Warp 利用率：3%</span><br></pre></td></tr></table></figure><h3 id="fen-ceng-fu-zai-jun-heng" tabindex="-1" id="分层负载均衡">分层负载均衡</h3><p>根据节点度数选择不同的处理策略：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">__global__ void BFS_adaptive(int *row_ptr, int *col_idx, int *level,</span><br><span class="line">                              int *frontier, int frontier_size,</span><br><span class="line">                              int *next_frontier, int *next_size,</span><br><span class="line">                              int depth) &#123;</span><br><span class="line">    int tid = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    </span><br><span class="line">    if (tid &lt; frontier_size) &#123;</span><br><span class="line">        int u = frontier[tid];</span><br><span class="line">        int degree = row_ptr[u + 1] - row_ptr[u];</span><br><span class="line">        </span><br><span class="line">        if (degree &lt; 32) &#123;</span><br><span class="line">            // 小度数节点：单线程处理</span><br><span class="line">            process_node_single(u, row_ptr, col_idx, level, </span><br><span class="line">                                next_frontier, next_size, depth);</span><br><span class="line">        &#125; else if (degree &lt; 512) &#123;</span><br><span class="line">            // 中等度数：Warp 协作处理</span><br><span class="line">            if (threadIdx.x % 32 == 0) &#123;</span><br><span class="line">                process_node_warp(u, row_ptr, col_idx, level,</span><br><span class="line">                                  next_frontier, next_size, depth);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            // 大度数：Block 协作处理</span><br><span class="line">            if (threadIdx.x == 0) &#123;</span><br><span class="line">                process_node_block(u, row_ptr, col_idx, level,</span><br><span class="line">                                   next_frontier, next_size, depth);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="warp-ji-xie-zuo" tabindex="-1" id="Warp-级协作">Warp 级协作</h3><p>让一个 Warp 的32个线程协作处理一个节点：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">__device__ void process_node_warp(int u, int *row_ptr, int *col_idx, </span><br><span class="line">                                   int *level, int *next_frontier, </span><br><span class="line">                                   int *next_size, int depth) &#123;</span><br><span class="line">    int lane = threadIdx.x % 32;</span><br><span class="line">    int start = row_ptr[u];</span><br><span class="line">    int end = row_ptr[u + 1];</span><br><span class="line">    </span><br><span class="line">    __shared__ int warp_queue[32];</span><br><span class="line">    __shared__ int warp_tail;</span><br><span class="line">    </span><br><span class="line">    if (lane == 0) warp_tail = 0;</span><br><span class="line">    __syncwarp();</span><br><span class="line">    </span><br><span class="line">    // Warp 内线程协作遍历邻居</span><br><span class="line">    for (int i = start + lane; i &lt; end; i += 32) &#123;</span><br><span class="line">        int v = col_idx[i];</span><br><span class="line">        </span><br><span class="line">        if (atomicCAS(&amp;level[v], -1, depth + 1) == -1) &#123;</span><br><span class="line">            int pos = atomicAdd(&amp;warp_tail, 1);</span><br><span class="line">            if (pos &lt; 32) &#123;</span><br><span class="line">                warp_queue[pos] = v;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    __syncwarp();</span><br><span class="line">    </span><br><span class="line">    // Warp 的第一个线程提交到全局</span><br><span class="line">    if (lane == 0 &amp;&amp; warp_tail &gt; 0) &#123;</span><br><span class="line">        int offset = atomicAdd(next_size, warp_tail);</span><br><span class="line">        for (int i = 0; i &lt; warp_tail; i++) &#123;</span><br><span class="line">            next_frontier[offset + i] = warp_queue[i];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="xing-neng-dui-bi" tabindex="-1" id="性能对比">性能对比</h3><p>以 Twitter 社交网络图为例：</p><table><thead><tr><th>策略</th><th>时间（ms）</th><th>加速比</th></tr></thead><tbody><tr><td>每线程一节点</td><td>2800</td><td>1×</td></tr><tr><td>线程束协作</td><td>800</td><td>3.5×</td></tr><tr><td>自适应负载均衡</td><td>450</td><td>6.2×</td></tr><tr><td>+ 方向优化</td><td>180</td><td>15.6×</td></tr></tbody></table><p><strong>测试环境</strong>：</p><ul><li>图数据：Twitter 社交网络（4100万节点，14.7亿条边）</li><li>GPU：NVIDIA A100（6912 CUDA 核心，40GB HBM2）</li><li>块大小：256线程</li></ul><p><strong>观察</strong>：负载均衡和方向优化的组合效果最好，在无标度网络中尤其明显。</p><h2 id="warp-ji-yuan-yu-you-hua" tabindex="-1" id="Warp-级原语优化">Warp 级原语优化</h2><h3 id="shi-yong-ballot-he-shuffle" tabindex="-1" id="使用-Ballot-和-Shuffle">使用 Ballot 和 Shuffle</h3><p>现代 GPU 的 Warp 级原语可以进一步优化 BFS：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">__device__ void process_neighbors_warp_optimized(</span><br><span class="line">    int start, int end, int *col_idx, int *level,</span><br><span class="line">    int *next_frontier, int *next_size, int depth) &#123;</span><br><span class="line">    </span><br><span class="line">    int lane = threadIdx.x % 32;</span><br><span class="line">    int found = 0;</span><br><span class="line">    </span><br><span class="line">    // Warp 协作遍历</span><br><span class="line">    for (int i = start + lane; i &lt; end; i += 32) &#123;</span><br><span class="line">        int v = col_idx[i];</span><br><span class="line">        if (atomicCAS(&amp;level[v], -1, depth + 1) == -1) &#123;</span><br><span class="line">            found = v;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    // 使用 ballot 统计有多少线程找到了新节点</span><br><span class="line">    unsigned mask = __ballot_sync(0xffffffff, found != 0);</span><br><span class="line">    int count = __popc(mask);</span><br><span class="line">    </span><br><span class="line">    if (count &gt; 0) &#123;</span><br><span class="line">        // 第一个有效线程申请空间</span><br><span class="line">        __shared__ int warp_offset;</span><br><span class="line">        if (lane == __ffs(mask) - 1) &#123;</span><br><span class="line">            warp_offset = atomicAdd(next_size, count);</span><br><span class="line">        &#125;</span><br><span class="line">        __syncwarp();</span><br><span class="line">        </span><br><span class="line">        // 使用前缀和确定每个线程的位置</span><br><span class="line">        if (found != 0) &#123;</span><br><span class="line">            unsigned preceding = mask &amp; ((1u &lt;&lt; lane) - 1);</span><br><span class="line">            int local_pos = __popc(preceding);</span><br><span class="line">            next_frontier[warp_offset + local_pos] = found;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>优势</strong>：</p><ul><li>减少原子操作到每 Warp 最多一次</li><li>利用 Warp 内隐式同步</li><li>紧凑存储，无空隙</li></ul><h2 id="zhong-zhi-tiao-jian-jian-ce" tabindex="-1" id="终止条件检测">终止条件检测</h2><h3 id="wen-ti" tabindex="-1" id="问题">问题</h3><p>每次迭代都需要检查前沿是否为空，传统方法需要：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cudaMemcpy</span>(&amp;h_size, d_queue_size, <span class="built_in">sizeof</span>(<span class="type">int</span>), cudaMemcpyDeviceToHost);</span><br><span class="line"><span class="keyword">if</span> (h_size == <span class="number">0</span>) <span class="keyword">break</span>;</span><br></pre></td></tr></table></figure><p>每次迭代都有 D2H 拷贝，延迟高。</p><h3 id="you-hua-gpu-duan-zhong-zhi-jian-ce" tabindex="-1" id="优化：GPU-端终止检测">优化：GPU 端终止检测</h3><p>使用 CUDA 流和回调函数：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">__global__ void check_termination(int *queue_size, int *terminate_flag) &#123;</span><br><span class="line">    if (*queue_size == 0) &#123;</span><br><span class="line">        *terminate_flag = 1;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// Host 端</span><br><span class="line">int *d_terminate;</span><br><span class="line">cudaMallocHost(&amp;h_terminate, sizeof(int));  // 固定内存</span><br><span class="line">cudaMalloc(&amp;d_terminate, sizeof(int));</span><br><span class="line"></span><br><span class="line">while (true) &#123;</span><br><span class="line">    BFS_kernel&lt;&lt;&lt;...&gt;&gt;&gt;(...);</span><br><span class="line">    </span><br><span class="line">    // 异步检测终止</span><br><span class="line">    check_termination&lt;&lt;&lt;1, 1&gt;&gt;&gt;(d_queue_size, d_terminate);</span><br><span class="line">    cudaMemcpyAsync(h_terminate, d_terminate, sizeof(int), </span><br><span class="line">                     cudaMemcpyDeviceToHost);</span><br><span class="line">    cudaDeviceSynchronize();</span><br><span class="line">    </span><br><span class="line">    if (*h_terminate == 1) break;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="geng-you-zhong-die-jian-ce-yu-ji-suan" tabindex="-1" id="更优：重叠检测与计算">更优：重叠检测与计算</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">// 使用双缓冲和流</span><br><span class="line">while (true) &#123;</span><br><span class="line">    BFS_kernel&lt;&lt;&lt;..., stream1&gt;&gt;&gt;(...);</span><br><span class="line">    </span><br><span class="line">    // 在另一个流中异步检测</span><br><span class="line">    check_termination&lt;&lt;&lt;1, 1, 0, stream2&gt;&gt;&gt;(d_queue_size, d_terminate);</span><br><span class="line">    cudaMemcpyAsync(h_terminate, d_terminate, sizeof(int),</span><br><span class="line">                     cudaMemcpyDeviceToHost, stream2);</span><br><span class="line">    </span><br><span class="line">    // 准备下一次迭代（与检测重叠）</span><br><span class="line">    prepare_next_iteration&lt;&lt;&lt;..., stream1&gt;&gt;&gt;(...);</span><br><span class="line">    </span><br><span class="line">    cudaStreamSynchronize(stream2);</span><br><span class="line">    if (*h_terminate == 1) break;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="wan-zheng-you-hua-ban-ben" tabindex="-1" id="完整优化版本">完整优化版本</h2><h3 id="zong-he-suo-you-you-hua" tabindex="-1" id="综合所有优化">综合所有优化</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line">#define BLOCK_SIZE 256</span><br><span class="line">#define WARP_SIZE 32</span><br><span class="line">#define LOCAL_QUEUE_SIZE 512</span><br><span class="line"></span><br><span class="line">__global__ void BFS_optimized(</span><br><span class="line">    int *row_ptr, int *col_idx, int *level,</span><br><span class="line">    int *current_queue, int current_size,</span><br><span class="line">    int *next_queue, int *next_size,</span><br><span class="line">    bool *frontier_bitmap,  // 用于 Bottom-Up</span><br><span class="line">    int depth, bool top_down_mode) &#123;</span><br><span class="line">    </span><br><span class="line">    __shared__ int s_queue[LOCAL_QUEUE_SIZE];</span><br><span class="line">    __shared__ int s_tail;</span><br><span class="line">    </span><br><span class="line">    if (threadIdx.x == 0) s_tail = 0;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    if (top_down_mode) &#123;</span><br><span class="line">        // ========== Top-Down 模式 ==========</span><br><span class="line">        int tid = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">        int warp_id = tid / WARP_SIZE;</span><br><span class="line">        int lane = tid % WARP_SIZE;</span><br><span class="line">        </span><br><span class="line">        if (tid &lt; current_size) &#123;</span><br><span class="line">            int u = current_queue[tid];</span><br><span class="line">            int degree = row_ptr[u + 1] - row_ptr[u];</span><br><span class="line">            </span><br><span class="line">            if (degree &lt; WARP_SIZE) &#123;</span><br><span class="line">                // 单线程处理小度数节点</span><br><span class="line">                for (int i = row_ptr[u]; i &lt; row_ptr[u + 1]; i++) &#123;</span><br><span class="line">                    int v = col_idx[i];</span><br><span class="line">                    if (atomicCAS(&amp;level[v], -1, depth + 1) == -1) &#123;</span><br><span class="line">                        int pos = atomicAdd(&amp;s_tail, 1);</span><br><span class="line">                        if (pos &lt; LOCAL_QUEUE_SIZE) &#123;</span><br><span class="line">                            s_queue[pos] = v;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                // Warp 协作处理大度数节点</span><br><span class="line">                for (int i = row_ptr[u] + lane; i &lt; row_ptr[u + 1]; i += WARP_SIZE) &#123;</span><br><span class="line">                    int v = col_idx[i];</span><br><span class="line">                    if (atomicCAS(&amp;level[v], -1, depth + 1) == -1) &#123;</span><br><span class="line">                        int pos = atomicAdd(&amp;s_tail, 1);</span><br><span class="line">                        if (pos &lt; LOCAL_QUEUE_SIZE) &#123;</span><br><span class="line">                            s_queue[pos] = v;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        // ========== Bottom-Up 模式 ==========</span><br><span class="line">        int v = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">        </span><br><span class="line">        if (v &lt; num_nodes &amp;&amp; level[v] == -1) &#123;</span><br><span class="line">            for (int i = row_ptr[v]; i &lt; row_ptr[v + 1]; i++) &#123;</span><br><span class="line">                int u = col_idx[i];</span><br><span class="line">                if (frontier_bitmap[u]) &#123;</span><br><span class="line">                    level[v] = depth + 1;</span><br><span class="line">                    int pos = atomicAdd(&amp;s_tail, 1);</span><br><span class="line">                    if (pos &lt; LOCAL_QUEUE_SIZE) &#123;</span><br><span class="line">                        s_queue[pos] = v;</span><br><span class="line">                    &#125;</span><br><span class="line">                    break;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    // 批量提交局部队列到全局</span><br><span class="line">    if (s_tail &gt; 0) &#123;</span><br><span class="line">        __shared__ int g_offset;</span><br><span class="line">        if (threadIdx.x == 0) &#123;</span><br><span class="line">            g_offset = atomicAdd(next_size, s_tail);</span><br><span class="line">        &#125;</span><br><span class="line">        __syncthreads();</span><br><span class="line">        </span><br><span class="line">        for (int i = threadIdx.x; i &lt; s_tail; i += BLOCK_SIZE) &#123;</span><br><span class="line">            next_queue[g_offset + i] = s_queue[i];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="xing-neng-fen-xi-yu-dui-bi" tabindex="-1" id="性能分析与对比">性能分析与对比</h2><h3 id="bu-tong-you-hua-de-lei-ji-xiao-guo" tabindex="-1" id="不同优化的累计效果">不同优化的累计效果</h3><p>以美国道路网络图为例：</p><table><thead><tr><th>优化阶段</th><th>时间（ms）</th><th>单阶段加速</th><th>累计加速</th></tr></thead><tbody><tr><td>朴素布尔前沿</td><td>8500</td><td>1×</td><td>1×</td></tr><tr><td>稀疏队列</td><td>2100</td><td>4.0×</td><td>4.0×</td></tr><tr><td>+ 私有化队列</td><td>620</td><td>3.4×</td><td>13.7×</td></tr><tr><td>+ 线程束协作</td><td>380</td><td>1.6×</td><td>22.4×</td></tr><tr><td>+ 方向优化</td><td>95</td><td>4.0×</td><td>89.5×</td></tr><tr><td>+ CUB DeviceSelect优化</td><td>75</td><td>1.3×</td><td>113×</td></tr></tbody></table><h3 id="shi-ji-ce-shi-huan-jing" tabindex="-1" id="实际测试环境">实际测试环境</h3><p><strong>硬件配置</strong>：</p><ul><li>GPU：NVIDIA RTX 3090（10496 CUDA 核心，24GB GDDR6X）</li><li>CPU：Intel i9-12900K（用于对比）</li><li>CUDA 版本：11.8</li><li>编译选项：nvcc -O3 -arch=sm_86</li></ul><p><strong>测试图数据集</strong>：</p><ul><li>社交网络：Twitter 图（4100万节点，14.7亿条边）</li><li>路网：USA Road Network（2300万节点，5800万条边）</li><li>随机图：RMAT Scale-26（6700万节点，5.3亿条边）</li></ul><p><strong>说明</strong>：性能数据为10次运行的平均值，不包括图数据传输时间。</p><h3 id="ge-you-hua-de-ping-jing-fen-xi" tabindex="-1" id="各优化的瓶颈分析">各优化的瓶颈分析</h3><table><thead><tr><th>版本</th><th>主要瓶颈</th><th>带宽利用率</th><th>占用率</th></tr></thead><tbody><tr><td>布尔前沿</td><td>分支发散、浪费</td><td>5%</td><td>10%</td></tr><tr><td>朴素队列</td><td>全局原子争用</td><td>15%</td><td>35%</td></tr><tr><td>私有化</td><td>共享内存原子</td><td>45%</td><td>60%</td></tr><tr><td>Warp 协作</td><td>负载不均</td><td>65%</td><td>75%</td></tr><tr><td>方向优化</td><td>接近最优</td><td>85%</td><td>80%</td></tr></tbody></table><h2 id="ying-yong-kuo-zhan" tabindex="-1" id="应用扩展">应用扩展</h2><h3 id="dan-yuan-zui-duan-lu-jing-sssp" tabindex="-1" id="单源最短路径（SSSP）">单源最短路径（SSSP）</h3><p>BFS 可以扩展到加权图的最短路径：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">__global__ void SSSP_kernel(int *row_ptr, int *col_idx, float *weights,</span><br><span class="line">                             float *dist, bool *updated, int num_nodes) &#123;</span><br><span class="line">    int u = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    </span><br><span class="line">    if (u &lt; num_nodes &amp;&amp; updated[u]) &#123;</span><br><span class="line">        updated[u] = false;</span><br><span class="line">        </span><br><span class="line">        for (int i = row_ptr[u]; i &lt; row_ptr[u + 1]; i++) &#123;</span><br><span class="line">            int v = col_idx[i];</span><br><span class="line">            float new_dist = dist[u] + weights[i];</span><br><span class="line">            </span><br><span class="line">            // 使用原子操作更新更短的距离</span><br><span class="line">            atomicMin_float(&amp;dist[v], new_dist);</span><br><span class="line">            updated[v] = true;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>关键差异</strong>：</p><ul><li>BFS 每个节点只访问一次</li><li>SSSP 可能多次更新（松弛操作）</li><li>需要迭代直到收敛</li></ul><h3 id="lian-tong-fen-liang" tabindex="-1" id="连通分量">连通分量</h3><p>找到图中的所有连通分量：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">__global__ void connected_components_kernel(</span><br><span class="line">    int *row_ptr, int *col_idx, int *component, </span><br><span class="line">    bool *changed, int num_nodes) &#123;</span><br><span class="line">    </span><br><span class="line">    int u = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    </span><br><span class="line">    if (u &lt; num_nodes) &#123;</span><br><span class="line">        int my_component = component[u];</span><br><span class="line">        </span><br><span class="line">        for (int i = row_ptr[u]; i &lt; row_ptr[u + 1]; i++) &#123;</span><br><span class="line">            int v = col_idx[i];</span><br><span class="line">            int neighbor_component = component[v];</span><br><span class="line">            </span><br><span class="line">            // 取较小的分量标签</span><br><span class="line">            if (neighbor_component &lt; my_component) &#123;</span><br><span class="line">                atomicMin(&amp;component[u], neighbor_component);</span><br><span class="line">                *changed = true;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>迭代执行直到没有变化。</p><h3 id="san-jiao-xing-ji-shu" tabindex="-1" id="三角形计数">三角形计数</h3><p>统计图中三角形的数量（社交网络分析的重要指标）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">__global__ void triangle_count_kernel(</span><br><span class="line">    int *row_ptr, int *col_idx, int num_nodes, </span><br><span class="line">    unsigned long long *count) &#123;</span><br><span class="line">    </span><br><span class="line">    int u = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    </span><br><span class="line">    if (u &lt; num_nodes) &#123;</span><br><span class="line">        int u_start = row_ptr[u];</span><br><span class="line">        int u_end = row_ptr[u + 1];</span><br><span class="line">        </span><br><span class="line">        // 遍历 u 的邻居 v</span><br><span class="line">        for (int i = u_start; i &lt; u_end; i++) &#123;</span><br><span class="line">            int v = col_idx[i];</span><br><span class="line">            if (v &gt; u) &#123;  // 避免重复计数</span><br><span class="line">                int v_start = row_ptr[v];</span><br><span class="line">                int v_end = row_ptr[v + 1];</span><br><span class="line">                </span><br><span class="line">                // 找 u 和 v 的共同邻居</span><br><span class="line">                int j = u_start, k = v_start;</span><br><span class="line">                while (j &lt; u_end &amp;&amp; k &lt; v_end) &#123;</span><br><span class="line">                    int u_neighbor = col_idx[j];</span><br><span class="line">                    int v_neighbor = col_idx[k];</span><br><span class="line">                    </span><br><span class="line">                    if (u_neighbor == v_neighbor &amp;&amp; u_neighbor &gt; v) &#123;</span><br><span class="line">                        atomicAdd(count, 1ULL);</span><br><span class="line">                        j++; k++;</span><br><span class="line">                    &#125; else if (u_neighbor &lt; v_neighbor) &#123;</span><br><span class="line">                        j++;</span><br><span class="line">                    &#125; else &#123;</span><br><span class="line">                        k++;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>优化</strong>：利用邻居列表有序的特性，用归并式遍历查找交集。</p><h2 id="shi-yong-cub-cu-graph-ku" tabindex="-1" id="使用-CUB-cuGraph-库">使用 CUB/cuGraph 库</h2><h3 id="cub-de-dui-lie-guan-li" tabindex="-1" id="CUB-的队列管理">CUB 的队列管理</h3><p>CUB 提供高效的 Select 操作，可用于队列管理：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;cub/cub.cuh&gt;</span><br><span class="line"></span><br><span class="line">// 从布尔前沿中提取节点 ID</span><br><span class="line">void compact_frontier(bool *d_frontier, int *d_queue, int *d_size, int num_nodes) &#123;</span><br><span class="line">    void *d_temp = nullptr;</span><br><span class="line">    size_t temp_bytes = 0;</span><br><span class="line">    </span><br><span class="line">    // 计算需要的临时空间</span><br><span class="line">    cub::DeviceSelect::Flagged(d_temp, temp_bytes,</span><br><span class="line">                                 d_indices, d_frontier,  // 输入</span><br><span class="line">                                 d_queue, d_size,        // 输出</span><br><span class="line">                                 num_nodes);</span><br><span class="line">    </span><br><span class="line">    cudaMalloc(&amp;d_temp, temp_bytes);</span><br><span class="line">    </span><br><span class="line">    // 执行压缩</span><br><span class="line">    cub::DeviceSelect::Flagged(d_temp, temp_bytes,</span><br><span class="line">                                 d_indices, d_frontier,</span><br><span class="line">                                 d_queue, d_size,</span><br><span class="line">                                 num_nodes);</span><br><span class="line">    </span><br><span class="line">    cudaFree(d_temp);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="cu-graph-ku" tabindex="-1" id="cuGraph-库">cuGraph 库</h3><p>NVIDIA 的图分析库提供优化的 BFS 实现：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cugraph/algorithms.hpp&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">bfs_cugraph</span><span class="params">(<span class="type">int</span> num_nodes, <span class="type">int</span> num_edges,</span></span></span><br><span class="line"><span class="params"><span class="function">                  <span class="type">int</span> *offsets, <span class="type">int</span> *indices, <span class="type">int</span> source)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 创建图对象</span></span><br><span class="line">    <span class="function">cugraph::GraphCSRView&lt;<span class="type">int</span>, <span class="type">int</span>, <span class="type">float</span>&gt; <span class="title">graph</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">        offsets, indices, <span class="literal">nullptr</span>,  <span class="comment">// CSR 格式</span></span></span></span><br><span class="line"><span class="params"><span class="function">        num_nodes, num_edges</span></span></span><br><span class="line"><span class="params"><span class="function">    )</span></span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 分配结果数组</span></span><br><span class="line">    <span class="function">rmm::device_vector&lt;<span class="type">int</span>&gt; <span class="title">distances</span><span class="params">(num_nodes)</span></span>;</span><br><span class="line">    <span class="function">rmm::device_vector&lt;<span class="type">int</span>&gt; <span class="title">predecessors</span><span class="params">(num_nodes)</span></span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 执行 BFS</span></span><br><span class="line">    cugraph::<span class="built_in">bfs</span>(graph,</span><br><span class="line">                  distances.<span class="built_in">data</span>().<span class="built_in">get</span>(),</span><br><span class="line">                  predecessors.<span class="built_in">data</span>().<span class="built_in">get</span>(),</span><br><span class="line">                  source,</span><br><span class="line">                  <span class="literal">false</span>);  <span class="comment">// 不计算前驱节点</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>cuGraph 集成了本章讨论的所有优化技术。</p><h2 id="shi-zhan-jian-yi" tabindex="-1" id="实战建议">实战建议</h2><h3 id="tu-yu-chu-li" tabindex="-1" id="图预处理">图预处理</h3><p>在执行图算法前，预处理可以提升性能：</p><ol><li><p><strong>按度数排序节点</strong>：</p><ul><li>大度数节点聚集</li><li>方便负载均衡</li></ul></li><li><p><strong>重新编号</strong>：</p><ul><li>使用 BFS 顺序重新编号</li><li>提高缓存局部性</li></ul></li><li><p><strong>去除自环和重边</strong>：</p><ul><li>减少无效边</li><li>简化算法逻辑</li></ul></li></ol><h3 id="xuan-ze-he-gua-de-suan-fa" tabindex="-1" id="选择合适的算法">选择合适的算法</h3><table><thead><tr><th>图特征</th><th>推荐策略</th></tr></thead><tbody><tr><td>小前沿（&lt;1%）</td><td>Top-Down</td></tr><tr><td>大前沿（&gt;10%）</td><td>Bottom-Up</td></tr><tr><td>动态变化</td><td>方向优化</td></tr><tr><td>度数均匀</td><td>简单队列</td></tr><tr><td>无标度网络</td><td>Warp 协作</td></tr><tr><td>超大规模</td><td>多 GPU + 图分割</td></tr></tbody></table><h3 id="xing-neng-diao-you-jian-cha-qing-dan" tabindex="-1" id="性能调优检查清单">性能调优检查清单</h3><ul><li>[ ] 使用 CSR 格式存储图</li><li>[ ] 实现稀疏队列而非布尔数组</li><li>[ ] 使用共享内存私有化队列</li><li>[ ] 根据度数自适应选择策略</li><li>[ ] 考虑方向优化（Push/Pull 切换）</li><li>[ ] 使用 Warp 级原语减少原子操作</li><li>[ ] 优化终止条件检测</li><li>[ ] 考虑使用 cuGraph 库</li></ul><h2 id="xiao-jie" tabindex="-1" id="小结">小结</h2><p>第十五章深入讲解了 GPU 图遍历算法，相比于规则的矩阵运算，图算法充满了挑战：</p><p><strong>CSR 格式</strong>：是图和稀疏矩阵的桥梁。row_ptr 和 col_idx 两个数组高效表示稀疏邻接关系。</p><p><strong>按层同步</strong>：并行 BFS 的基本框架。每层并行处理当前前沿的所有节点。</p><p><strong>队列管理</strong>：</p><ul><li>布尔前沿：简单但工作效率极低</li><li>稀疏队列：只启动必要线程</li><li>私有化队列：减少全局原子操作争用</li></ul><p><strong>方向优化</strong>：</p><ul><li>Top-Down（Push）：前沿小时高效</li><li>Bottom-Up（Pull）：前沿大时高效</li><li>动态切换：自适应图的演化过程</li></ul><p><strong>负载均衡</strong>：</p><ul><li>无标度网络中度数差异巨大</li><li>单线程、Warp 协作、Block 协作分层处理</li><li>自适应策略根据度数选择</li></ul><p><strong>Warp 级优化</strong>：</p><ul><li>使用 ballot、shuffle 等原语</li><li>减少原子操作次数</li><li>提高内存效率</li></ul><p><strong>综合性能</strong>：</p><ul><li>优化后可达 100× 以上加速</li><li>接近内存带宽上限</li><li>方向优化贡献最大（通常 4-8×）</li></ul><p>图算法是 GPU 并行计算的试金石，它综合运用了前面学到的所有技术：原子操作、私有化、线程束原语、负载均衡、内存优化。掌握了图遍历，就掌握了处理不规则数据结构的核心技能。下一章将学习深度学习——GPU 计算当前最重要的应用领域。</p><h2 id="xia-yi-bu" tabindex="-1" id="🚀-下一步">🚀 下一步</h2><ul><li>尝试实现一个完整的 BFS 算法，从简单的布尔前沿数组开始，逐步优化到稀疏前沿和方向优化版本</li><li>探索其他图算法：最短路径（Dijkstra、Bellman-Ford）、连通分量、PageRank</li><li>学习 cuGraph 库，了解工业级的图算法实现</li><li>阅读 Graph500 基准测试，了解大规模图计算的性能指标</li></ul><hr><h2 id="can-kao-zi-liao" tabindex="-1" id="📚-参考资料">📚 参考资料</h2><ul><li>PMPP 第四版 Chapter 15</li><li><a href="https://smarter.xin/posts/pmmpp-chapter15-graph-traversal/">第十五章：图遍历</a></li><li>Hwu, W., Kirk, D., &amp; El Hajj, I. (2022). <em>Programming Massively Parallel Processors: A Hands-on Approach</em> (4th Edition). Morgan Kaufmann.</li><li>Merrill, D., et al. (2012). <em>Scalable GPU Graph Traversal</em>. PPoPP.</li><li>Beamer, S., et al. (2012). <em>Direction-Optimizing Breadth-First Search</em>. SC12.</li></ul><p><strong>学习愉快！</strong> 🎓</p><hr><blockquote><p><strong>本文 GitHub 仓库</strong>: <a href="https://github.com/psmarter/PMPP-Learning">https://github.com/psmarter/PMPP-Learning</a></p></blockquote>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h2 id=&quot;qian-yan&quot; tabindex=&quot;-1&quot; id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;第十四章我们学习了稀疏矩阵，那一章的重点是</summary>
        
      
    
    
    
    <category term="知识分享" scheme="https://smarter.xin/categories/knowledge-sharing/"/>
    
    
    <category term="CUDA" scheme="https://smarter.xin/tags/CUDA/"/>
    
    <category term="GPU编程" scheme="https://smarter.xin/tags/gpu-programming/"/>
    
    <category term="并行计算" scheme="https://smarter.xin/tags/parallel-computing/"/>
    
    <category term="PMPP" scheme="https://smarter.xin/tags/PMPP/"/>
    
    <category term="图算法" scheme="https://smarter.xin/tags/graph-algorithm/"/>
    
    <category term="BFS" scheme="https://smarter.xin/tags/BFS/"/>
    
    <category term="CSR格式" scheme="https://smarter.xin/tags/csr-format/"/>
    
  </entry>
  
  <entry>
    <title>PMPP-第十四章：稀疏矩阵计算</title>
    <link href="https://smarter.xin/posts/7af84cf7/"/>
    <id>https://smarter.xin/posts/7af84cf7/</id>
    <published>2026-01-19T02:49:30.000Z</published>
    <updated>2026-01-24T11:47:21.464Z</updated>
    
    <content type="html"><![CDATA[<h2 id="qian-yan" tabindex="-1" id="前言">前言</h2><p>前几章学习了归约、排序等处理&quot;规则数据&quot;的并行算法。本章学习<strong>稀疏矩阵（Sparse Matrix）</strong>——大部分元素为零的矩阵。稀疏矩阵在科学计算、图算法、机器学习中广泛应用。存储所有零元素既浪费空间又浪费计算，因此需要特殊的存储格式和算法。第十四章讲解常见的稀疏矩阵格式及其在 GPU 上的高效实现。</p><blockquote><p><strong>📦 配套资源</strong>：本系列文章配有完整的 <a href="https://github.com/psmarter/PMPP-Learning">GitHub 仓库</a>，包含每章的练习题解答、CUDA 代码实现和详细注释。所有代码都经过测试，可以直接运行。</p></blockquote><h2 id="xi-shu-ju-zhen-ji-chu" tabindex="-1" id="稀疏矩阵基础">稀疏矩阵基础</h2><h3 id="shi-yao-shi-xi-shu-ju-zhen" tabindex="-1" id="什么是稀疏矩阵">什么是稀疏矩阵</h3><p><strong>稀疏矩阵</strong>：非零元素占比很小的矩阵。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">密集矩阵 (Dense):</span><br><span class="line">[1, 2, 3, 4]</span><br><span class="line">[5, 6, 7, 8]</span><br><span class="line">[9, 10, 11, 12]</span><br><span class="line"></span><br><span class="line">稀疏矩阵 (Sparse):</span><br><span class="line">[0, 0, 3, 0]</span><br><span class="line">[0, 0, 0, 0]</span><br><span class="line">[2, 0, 0, 5]</span><br></pre></td></tr></table></figure><p><strong>稀疏度</strong>：零元素占比。通常稀疏度 &gt; 90% 就值得用稀疏格式存储。</p><h3 id="ying-yong-chang-jing" tabindex="-1" id="应用场景">应用场景</h3><table><thead><tr><th>领域</th><th>应用</th><th>稀疏度</th></tr></thead><tbody><tr><td>图算法</td><td>邻接矩阵</td><td>&gt; 99%</td></tr><tr><td>物理仿真</td><td>有限元刚度矩阵</td><td>&gt; 95%</td></tr><tr><td>推荐系统</td><td>用户-物品评分矩阵</td><td>&gt; 99.9%</td></tr><tr><td>NLP</td><td>词-文档矩阵</td><td>&gt; 99%</td></tr><tr><td>深度学习</td><td>剪枝后的权重矩阵</td><td>50%-90%</td></tr></tbody></table><h3 id="wei-shi-yao-xu-yao-te-shu-ge-shi" tabindex="-1" id="为什么需要特殊格式">为什么需要特殊格式</h3><p><strong>存储效率</strong>：</p><ul><li>密集格式：n² 个元素</li><li>稀疏格式：O(nnz) 个元素，nnz = 非零元素数</li></ul><p><strong>计算效率</strong>：</p><ul><li>密集 SpMV：O(n²) 操作</li><li>稀疏 SpMV：O(nnz) 操作</li></ul><p>对于 10000×10000 矩阵，1% 稀疏度：</p><ul><li>密集：10⁸ 个元素，400 MB</li><li>稀疏：10⁶ 个非零元素，~12 MB</li></ul><h2 id="chang-jian-xi-shu-ge-shi" tabindex="-1" id="常见稀疏格式">常见稀疏格式</h2><h3 id="coo-coordinate-ge-shi" tabindex="-1" id="COO（Coordinate）格式">COO（Coordinate）格式</h3><p>最直观的格式：存储每个非零元素的 (行, 列, 值)。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">矩阵:</span><br><span class="line">[0, 0, 3, 0]</span><br><span class="line">[0, 0, 0, 0]</span><br><span class="line">[2, 0, 0, 5]</span><br><span class="line"></span><br><span class="line">COO 表示:</span><br><span class="line">row:    [0, 2, 2]</span><br><span class="line">col:    [2, 0, 3]</span><br><span class="line">value:  [3, 2, 5]</span><br></pre></td></tr></table></figure><p><strong>存储空间</strong>：3 × nnz</p><p><strong>优点</strong>：简单，构建方便，支持乱序插入</p><p><strong>缺点</strong>：按行遍历效率低，不适合 SpMV</p><h3 id="csr-compressed-sparse-row-ge-shi" tabindex="-1" id="CSR（Compressed-Sparse-Row）格式">CSR（Compressed Sparse Row）格式</h3><p>最常用的格式：压缩行索引。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">矩阵:</span><br><span class="line">[0, 0, 3, 0]</span><br><span class="line">[0, 0, 0, 0]</span><br><span class="line">[2, 0, 0, 5]</span><br><span class="line"></span><br><span class="line">CSR 表示:</span><br><span class="line">row_ptr:  [0, 1, 1, 3]  // 每行的起始位置</span><br><span class="line">col_idx:  [2, 0, 3]      // 列索引</span><br><span class="line">values:   [3, 2, 5]      // 值</span><br></pre></td></tr></table></figure><p><strong>row_ptr 解读</strong>：</p><ul><li>第 0 行：row_ptr[0] 到 row_ptr[1]，即 [0, 1)，包含 1 个元素</li><li>第 1 行：row_ptr[1] 到 row_ptr[2]，即 [1, 1)，包含 0 个元素</li><li>第 2 行：row_ptr[2] 到 row_ptr[3]，即 [1, 3)，包含 2 个元素</li></ul><p><strong>存储空间</strong>：(n + 1) + 2 × nnz</p><p><strong>优点</strong>：按行访问高效，SpMV 友好</p><p><strong>缺点</strong>：插入/删除代价高，负载可能不均衡</p><h3 id="csc-compressed-sparse-column-ge-shi" tabindex="-1" id="CSC（Compressed-Sparse-Column）格式">CSC（Compressed Sparse Column）格式</h3><p>CSR 的转置：压缩列索引。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">col_ptr:  [0, 1, 1, 2, 3]  // 每列的起始位置</span><br><span class="line">row_idx:  [2, 0, 2]         // 行索引</span><br><span class="line">values:   [2, 3, 5]         // 值</span><br></pre></td></tr></table></figure><p><strong>适用场景</strong>：按列访问频繁，如 SpMV 的转置操作。</p><h3 id="ell-ellpack-itpack-ge-shi" tabindex="-1" id="ELL（ELLPACK-ITPACK）格式">ELL（ELLPACK/ITPACK）格式</h3><p>每行填充到相同长度：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">矩阵:</span><br><span class="line">[1, 0, 2, 0]</span><br><span class="line">[0, 3, 0, 0]</span><br><span class="line">[4, 5, 6, 0]</span><br><span class="line"></span><br><span class="line">ELL 表示（每行最多 3 个非零元素）:</span><br><span class="line">values:       col_idx:</span><br><span class="line">[1, 2, *]     [0, 2, *]</span><br><span class="line">[3, *, *]     [1, *, *]</span><br><span class="line">[4, 5, 6]     [0, 1, 2]</span><br></pre></td></tr></table></figure><ul><li>表示填充值（无效元素）</li></ul><p><strong>优点</strong>：规则访问模式，适合 GPU 向量化</p><p><strong>缺点</strong>：行长度差异大时浪费空间</p><h3 id="hybrid-hyb-ge-shi" tabindex="-1" id="Hybrid（HYB）格式">Hybrid（HYB）格式</h3><p>ELL + COO 的组合：</p><ul><li>大部分元素用 ELL 存储（规则部分）</li><li>超出 ELL 宽度的元素用 COO 存储（溢出部分）</li></ul><p><strong>适用场景</strong>：行长度分布不均匀的矩阵。</p><h2 id="xi-shu-ju-zhen-xiang-liang-cheng-fa-sp-mv" tabindex="-1" id="稀疏矩阵-向量乘法（SpMV）">稀疏矩阵-向量乘法（SpMV）</h2><h3 id="wen-ti-ding-yi" tabindex="-1" id="问题定义">问题定义</h3><p>y = A × x，其中 A 是 m × n 稀疏矩阵。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y[i] = Σ A[i][j] × x[j]  （j 遍历第 i 行的非零元素）</span><br></pre></td></tr></table></figure><p>SpMV 是科学计算最常见的操作，是迭代求解器（CG、GMRES）的核心。</p><h3 id="csr-sp-mv-chuan-xing-shi-xian" tabindex="-1" id="CSR-SpMV-串行实现">CSR SpMV 串行实现</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">spmv_csr_sequential</span><span class="params">(<span class="type">int</span> m, <span class="type">int</span> *row_ptr, <span class="type">int</span> *col_idx, </span></span><br><span class="line"><span class="params">                          <span class="type">float</span> *values, <span class="type">float</span> *x, <span class="type">float</span> *y)</span> &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; m; i++) &#123;</span><br><span class="line">        <span class="type">float</span> sum = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = row_ptr[i]; j &lt; row_ptr[i + <span class="number">1</span>]; j++) &#123;</span><br><span class="line">            sum += values[j] * x[col_idx[j]];</span><br><span class="line">        &#125;</span><br><span class="line">        y[i] = sum;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="csr-sp-mv-bing-xing-shi-xian" tabindex="-1" id="CSR-SpMV-并行实现">CSR SpMV 并行实现</h3><p><strong>每行一个线程</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">__global__ void spmv_csr_scalar(int m, int *row_ptr, int *col_idx,</span><br><span class="line">                                 float *values, float *x, float *y) &#123;</span><br><span class="line">    int row = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    </span><br><span class="line">    if (row &lt; m) &#123;</span><br><span class="line">        float sum = 0;</span><br><span class="line">        for (int j = row_ptr[row]; j &lt; row_ptr[row + 1]; j++) &#123;</span><br><span class="line">            sum += values[j] * x[col_idx[j]];</span><br><span class="line">        &#125;</span><br><span class="line">        y[row] = sum;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>问题</strong>：</p><ol><li><strong>负载不均衡</strong>：行长度差异导致线程工作量不同</li><li><strong>分支发散</strong>：同一 Warp 的线程循环次数不同</li><li><strong>非合并访问</strong>：x[col_idx[j]] 是间接访问，不连续</li></ol><h2 id="csr-sp-mv-you-hua" tabindex="-1" id="CSR-SpMV-优化">CSR SpMV 优化</h2><h3 id="mei-xing-yi-ge-warp" tabindex="-1" id="每行一个-Warp">每行一个 Warp</h3><p>用一个 Warp（32 线程）处理一行，Warp 内规约求和：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">__global__ void spmv_csr_vector(int m, int *row_ptr, int *col_idx,</span><br><span class="line">                                 float *values, float *x, float *y) &#123;</span><br><span class="line">    int row = blockIdx.x * blockDim.x / 32 + threadIdx.x / 32;</span><br><span class="line">    int lane = threadIdx.x % 32;</span><br><span class="line">    </span><br><span class="line">    if (row &lt; m) &#123;</span><br><span class="line">        float sum = 0;</span><br><span class="line">        int row_start = row_ptr[row];</span><br><span class="line">        int row_end = row_ptr[row + 1];</span><br><span class="line">        </span><br><span class="line">        // Warp 内线程协作遍历行</span><br><span class="line">        for (int j = row_start + lane; j &lt; row_end; j += 32) &#123;</span><br><span class="line">            sum += values[j] * x[col_idx[j]];</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        // Warp 内规约</span><br><span class="line">        for (int offset = 16; offset &gt; 0; offset /= 2) &#123;</span><br><span class="line">            sum += __shfl_down_sync(0xffffffff, sum, offset);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        if (lane == 0) &#123;</span><br><span class="line">            y[row] = sum;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>优势</strong>：</p><ul><li>负载在 Warp 内均衡</li><li>无分支发散（所有线程做相同次循环）</li><li>部分合并（values 连续）</li></ul><h3 id="zi-gua-ying-ce-lue" tabindex="-1" id="自适应策略">自适应策略</h3><p>根据行长度选择策略：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">if (row_length &lt; 32) &#123;</span><br><span class="line">    // 每行一个线程组（如 8 线程）</span><br><span class="line">&#125; else if (row_length &lt; 256) &#123;</span><br><span class="line">    // 每行一个 Warp</span><br><span class="line">&#125; else &#123;</span><br><span class="line">    // 每行多个 Warp</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>cuSPARSE 库会自动选择最优策略。</p><h2 id="ell-sp-mv" tabindex="-1" id="ELL-SpMV">ELL SpMV</h2><h3 id="shi-xian" tabindex="-1" id="实现">实现</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">__global__ void spmv_ell(int m, int max_nnz_per_row,</span><br><span class="line">                          int *col_idx, float *values,</span><br><span class="line">                          float *x, float *y) &#123;</span><br><span class="line">    int row = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    </span><br><span class="line">    if (row &lt; m) &#123;</span><br><span class="line">        float sum = 0;</span><br><span class="line">        for (int j = 0; j &lt; max_nnz_per_row; j++) &#123;</span><br><span class="line">            int idx = row + j * m;  // 列主序存储</span><br><span class="line">            int col = col_idx[idx];</span><br><span class="line">            if (col &gt;= 0) &#123;  // 有效元素</span><br><span class="line">                sum += values[idx] * x[col];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        y[row] = sum;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="lie-zhu-xu-bu-ju" tabindex="-1" id="列主序布局">列主序布局</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">原始（行主序）:</span><br><span class="line">row 0: [a, b, c]</span><br><span class="line">row 1: [d, e, *]</span><br><span class="line">row 2: [f, g, h]</span><br><span class="line"></span><br><span class="line">列主序:</span><br><span class="line">j=0: [a, d, f]  ← 连续访问！</span><br><span class="line">j=1: [b, e, g]</span><br><span class="line">j=2: [c, *, h]</span><br></pre></td></tr></table></figure><p><strong>优势</strong>：同一 Warp 的线程访问连续内存，实现合并访问。</p><h3 id="ell-vs-csr" tabindex="-1" id="ELL-vs-CSR">ELL vs CSR</h3><table><thead><tr><th>特性</th><th>CSR</th><th>ELL</th></tr></thead><tbody><tr><td>空间</td><td>2×nnz + (m+1)</td><td>2×m×max_nnz</td></tr><tr><td>访问合并</td><td>差（值和列索引）</td><td>好（列主序）</td></tr><tr><td>负载均衡</td><td>需要额外处理</td><td>自然均衡（固定循环）</td></tr><tr><td>适用矩阵</td><td>通用</td><td>行长度相近</td></tr></tbody></table><h2 id="jds-jagged-diagonal-storage-ge-shi" tabindex="-1" id="JDS（Jagged-Diagonal-Storage）格式">JDS（Jagged Diagonal Storage）格式</h2><h3 id="si-xiang" tabindex="-1" id="思想">思想</h3><p>按行长度降序排列行，然后用类似 ELL 的方式存储：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">原始矩阵:</span><br><span class="line">row 0: [a, b]       (长度 2)</span><br><span class="line">row 1: [c, d, e, f] (长度 4)</span><br><span class="line">row 2: [g]          (长度 1)</span><br><span class="line">row 3: [h, i, j]    (长度 3)</span><br><span class="line"></span><br><span class="line">按长度排序后:</span><br><span class="line">row 1: [c, d, e, f]</span><br><span class="line">row 3: [h, i, j, *]</span><br><span class="line">row 0: [a, b, *, *]</span><br><span class="line">row 2: [g, *, *, *]</span><br><span class="line"></span><br><span class="line">JDS 存储:</span><br><span class="line">jds_ptr:  [0, 4, 7, 9, 10]  // 每&quot;对角线&quot;的起始位置</span><br><span class="line">col_idx:  [1列索引...]</span><br><span class="line">values:   [c, h, a, g, d, i, b, e, j, f]</span><br><span class="line">perm:     [1, 3, 0, 2]      // 行重排映射</span><br></pre></td></tr></table></figure><h3 id="you-shi" tabindex="-1" id="优势">优势</h3><ul><li>短行集中在后面，减少填充浪费</li><li>前面的迭代负载均衡更好</li></ul><h3 id="que-dian" tabindex="-1" id="缺点">缺点</h3><ul><li>需要额外的行重排数组</li><li>结果需要按原顺序写回</li></ul><h2 id="fen-kuai-ge-shi" tabindex="-1" id="分块格式">分块格式</h2><h3 id="bsr-block-sparse-row" tabindex="-1" id="BSR（Block-Sparse-Row）">BSR（Block Sparse Row）</h3><p>把矩阵分成小块（如 4×4），用 CSR 存储块：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">原始矩阵 (8×8):</span><br><span class="line">[A, 0, B, 0]     A, B, C, D 是 2×2 块</span><br><span class="line">[0, C, 0, D]</span><br><span class="line"></span><br><span class="line">BSR 表示（块大小 2×2）:</span><br><span class="line">block_row_ptr: [0, 2, 4]</span><br><span class="line">block_col_idx: [0, 2, 1, 3]</span><br><span class="line">block_values:  [A的4个值, B的4个值, C的4个值, D的4个值]</span><br></pre></td></tr></table></figure><h3 id="you-shi-1" tabindex="-1" id="优势-2">优势</h3><ol><li><strong>减少索引开销</strong>：每个块只需一个 (行, 列) 索引</li><li><strong>提高缓存利用</strong>：块内数据连续</li><li><strong>利用密集计算</strong>：块内可以用密集矩阵乘法</li></ol><h3 id="gua-yong-chang-jing" tabindex="-1" id="适用场景">适用场景</h3><p>物理仿真中的多自由度系统（每个节点多个自由度），自然形成块结构。</p><h2 id="ge-shi-xuan-ze-zhi-nan" tabindex="-1" id="格式选择指南">格式选择指南</h2><h3 id="jue-ce-shu" tabindex="-1" id="决策树">决策树</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">              ┌─────────────────┐</span><br><span class="line">              │    稀疏矩阵      │</span><br><span class="line">              └────────┬────────┘</span><br><span class="line">                       │</span><br><span class="line">              ┌────────▼────────┐</span><br><span class="line">              │ 行长度差异大？   │</span><br><span class="line">              └────────┬────────┘</span><br><span class="line">             是        │        否</span><br><span class="line">        ┌──────────────┼──────────────┐</span><br><span class="line">        │              │              │</span><br><span class="line">┌───────▼───────┐      │      ┌───────▼───────┐</span><br><span class="line">│ HYB 或 JDS     │      │      │ ELL           │</span><br><span class="line">└───────────────┘      │      └───────────────┘</span><br><span class="line">                       │</span><br><span class="line">              ┌────────▼────────┐</span><br><span class="line">              │ 有块结构？      │</span><br><span class="line">              └────────┬────────┘</span><br><span class="line">             是        │        否</span><br><span class="line">        ┌──────────────┼──────────────┐</span><br><span class="line">        │              │              │</span><br><span class="line">┌───────▼───────┐      │      ┌───────▼───────┐</span><br><span class="line">│ BSR            │      │      │ CSR           │</span><br><span class="line">└───────────────┘      │      └───────────────┘</span><br></pre></td></tr></table></figure><h3 id="ge-shi-dui-bi" tabindex="-1" id="格式对比">格式对比</h3><table><thead><tr><th>格式</th><th>构建难度</th><th>空间效率</th><th>SpMV 性能</th><th>适用场景</th></tr></thead><tbody><tr><td>COO</td><td>容易</td><td>中</td><td>差</td><td>构建阶段</td></tr><tr><td>CSR</td><td>中</td><td>好</td><td>中</td><td>通用</td></tr><tr><td>ELL</td><td>中</td><td>差-中</td><td>好</td><td>均匀行长</td></tr><tr><td>HYB</td><td>复杂</td><td>中</td><td>好</td><td>不均匀</td></tr><tr><td>BSR</td><td>复杂</td><td>好</td><td>很好</td><td>块结构</td></tr></tbody></table><h2 id="ge-shi-zhuan-huan" tabindex="-1" id="格式转换">格式转换</h2><h3 id="coo-dao-csr" tabindex="-1" id="COO-到-CSR">COO 到 CSR</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">void coo_to_csr(int m, int nnz, int *coo_row, int *coo_col, </span><br><span class="line">                float *coo_val, int *csr_row_ptr, int *csr_col, </span><br><span class="line">                float *csr_val) &#123;</span><br><span class="line">    // 1. 统计每行元素数</span><br><span class="line">    for (int i = 0; i &lt; nnz; i++) &#123;</span><br><span class="line">        csr_row_ptr[coo_row[i] + 1]++;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    // 2. 前缀和得到行指针</span><br><span class="line">    for (int i = 0; i &lt; m; i++) &#123;</span><br><span class="line">        csr_row_ptr[i + 1] += csr_row_ptr[i];</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    // 3. 填充列索引和值</span><br><span class="line">    int *temp = calloc(m, sizeof(int));</span><br><span class="line">    for (int i = 0; i &lt; nnz; i++) &#123;</span><br><span class="line">        int row = coo_row[i];</span><br><span class="line">        int pos = csr_row_ptr[row] + temp[row];</span><br><span class="line">        csr_col[pos] = coo_col[i];</span><br><span class="line">        csr_val[pos] = coo_val[i];</span><br><span class="line">        temp[row]++;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="bing-xing-zhuan-huan" tabindex="-1" id="并行转换">并行转换</h3><p>利用前面学的技术：</p><ol><li><strong>统计</strong>：并行直方图</li><li><strong>前缀和</strong>：并行扫描</li><li><strong>分配</strong>：原子操作或前缀和确定位置</li></ol><h2 id="cu-sparse-ku" tabindex="-1" id="cuSPARSE-库">cuSPARSE 库</h2><h3 id="ji-ben-shi-yong" tabindex="-1" id="基本使用">基本使用</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;cusparse.h&gt;</span><br><span class="line"></span><br><span class="line">void spmv_cusparse(int m, int n, int nnz,</span><br><span class="line">                   int *row_ptr, int *col_idx, float *values,</span><br><span class="line">                   float *x, float *y) &#123;</span><br><span class="line">    cusparseHandle_t handle;</span><br><span class="line">    cusparseCreate(&amp;handle);</span><br><span class="line">    </span><br><span class="line">    // 创建矩阵描述符</span><br><span class="line">    cusparseSpMatDescr_t matA;</span><br><span class="line">    cusparseCreateCsr(&amp;matA, m, n, nnz,</span><br><span class="line">                      row_ptr, col_idx, values,</span><br><span class="line">                      CUSPARSE_INDEX_32I, CUSPARSE_INDEX_32I,</span><br><span class="line">                      CUSPARSE_INDEX_BASE_ZERO, CUDA_R_32F);</span><br><span class="line">    </span><br><span class="line">    // 创建向量描述符</span><br><span class="line">    cusparseDnVecDescr_t vecX, vecY;</span><br><span class="line">    cusparseCreateDnVec(&amp;vecX, n, x, CUDA_R_32F);</span><br><span class="line">    cusparseCreateDnVec(&amp;vecY, m, y, CUDA_R_32F);</span><br><span class="line">    </span><br><span class="line">    // 分配临时空间</span><br><span class="line">    float alpha = 1.0f, beta = 0.0f;</span><br><span class="line">    size_t bufferSize;</span><br><span class="line">    cusparseSpMV_bufferSize(handle, CUSPARSE_OPERATION_NON_TRANSPOSE,</span><br><span class="line">                            &amp;alpha, matA, vecX, &amp;beta, vecY,</span><br><span class="line">                            CUDA_R_32F, CUSPARSE_SPMV_ALG_DEFAULT,</span><br><span class="line">                            &amp;bufferSize);</span><br><span class="line">    </span><br><span class="line">    void *buffer;</span><br><span class="line">    cudaMalloc(&amp;buffer, bufferSize);</span><br><span class="line">    </span><br><span class="line">    // 执行 SpMV</span><br><span class="line">    cusparseSpMV(handle, CUSPARSE_OPERATION_NON_TRANSPOSE,</span><br><span class="line">                 &amp;alpha, matA, vecX, &amp;beta, vecY,</span><br><span class="line">                 CUDA_R_32F, CUSPARSE_SPMV_ALG_DEFAULT, buffer);</span><br><span class="line">    </span><br><span class="line">    // 清理</span><br><span class="line">    cusparseDestroySpMat(matA);</span><br><span class="line">    cusparseDestroyDnVec(vecX);</span><br><span class="line">    cusparseDestroyDnVec(vecY);</span><br><span class="line">    cudaFree(buffer);</span><br><span class="line">    cusparseDestroy(handle);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="cu-sparse-te-xing" tabindex="-1" id="cuSPARSE-特性">cuSPARSE 特性</h3><table><thead><tr><th>功能</th><th>说明</th></tr></thead><tbody><tr><td>SpMV</td><td>稀疏矩阵-向量乘</td></tr><tr><td>SpMM</td><td>稀疏矩阵-密集矩阵乘</td></tr><tr><td>SpGEMM</td><td>稀疏矩阵-稀疏矩阵乘</td></tr><tr><td>三角求解</td><td>稀疏三角矩阵求解</td></tr><tr><td>格式转换</td><td>COO/CSR/CSC/BSR 互转</td></tr><tr><td>矩阵分析</td><td>着色、重排序</td></tr></tbody></table><h2 id="xing-neng-you-hua-zong-jie" tabindex="-1" id="性能优化总结">性能优化总结</h2><h3 id="nei-cun-fang-wen-you-hua" tabindex="-1" id="内存访问优化">内存访问优化</h3><ol><li><strong>值和列索引</strong>：CSR 中这两者通常连续访问，合并良好</li><li><strong>x 向量</strong>：间接访问，考虑用纹理缓存</li><li><strong>列主序 ELL</strong>：保证同一 Warp 的线程访问连续</li></ol><h3 id="fu-zai-jun-heng" tabindex="-1" id="负载均衡">负载均衡</h3><ol><li><strong>分行策略</strong>：短行用少线程，长行用多线程</li><li><strong>分块处理</strong>：把非零元素均匀分配给线程块</li><li><strong>动态调度</strong>：运行时根据行长度分配资源</li></ol><h3 id="jian-shao-kai-xiao" tabindex="-1" id="减少开销">减少开销</h3><ol><li><strong>合并迭代</strong>：多次 SpMV 之间不必来回拷贝</li><li><strong>重用分析结果</strong>：矩阵结构不变时，analysis 只做一次</li><li><strong>混合精度</strong>：索引用 int32，值用 fp16/bf16</li></ol><h2 id="xiao-jie" tabindex="-1" id="小结">小结</h2><p>第十四章深入讲解稀疏矩阵：</p><p><strong>存储格式</strong>：COO（简单）、CSR（通用）、ELL（规则）、BSR（块结构）。选择取决于矩阵特性和操作类型。</p><p><strong>CSR SpMV</strong>：最常用。每行一线程简单但负载不均；每行一 Warp 更均衡但需要规约。自适应策略根据行长度选择。</p><p><strong>ELL SpMV</strong>：列主序存储保证合并访问。适合行长度相近的矩阵。</p><p><strong>格式转换</strong>：COO → CSR 用前缀和确定位置。并行转换利用直方图和扫描。</p><p><strong>cuSPARSE</strong>：生产环境首选。提供多种格式和操作，自动选择最优算法。</p><p>稀疏矩阵是科学计算的基础。掌握格式选择和 SpMV 优化，就能高效处理图算法、物理仿真、机器学习中的大规模稀疏数据。</p><hr><h2 id="xia-yi-bu" tabindex="-1" id="🚀-下一步">🚀 下一步</h2><hr><h2 id="can-kao-zi-liao" tabindex="-1" id="📚-参考资料">📚 参考资料</h2><ul><li>PMPP 第四版 Chapter 14</li><li><a href="https://smarter.xin/posts/7af84cf7/">第十四章：稀疏矩阵计算</a></li></ul><p><strong>学习愉快！</strong> 🎓</p><hr><blockquote><p><strong>本文 GitHub 仓库</strong>: <a href="https://github.com/psmarter/PMPP-Learning">https://github.com/psmarter/PMPP-Learning</a></p></blockquote>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h2 id=&quot;qian-yan&quot; tabindex=&quot;-1&quot; id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;前几章学习了归约、排序等处理&amp;quot;规则数据&amp;quot;的并行算法。本章学习&lt;strong&gt;稀疏矩阵（Sparse</summary>
        
      
    
    
    
    <category term="知识分享" scheme="https://smarter.xin/categories/knowledge-sharing/"/>
    
    
    <category term="CUDA" scheme="https://smarter.xin/tags/CUDA/"/>
    
    <category term="GPU编程" scheme="https://smarter.xin/tags/gpu-programming/"/>
    
    <category term="并行计算" scheme="https://smarter.xin/tags/parallel-computing/"/>
    
    <category term="PMPP" scheme="https://smarter.xin/tags/PMPP/"/>
    
    <category term="CSR格式" scheme="https://smarter.xin/tags/csr-format/"/>
    
    <category term="稀疏矩阵" scheme="https://smarter.xin/tags/sparse-matrix/"/>
    
    <category term="SpMV" scheme="https://smarter.xin/tags/SpMV/"/>
    
  </entry>
  
  <entry>
    <title>PMPP-第十三章：排序</title>
    <link href="https://smarter.xin/posts/d9ee9484/"/>
    <id>https://smarter.xin/posts/d9ee9484/</id>
    <published>2026-01-18T14:04:20.000Z</published>
    <updated>2026-01-24T11:47:21.463Z</updated>
    
    <content type="html"><![CDATA[<h2 id="qian-yan" tabindex="-1" id="前言">前言</h2><p>前两章学习了归约和归并，本章学习<strong>排序（Sorting）</strong>——把无序数据变成有序数据。排序是最基础的算法之一，在几乎所有计算领域都有应用。GPU 排序的挑战在于：传统排序算法（如快速排序）的递归结构和数据依赖不适合 GPU 的 SIMT 模型。第十三章介绍适合 GPU 的排序算法，重点是<strong>基数排序（Radix Sort）</strong>——通过前缀和实现高效并行排序。</p><blockquote><p><strong>📦 配套资源</strong>：本系列文章配有完整的 <a href="https://github.com/psmarter/PMPP-Learning">GitHub 仓库</a>，包含每章的练习题解答、CUDA 代码实现和详细注释。所有代码都经过测试，可以直接运行。</p></blockquote><h2 id="pai-xu-suan-fa-gai-lan" tabindex="-1" id="排序算法概览">排序算法概览</h2><h3 id="ji-yu-bi-jiao-de-pai-xu" tabindex="-1" id="基于比较的排序">基于比较的排序</h3><table><thead><tr><th>算法</th><th>平均复杂度</th><th>最坏复杂度</th><th>空间</th><th>稳定性</th></tr></thead><tbody><tr><td>冒泡排序</td><td>O(n²)</td><td>O(n²)</td><td>O(1)</td><td>稳定</td></tr><tr><td>插入排序</td><td>O(n²)</td><td>O(n²)</td><td>O(1)</td><td>稳定</td></tr><tr><td>快速排序</td><td>O(n log n)</td><td>O(n²)</td><td>O(log n)</td><td>不稳定</td></tr><tr><td>归并排序</td><td>O(n log n)</td><td>O(n log n)</td><td>O(n)</td><td>稳定</td></tr><tr><td>堆排序</td><td>O(n log n)</td><td>O(n log n)</td><td>O(1)</td><td>不稳定</td></tr></tbody></table><p><strong>理论下界</strong>：基于比较的排序最优是 O(n log n)。</p><h3 id="fei-bi-jiao-pai-xu" tabindex="-1" id="非比较排序">非比较排序</h3><table><thead><tr><th>算法</th><th>复杂度</th><th>适用类型</th></tr></thead><tbody><tr><td>计数排序</td><td>O(n + k)</td><td>小范围整数</td></tr><tr><td>基数排序</td><td>O(d(n + k))</td><td>固定位数整数</td></tr><tr><td>桶排序</td><td>O(n + k)</td><td>均匀分布</td></tr></tbody></table><p><strong>突破下界</strong>：非比较排序可以达到 O(n)，但有类型限制。</p><h3 id="gpu-pai-xu-de-xuan-ze" tabindex="-1" id="GPU-排序的选择">GPU 排序的选择</h3><p><strong>快速排序不适合 GPU</strong>：</p><ul><li>递归深度不确定</li><li>分区不平衡导致负载不均</li><li>数据依赖导致分支发散</li></ul><p><strong>GPU 友好的算法</strong>：</p><ul><li><strong>基数排序</strong>：规则的数据访问模式，利用前缀和</li><li><strong>归并排序</strong>：确定的步骤数，可并行归并</li><li><strong>双调排序</strong>：完全数据无关的比较网络</li></ul><h2 id="ji-shu-pai-xu" tabindex="-1" id="基数排序">基数排序</h2><h3 id="he-xin-si-xiang" tabindex="-1" id="核心思想">核心思想</h3><p>按位排序，从最低位到最高位：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">原始:    [329, 457, 657, 839, 436, 720, 355]</span><br><span class="line"></span><br><span class="line">按个位排序（第0位）:</span><br><span class="line">         [720, 355, 436, 457, 657, 329, 839]</span><br><span class="line"></span><br><span class="line">按十位排序（第1位）:</span><br><span class="line">         [720, 329, 436, 839, 355, 457, 657]</span><br><span class="line"></span><br><span class="line">按百位排序（第2位）:</span><br><span class="line">         [329, 355, 436, 457, 657, 720, 839]</span><br><span class="line"></span><br><span class="line">完成！</span><br></pre></td></tr></table></figure><p><strong>关键</strong>：每一轮排序必须是<strong>稳定</strong>的，保持相同键值元素的相对顺序。</p><h3 id="wei-pai-xu-yu-ji-shu-pai-xu" tabindex="-1" id="位排序与计数排序">位排序与计数排序</h3><p>每一轮按某一位排序，使用<strong>计数排序</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. 统计每个值的出现次数</span><br><span class="line">2. 计算前缀和得到每个值的起始位置</span><br><span class="line">3. 按原顺序分配到输出位置</span><br></pre></td></tr></table></figure><p>对于二进制位（0 或 1）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">输入:    [1, 0, 1, 1, 0, 0, 1, 0]</span><br><span class="line">计数:    count[0]=4, count[1]=4</span><br><span class="line">前缀和:  pos[0]=0, pos[1]=4</span><br><span class="line">分配:    输出位置 = pos[bit]++</span><br><span class="line">结果:    [0, 0, 0, 0, 1, 1, 1, 1]</span><br></pre></td></tr></table></figure><h3 id="duo-wei-yi-qi-chu-li" tabindex="-1" id="多位一起处理">多位一起处理</h3><p>一次处理多位（如 4 位）可以减少轮数：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">32 位整数:</span><br><span class="line">  1 位/轮: 32 轮</span><br><span class="line">  4 位/轮: 8 轮</span><br><span class="line">  8 位/轮: 4 轮</span><br></pre></td></tr></table></figure><p>代价是每轮需要更大的计数数组（2^b 个桶）。</p><h2 id="bing-xing-ji-shu-pai-xu" tabindex="-1" id="并行基数排序">并行基数排序</h2><h3 id="dan-block-ban-ben" tabindex="-1" id="单-Block-版本">单 Block 版本</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">#define RADIX_BITS 4</span><br><span class="line">#define RADIX (1 &lt;&lt; RADIX_BITS)  // 16</span><br><span class="line">#define RADIX_MASK (RADIX - 1)</span><br><span class="line"></span><br><span class="line">__global__ void radix_sort_block(unsigned int *data, int n, int bit) &#123;</span><br><span class="line">    __shared__ unsigned int s_data[BLOCK_SIZE];</span><br><span class="line">    __shared__ int s_count[RADIX];</span><br><span class="line">    __shared__ int s_offset[RADIX];</span><br><span class="line">    </span><br><span class="line">    int tid = threadIdx.x;</span><br><span class="line">    </span><br><span class="line">    // 加载数据</span><br><span class="line">    s_data[tid] = (tid &lt; n) ? data[tid] : 0xFFFFFFFF;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    // 统计每个桶的计数（这里简化，实际需要原子或规约）</span><br><span class="line">    if (tid &lt; RADIX) s_count[tid] = 0;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    int digit = (s_data[tid] &gt;&gt; bit) &amp; RADIX_MASK;</span><br><span class="line">    atomicAdd(&amp;s_count[digit], 1);</span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    // 前缀和得到偏移</span><br><span class="line">    // ... exclusive scan on s_count → s_offset ...</span><br><span class="line">    </span><br><span class="line">    // 分配到输出位置</span><br><span class="line">    int pos = atomicAdd(&amp;s_offset[digit], 1);  // 动态分配</span><br><span class="line">    </span><br><span class="line">    __shared__ unsigned int s_temp[BLOCK_SIZE];</span><br><span class="line">    s_temp[pos] = s_data[tid];</span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    // 写回</span><br><span class="line">    s_data[tid] = s_temp[tid];</span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    if (tid &lt; n) data[tid] = s_data[tid];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="da-gui-mo-ji-shu-pai-xu" tabindex="-1" id="大规模基数排序">大规模基数排序</h3><p>对于超过单 Block 的数据，需要分阶段：</p><p><strong>阶段 1：局部直方图</strong></p><p>每个 Block 统计自己区域的桶计数。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">__global__ void compute_histograms(unsigned int *data, int *histograms, </span><br><span class="line">                                    int n, int bit) &#123;</span><br><span class="line">    __shared__ int local_hist[RADIX];</span><br><span class="line">    </span><br><span class="line">    // 初始化</span><br><span class="line">    if (threadIdx.x &lt; RADIX) local_hist[threadIdx.x] = 0;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    // 统计</span><br><span class="line">    int i = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    if (i &lt; n) &#123;</span><br><span class="line">        int digit = (data[i] &gt;&gt; bit) &amp; RADIX_MASK;</span><br><span class="line">        atomicAdd(&amp;local_hist[digit], 1);</span><br><span class="line">    &#125;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    // 写入全局直方图</span><br><span class="line">    if (threadIdx.x &lt; RADIX) &#123;</span><br><span class="line">        histograms[blockIdx.x * RADIX + threadIdx.x] = local_hist[threadIdx.x];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>阶段 2：前缀和</strong></p><p>对所有 Block 的直方图做全局前缀和，得到每个 Block 每个桶的全局起始位置。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Block 0 桶 k 的起始位置 = Σ(Block &lt; 0, 桶 &lt; k 的计数) + Σ(Block &lt; 0, 桶 k 的计数)</span><br></pre></td></tr></table></figure><p>这是一个二维前缀和问题。</p><p><strong>阶段 3：重排（Scatter）</strong></p><p>根据计算出的位置，把元素移动到正确位置。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">__global__ void scatter(unsigned int *in, unsigned int *out, </span><br><span class="line">                        int *prefix, int n, int bit) &#123;</span><br><span class="line">    __shared__ int local_prefix[RADIX];</span><br><span class="line">    </span><br><span class="line">    // 加载本 Block 的前缀</span><br><span class="line">    if (threadIdx.x &lt; RADIX) &#123;</span><br><span class="line">        local_prefix[threadIdx.x] = prefix[blockIdx.x * RADIX + threadIdx.x];</span><br><span class="line">    &#125;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    int i = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    if (i &lt; n) &#123;</span><br><span class="line">        int digit = (in[i] &gt;&gt; bit) &amp; RADIX_MASK;</span><br><span class="line">        int pos = atomicAdd(&amp;local_prefix[digit], 1);</span><br><span class="line">        out[pos] = in[i];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="wan-zheng-liu-cheng" tabindex="-1" id="完整流程">完整流程</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">void radix_sort(unsigned int *data, int n) &#123;</span><br><span class="line">    unsigned int *d_data, *d_temp;</span><br><span class="line">    int *d_histograms, *d_prefix;</span><br><span class="line">    </span><br><span class="line">    int num_blocks = (n + BLOCK_SIZE - 1) / BLOCK_SIZE;</span><br><span class="line">    </span><br><span class="line">    cudaMalloc(&amp;d_data, n * sizeof(unsigned int));</span><br><span class="line">    cudaMalloc(&amp;d_temp, n * sizeof(unsigned int));</span><br><span class="line">    cudaMalloc(&amp;d_histograms, num_blocks * RADIX * sizeof(int));</span><br><span class="line">    cudaMalloc(&amp;d_prefix, num_blocks * RADIX * sizeof(int));</span><br><span class="line">    </span><br><span class="line">    cudaMemcpy(d_data, data, n * sizeof(unsigned int), cudaMemcpyHostToDevice);</span><br><span class="line">    </span><br><span class="line">    for (int bit = 0; bit &lt; 32; bit += RADIX_BITS) &#123;</span><br><span class="line">        // 阶段 1：计算直方图</span><br><span class="line">        compute_histograms&lt;&lt;&lt;num_blocks, BLOCK_SIZE&gt;&gt;&gt;</span><br><span class="line">            (d_data, d_histograms, n, bit);</span><br><span class="line">        </span><br><span class="line">        // 阶段 2：全局前缀和</span><br><span class="line">        exclusive_scan(d_histograms, d_prefix, num_blocks * RADIX);</span><br><span class="line">        </span><br><span class="line">        // 阶段 3：重排</span><br><span class="line">        scatter&lt;&lt;&lt;num_blocks, BLOCK_SIZE&gt;&gt;&gt;</span><br><span class="line">            (d_data, d_temp, d_prefix, n, bit);</span><br><span class="line">        </span><br><span class="line">        // 交换缓冲区</span><br><span class="line">        swap(d_data, d_temp);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    cudaMemcpy(data, d_data, n * sizeof(unsigned int), cudaMemcpyDeviceToHost);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="you-hua-ji-zhu" tabindex="-1" id="优化技术">优化技术</h2><h3 id="bi-mian-yuan-zi-cao-zuo" tabindex="-1" id="避免原子操作">避免原子操作</h3><p>阶段 3 的 <code>atomicAdd</code> 是瓶颈。可以用<strong>本地排序 + 前缀和</strong>替代：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1. 每个线程处理多个元素</span><br><span class="line">2. 本地计算每个桶的元素个数</span><br><span class="line">3. Block 内前缀和得到每个线程的起始偏移</span><br><span class="line">4. 无冲突地写入输出</span><br></pre></td></tr></table></figure><h3 id="xiang-liang-hua-jia-zai" tabindex="-1" id="向量化加载">向量化加载</h3><p>每次加载 4 个元素：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">uint4 data4 = *reinterpret_cast&lt;uint4*&gt;(&amp;data[i]);</span><br><span class="line">// 处理 data4.x, data4.y, data4.z, data4.w</span><br></pre></td></tr></table></figure><p>减少内存事务数。</p><h3 id="fen-tong-you-hua" tabindex="-1" id="分桶优化">分桶优化</h3><p>对于大范围数据，先按高位分成大桶，再分别排序小桶：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">第一遍：按高 8 位分成 256 个桶</span><br><span class="line">第二遍：对每个桶按剩余 24 位排序</span><br></pre></td></tr></table></figure><p>减少每轮需要处理的数据量。</p><h2 id="gui-bing-pai-xu" tabindex="-1" id="归并排序">归并排序</h2><h3 id="gpu-gui-bing-pai-xu-liu-cheng" tabindex="-1" id="GPU-归并排序流程">GPU 归并排序流程</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1. Block 内排序（用共享内存）</span><br><span class="line">2. 跨 Block 归并（用并行归并）</span><br></pre></td></tr></table></figure><p><strong>Block 内排序</strong>可以用：</p><ul><li>比特序列排序（Bitonic Sort）</li><li>奇偶归并排序</li><li>直接归并排序</li></ul><h3 id="block-nei-pai-xu" tabindex="-1" id="Block-内排序">Block 内排序</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">__global__ void block_sort(int *data, int n) &#123;</span><br><span class="line">    __shared__ int s_data[BLOCK_SIZE];</span><br><span class="line">    </span><br><span class="line">    int tid = threadIdx.x;</span><br><span class="line">    int gid = blockIdx.x * blockDim.x + tid;</span><br><span class="line">    </span><br><span class="line">    // 加载</span><br><span class="line">    s_data[tid] = (gid &lt; n) ? data[gid] : INT_MAX;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    // 双调排序（Bitonic Sort）</span><br><span class="line">    for (int k = 2; k &lt;= BLOCK_SIZE; k *= 2) &#123;</span><br><span class="line">        for (int j = k / 2; j &gt; 0; j /= 2) &#123;</span><br><span class="line">            int ixj = tid ^ j;</span><br><span class="line">            if (ixj &gt; tid) &#123;</span><br><span class="line">                bool ascending = ((tid &amp; k) == 0);</span><br><span class="line">                if ((s_data[tid] &gt; s_data[ixj]) == ascending) &#123;</span><br><span class="line">                    // 交换</span><br><span class="line">                    int temp = s_data[tid];</span><br><span class="line">                    s_data[tid] = s_data[ixj];</span><br><span class="line">                    s_data[ixj] = temp;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            __syncthreads();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    // 写回</span><br><span class="line">    if (gid &lt; n) data[gid] = s_data[tid];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="kua-block-gui-bing" tabindex="-1" id="跨-Block-归并">跨 Block 归并</h3><p>使用第十二章的并行归并技术：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">void merge_sort_gpu(int *data, int n) &#123;</span><br><span class="line">    // 阶段 1：Block 内排序</span><br><span class="line">    int num_blocks = (n + BLOCK_SIZE - 1) / BLOCK_SIZE;</span><br><span class="line">    block_sort&lt;&lt;&lt;num_blocks, BLOCK_SIZE&gt;&gt;&gt;(data, n);</span><br><span class="line">    </span><br><span class="line">    // 阶段 2：逐层归并</span><br><span class="line">    for (int width = BLOCK_SIZE; width &lt; n; width *= 2) &#123;</span><br><span class="line">        int num_merges = (n + 2 * width - 1) / (2 * width);</span><br><span class="line">        </span><br><span class="line">        parallel_merge&lt;&lt;&lt;num_merges, BLOCK_SIZE&gt;&gt;&gt;(</span><br><span class="line">            data, n, width);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="fu-za-du-fen-xi" tabindex="-1" id="复杂度分析">复杂度分析</h3><table><thead><tr><th>阶段</th><th>工作量</th><th>并行度</th></tr></thead><tbody><tr><td>Block 排序</td><td>O(n log B)</td><td>n/B 个 Block</td></tr><tr><td>归并 k 层</td><td>O(n) × log(n/B)</td><td>递减</td></tr><tr><td><strong>总计</strong></td><td>O(n log n)</td><td></td></tr></tbody></table><h2 id="yang-ben-pai-xu-sample-sort" tabindex="-1" id="样本排序（Sample-Sort）">样本排序（Sample Sort）</h2><h3 id="si-xiang" tabindex="-1" id="思想">思想</h3><ol><li><strong>采样</strong>：从数据中随机选取样本</li><li><strong>排序样本</strong>：得到分割点（splitters）</li><li><strong>分区</strong>：根据分割点把数据分到不同桶</li><li><strong>桶排序</strong>：每个桶独立排序</li><li><strong>合并</strong>：按顺序拼接所有桶</li></ol><h3 id="you-shi" tabindex="-1" id="优势">优势</h3><ul><li>负载均衡更好（采样保证桶大小接近）</li><li>减少同步开销（桶间独立）</li></ul><h3 id="gpu-shi-xian-yao-dian" tabindex="-1" id="GPU-实现要点">GPU 实现要点</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">void sample_sort(int *data, int n) &#123;</span><br><span class="line">    // 1. 采样</span><br><span class="line">    int sample_size = min(n, 1024);</span><br><span class="line">    sample_and_sort(data, n, samples, sample_size);</span><br><span class="line">    </span><br><span class="line">    // 2. 选择分割点</span><br><span class="line">    int num_buckets = 256;</span><br><span class="line">    select_splitters(samples, sample_size, splitters, num_buckets);</span><br><span class="line">    </span><br><span class="line">    // 3. 分区</span><br><span class="line">    partition_to_buckets(data, n, splitters, bucket_ids, bucket_counts);</span><br><span class="line">    </span><br><span class="line">    // 4. 前缀和得到桶偏移</span><br><span class="line">    exclusive_scan(bucket_counts, bucket_offsets, num_buckets);</span><br><span class="line">    </span><br><span class="line">    // 5. 重排到桶</span><br><span class="line">    scatter_to_buckets(data, bucket_ids, bucket_offsets, temp, n);</span><br><span class="line">    </span><br><span class="line">    // 6. 桶内排序</span><br><span class="line">    for (int b = 0; b &lt; num_buckets; b++) &#123;</span><br><span class="line">        int start = bucket_offsets[b];</span><br><span class="line">        int end = bucket_offsets[b + 1];</span><br><span class="line">        sort_bucket&lt;&lt;&lt;...&gt;&gt;&gt;(temp + start, end - start);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    // 7. 拷贝回</span><br><span class="line">    cudaMemcpy(data, temp, n * sizeof(int), cudaMemcpyDeviceToDevice);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="pai-xu-wen-ding-xing" tabindex="-1" id="排序稳定性">排序稳定性</h2><h3 id="wei-shi-yao-zhong-yao" tabindex="-1" id="为什么重要">为什么重要</h3><p><strong>稳定排序</strong>：相同键值的元素保持原有的相对顺序。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">原始:    [(3,&#x27;a&#x27;), (1,&#x27;b&#x27;), (3,&#x27;c&#x27;), (2,&#x27;d&#x27;)]</span><br><span class="line">按数字稳定排序:</span><br><span class="line">         [(1,&#x27;b&#x27;), (2,&#x27;d&#x27;), (3,&#x27;a&#x27;), (3,&#x27;c&#x27;)]</span><br><span class="line">                          ↑ &#x27;a&#x27; 仍在 &#x27;c&#x27; 前面</span><br></pre></td></tr></table></figure><p><strong>应用</strong>：</p><ul><li>多关键字排序（先按次关键字，再按主关键字）</li><li>数据库操作（保持插入顺序）</li><li>基数排序的正确性依赖稳定性</li></ul><h3 id="gpu-pai-xu-de-wen-ding-xing" tabindex="-1" id="GPU-排序的稳定性">GPU 排序的稳定性</h3><table><thead><tr><th>算法</th><th>稳定性</th></tr></thead><tbody><tr><td>基数排序</td><td>稳定</td></tr><tr><td>归并排序</td><td>稳定</td></tr><tr><td>双调排序</td><td>不稳定</td></tr><tr><td>快速排序</td><td>不稳定</td></tr></tbody></table><p>基数排序天然稳定，是 GPU 排序的首选。</p><h2 id="cub-thrust-ku" tabindex="-1" id="CUB-Thrust-库">CUB/Thrust 库</h2><h3 id="shi-yong-thrust" tabindex="-1" id="使用-Thrust">使用 Thrust</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;thrust/sort.h&gt;</span><br><span class="line">#include &lt;thrust/device_vector.h&gt;</span><br><span class="line"></span><br><span class="line">void sortWithThrust(int *d_data, int n) &#123;</span><br><span class="line">    thrust::device_ptr&lt;int&gt; d_ptr(d_data);</span><br><span class="line">    thrust::sort(d_ptr, d_ptr + n);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 稳定排序</span><br><span class="line">thrust::stable_sort(d_ptr, d_ptr + n);</span><br><span class="line"></span><br><span class="line">// 按键排序</span><br><span class="line">thrust::sort_by_key(d_keys, d_keys + n, d_values);</span><br></pre></td></tr></table></figure><h3 id="shi-yong-cub" tabindex="-1" id="使用-CUB">使用 CUB</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;cub/cub.cuh&gt;</span><br><span class="line"></span><br><span class="line">void sortWithCub(unsigned int *d_data, int n) &#123;</span><br><span class="line">    void *d_temp = nullptr;</span><br><span class="line">    size_t temp_bytes = 0;</span><br><span class="line">    </span><br><span class="line">    // 确定临时存储大小</span><br><span class="line">    cub::DeviceRadixSort::SortKeys(d_temp, temp_bytes, </span><br><span class="line">                                    d_data, d_data, n);</span><br><span class="line">    </span><br><span class="line">    cudaMalloc(&amp;d_temp, temp_bytes);</span><br><span class="line">    </span><br><span class="line">    // 执行排序</span><br><span class="line">    cub::DeviceRadixSort::SortKeys(d_temp, temp_bytes,</span><br><span class="line">                                    d_data, d_data, n);</span><br><span class="line">    </span><br><span class="line">    cudaFree(d_temp);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 键值对排序</span><br><span class="line">cub::DeviceRadixSort::SortPairs(d_temp, temp_bytes,</span><br><span class="line">                                 d_keys, d_keys,</span><br><span class="line">                                 d_values, d_values, n);</span><br></pre></td></tr></table></figure><h3 id="xing-neng-dui-bi" tabindex="-1" id="性能对比">性能对比</h3><p>以 1 亿个32位整数排序为例：</p><table><thead><tr><th>实现</th><th>时间</th><th>吞吐量</th></tr></thead><tbody><tr><td>std::sort (CPU)</td><td>~8 秒</td><td>50 M元素/s</td></tr><tr><td>Thrust sort</td><td>~30 ms</td><td>3.3 G元素/s</td></tr><tr><td>CUB RadixSort</td><td>~15 ms</td><td>6.6 G元素/s</td></tr></tbody></table><p><strong>测试环境</strong>：</p><ul><li>CPU：Intel i9-12900K（16核）</li><li>GPU：NVIDIA RTX 3090（10496 CUDA 核心，24GB 显存）</li><li>数据：随机生成的32位无符号整数</li></ul><p>GPU 排序比单核 CPU 快 500 倍以上，比多核 CPU 快 200 倍以上。</p><h2 id="xing-neng-you-hua-zong-jie" tabindex="-1" id="性能优化总结">性能优化总结</h2><h3 id="you-hua-ceng-ci" tabindex="-1" id="优化层次">优化层次</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">┌─────────────────────────────────────────────────┐</span><br><span class="line">│ Level 4: 算法选择                                │</span><br><span class="line">│   - 基数排序（整数最快）                         │</span><br><span class="line">│   - 归并排序（通用稳定）                         │</span><br><span class="line">│   - 样本排序（负载均衡）                         │</span><br><span class="line">├─────────────────────────────────────────────────┤</span><br><span class="line">│ Level 3: 数据局部性                              │</span><br><span class="line">│   - Block 内共享内存排序                         │</span><br><span class="line">│   - 向量化加载/存储                              │</span><br><span class="line">├─────────────────────────────────────────────────┤</span><br><span class="line">│ Level 2: 减少同步                                │</span><br><span class="line">│   - Warp 内排序无需同步                          │</span><br><span class="line">│   - 减少 Kernel 启动次数                         │</span><br><span class="line">├─────────────────────────────────────────────────┤</span><br><span class="line">│ Level 1: 利用前缀和                              │</span><br><span class="line">│   - 高效的直方图和分配                           │</span><br><span class="line">│   - 避免原子操作争用                             │</span><br><span class="line">└─────────────────────────────────────────────────┘</span><br></pre></td></tr></table></figure><h3 id="xuan-ze-zhi-nan" tabindex="-1" id="选择指南">选择指南</h3><table><thead><tr><th>数据类型</th><th>推荐算法</th></tr></thead><tbody><tr><td>32 位整数</td><td>基数排序</td></tr><tr><td>64 位整数</td><td>基数排序</td></tr><tr><td>浮点数</td><td>基数排序</td></tr><tr><td>结构体/自定义</td><td>归并排序</td></tr><tr><td>需要稳定性</td><td>基数/归并</td></tr></tbody></table><p>浮点数需要特殊处理符号位和指数。</p><h2 id="xiao-jie" tabindex="-1" id="小结">小结</h2><p>第十三章系统讲解 GPU 排序：</p><p><strong>基数排序</strong>：GPU 上最快的整数排序。按位处理，利用前缀和确定输出位置。多轮（32 位需要 8 轮 4 位）但每轮高度并行。</p><p><strong>三阶段流程</strong>：直方图统计 → 前缀和计算 → 元素重排。每个阶段都是高效的并行操作。</p><p><strong>归并排序</strong>：通用且稳定。Block 内用双调排序，跨 Block 用并行归并。适合任意可比较类型。</p><p><strong>样本排序</strong>：通过采样实现负载均衡。适合数据分布不均匀的情况。</p><p><strong>稳定性</strong>：基数排序天然稳定，多关键字排序和数据库操作必需。</p><p><strong>库优先</strong>：CUB 的 RadixSort 高度优化，生产环境直接使用。理解原理有助于特殊需求的定制。</p><p>排序是并行计算的试金石，把前面学的归约、前缀和、归并等技术综合运用。掌握 GPU 排序，就掌握了这些基础原语的实战应用。</p><hr><h2 id="xia-yi-bu" tabindex="-1" id="🚀-下一步">🚀 下一步</h2><hr><h2 id="can-kao-zi-liao" tabindex="-1" id="📚-参考资料">📚 参考资料</h2><ul><li>PMPP 第四版 Chapter 13</li><li><a href="https://smarter.xin/posts/d9ee9484/">第十三章：排序</a></li></ul><p><strong>学习愉快！</strong> 🎓</p><hr><blockquote><p><strong>本文 GitHub 仓库</strong>: <a href="https://github.com/psmarter/PMPP-Learning">https://github.com/psmarter/PMPP-Learning</a></p></blockquote>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h2 id=&quot;qian-yan&quot; tabindex=&quot;-1&quot; id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;前两章学习了归约和归并，本章学习&lt;strong&gt;排序（Sorting）&lt;/strong&gt;——把无序数据变成有序数据。排序是最基础的算法之一，在几乎所有计算领域都有应用。GPU</summary>
        
      
    
    
    
    <category term="知识分享" scheme="https://smarter.xin/categories/knowledge-sharing/"/>
    
    
    <category term="CUDA" scheme="https://smarter.xin/tags/CUDA/"/>
    
    <category term="GPU编程" scheme="https://smarter.xin/tags/gpu-programming/"/>
    
    <category term="并行计算" scheme="https://smarter.xin/tags/parallel-computing/"/>
    
    <category term="PMPP" scheme="https://smarter.xin/tags/PMPP/"/>
    
    <category term="排序" scheme="https://smarter.xin/tags/sort/"/>
    
    <category term="基数排序" scheme="https://smarter.xin/tags/radix-sort/"/>
    
    <category term="归并排序" scheme="https://smarter.xin/tags/merge-sort/"/>
    
  </entry>
  
  <entry>
    <title>PMPP-第十二章：归并</title>
    <link href="https://smarter.xin/posts/31928809/"/>
    <id>https://smarter.xin/posts/31928809/</id>
    <published>2026-01-18T13:42:06.000Z</published>
    <updated>2026-01-24T11:47:21.463Z</updated>
    
    <content type="html"><![CDATA[<h2 id="qian-yan" tabindex="-1" id="前言">前言</h2><p>第十一章学习了前缀和，本章学习<strong>归并（Merge）</strong>——把两个有序数组合并成一个有序数组。归并是排序算法的核心组件（归并排序），也是数据库操作的基础（JOIN 操作）。并行归并的挑战在于：<strong>输出位置取决于两个数组的数据内容</strong>，不像矩阵乘法那样可以根据线程索引直接确定位置。第十二章讲解如何使用**协同排名（Co-Rank）**技术解决这个&quot;动态数据识别&quot;问题。</p><blockquote><p><strong>📦 配套资源</strong>：本系列文章配有完整的 <a href="https://github.com/psmarter/PMPP-Learning">GitHub 仓库</a>，包含每章的练习题解答、CUDA 代码实现和详细注释。所有代码都经过测试，可以直接运行。</p></blockquote><h2 id="gui-bing-ji-chu" tabindex="-1" id="归并基础">归并基础</h2><h3 id="shi-yao-shi-gui-bing" tabindex="-1" id="什么是归并">什么是归并</h3><p><strong>归并</strong>：给定两个<strong>已排序</strong>的数组 A 和 B，生成一个包含所有元素的<strong>有序</strong>数组 C。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">A = [1, 3, 5, 7, 9]</span><br><span class="line">B = [2, 4, 6, 8, 10]</span><br><span class="line">C = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</span><br></pre></td></tr></table></figure><h3 id="chuan-xing-gui-bing" tabindex="-1" id="串行归并">串行归并</h3><p>经典的双指针算法：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">merge_sequential</span><span class="params">(<span class="type">int</span> *A, <span class="type">int</span> m, <span class="type">int</span> *B, <span class="type">int</span> n, <span class="type">int</span> *C)</span> &#123;</span><br><span class="line">    <span class="type">int</span> i = <span class="number">0</span>, j = <span class="number">0</span>, k = <span class="number">0</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> (i &lt; m &amp;&amp; j &lt; n) &#123;</span><br><span class="line">        <span class="keyword">if</span> (A[i] &lt;= B[j]) &#123;</span><br><span class="line">            C[k++] = A[i++];</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            C[k++] = B[j++];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 处理剩余元素</span></span><br><span class="line">    <span class="keyword">while</span> (i &lt; m) C[k++] = A[i++];</span><br><span class="line">    <span class="keyword">while</span> (j &lt; n) C[k++] = B[j++];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>时间复杂度 O(m+n)，空间复杂度 O(1)（不计输出）。</p><h3 id="bing-xing-hua-de-tiao-zhan" tabindex="-1" id="并行化的挑战">并行化的挑战</h3><p><strong>问题</strong>：输出位置 k 对应的输入位置 (i, j) 取决于数据内容。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">要填充 C[5]，需要知道：</span><br><span class="line">- A 和 B 中有多少元素 ≤ C[5] 的值</span><br><span class="line">- 这取决于 A 和 B 的具体内容</span><br></pre></td></tr></table></figure><p>不像矩阵乘法那样可以根据线程 ID 直接计算输入位置。</p><p><strong>核心问题</strong>：如何让每个线程知道自己应该处理 A 和 B 的哪一段？</p><h2 id="xie-tong-pai-ming-co-rank" tabindex="-1" id="协同排名（Co-Rank）">协同排名（Co-Rank）</h2><h3 id="he-xin-dong-cha" tabindex="-1" id="核心洞察">核心洞察</h3><p>对于输出位置 k，假设它对应 A 中的前 i 个元素和 B 中的前 j 个元素，则：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">i + j = k</span><br></pre></td></tr></table></figure><p>这就是<strong>协同排名</strong>约束。</p><p><strong>问题转化</strong>：给定 k，找到满足约束且保持有序性的 (i, j)。</p><h3 id="er-fen-sou-suo-jie-fa" tabindex="-1" id="二分搜索解法">二分搜索解法</h3><p><strong>有序性条件</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A[i-1] ≤ B[j]  且  B[j-1] ≤ A[i]</span><br></pre></td></tr></table></figure><p>即：A 中第 i 个元素应该排在 B 的第 j 个元素之前或相等，反之亦然。</p><p><strong>算法</strong>：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">co_rank</span><span class="params">(<span class="type">int</span> k, <span class="type">int</span> *A, <span class="type">int</span> m, <span class="type">int</span> *B, <span class="type">int</span> n)</span> &#123;</span><br><span class="line">    <span class="comment">// i 的范围</span></span><br><span class="line">    <span class="type">int</span> i_low = max(<span class="number">0</span>, k - n);</span><br><span class="line">    <span class="type">int</span> i_high = min(k, m);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> (i_low &lt; i_high) &#123;</span><br><span class="line">        <span class="type">int</span> i = (i_low + i_high) / <span class="number">2</span>;</span><br><span class="line">        <span class="type">int</span> j = k - i;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> (i &gt; <span class="number">0</span> &amp;&amp; j &lt; n &amp;&amp; A[i<span class="number">-1</span>] &gt; B[j]) &#123;</span><br><span class="line">            <span class="comment">// A[i-1] 太大，i 需要减小</span></span><br><span class="line">            i_high = i;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (j &gt; <span class="number">0</span> &amp;&amp; i &lt; m &amp;&amp; B[j<span class="number">-1</span>] &gt; A[i]) &#123;</span><br><span class="line">            <span class="comment">// B[j-1] 太大，i 需要增大</span></span><br><span class="line">            i_low = i + <span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// 找到了</span></span><br><span class="line">            <span class="keyword">return</span> i;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> i_low;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>时间复杂度</strong>：O(log(min(k, m, n)))</p><h3 id="shi-li" tabindex="-1" id="示例">示例</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">A = [1, 3, 5, 7, 9]  (m=5)</span><br><span class="line">B = [2, 4, 6, 8, 10] (n=5)</span><br><span class="line">k = 6（输出位置 6）</span><br><span class="line"></span><br><span class="line">i + j = 6</span><br><span class="line"></span><br><span class="line">尝试 i=3: j=3</span><br><span class="line">  A[2]=5 ≤ B[3]=8? ✓</span><br><span class="line">  B[2]=6 ≤ A[3]=7? ✓</span><br><span class="line">  找到！</span><br><span class="line"></span><br><span class="line">所以 C[0..5] 来自 A[0..2] 和 B[0..2]</span><br><span class="line">C[6..9] 来自 A[3..4] 和 B[3..4]</span><br></pre></td></tr></table></figure><h2 id="ji-chu-bing-xing-gui-bing" tabindex="-1" id="基础并行归并">基础并行归并</h2><h3 id="mei-xian-cheng-yi-ge-yuan-su" tabindex="-1" id="每线程一个元素">每线程一个元素</h3><p>最简单的并行化：每个线程负责计算一个输出元素。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">__global__ void merge_basic(int *A, int m, int *B, int n, int *C) &#123;</span><br><span class="line">    int k = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    </span><br><span class="line">    if (k &lt; m + n) &#123;</span><br><span class="line">        int i = co_rank(k, A, m, B, n);</span><br><span class="line">        int j = k - i;</span><br><span class="line">        </span><br><span class="line">        int i_next = co_rank(k + 1, A, m, B, n);</span><br><span class="line">        int j_next = k + 1 - i_next;</span><br><span class="line">        </span><br><span class="line">        // 确定这个位置的值</span><br><span class="line">        if (i_next &gt; i) &#123;</span><br><span class="line">            C[k] = A[i];</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            C[k] = B[j];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="wen-ti" tabindex="-1" id="问题">问题</h3><p><strong>效率低</strong>：每个线程都做一次二分搜索（O(log n)），总工作量 O(n log n)。</p><p>串行只需 O(n)，并行反而做了更多工作！</p><h2 id="fen-kuai-bing-xing-gui-bing" tabindex="-1" id="分块并行归并">分块并行归并</h2><h3 id="si-lu" tabindex="-1" id="思路">思路</h3><p>不要每个元素都二分搜索，而是：</p><ol><li>把输出分成若干块（Tile）</li><li>每个 Tile 做一次 Co-Rank 找到边界</li><li>Tile 内部用串行归并</li></ol><h3 id="suan-fa" tabindex="-1" id="算法">算法</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">输出大小：m + n</span><br><span class="line">Tile 大小：T</span><br><span class="line">Tile 数量：(m + n + T - 1) / T</span><br><span class="line"></span><br><span class="line">对于 Tile k：</span><br><span class="line">  起始位置：k * T</span><br><span class="line">  结束位置：min((k+1) * T, m+n)</span><br><span class="line">  </span><br><span class="line">  Co-Rank 找到 (i_start, j_start) 和 (i_end, j_end)</span><br><span class="line">  </span><br><span class="line">  归并 A[i_start..i_end] 和 B[j_start..j_end]</span><br></pre></td></tr></table></figure><h3 id="cuda-shi-xian" tabindex="-1" id="CUDA-实现">CUDA 实现</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">#define TILE_SIZE 1024</span><br><span class="line"></span><br><span class="line">__global__ void merge_tiled(int *A, int m, int *B, int n, int *C) &#123;</span><br><span class="line">    // 每个 Block 处理一个 Tile</span><br><span class="line">    int k_start = blockIdx.x * TILE_SIZE;</span><br><span class="line">    int k_end = min(k_start + TILE_SIZE, m + n);</span><br><span class="line">    </span><br><span class="line">    // Co-Rank 找边界</span><br><span class="line">    __shared__ int i_start, j_start, i_end, j_end;</span><br><span class="line">    </span><br><span class="line">    if (threadIdx.x == 0) &#123;</span><br><span class="line">        i_start = co_rank(k_start, A, m, B, n);</span><br><span class="line">        j_start = k_start - i_start;</span><br><span class="line">        i_end = co_rank(k_end, A, m, B, n);</span><br><span class="line">        j_end = k_end - i_end;</span><br><span class="line">    &#125;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    // 每个线程处理 Tile 中的一部分</span><br><span class="line">    int tile_size = k_end - k_start;</span><br><span class="line">    int elements_per_thread = (tile_size + blockDim.x - 1) / blockDim.x;</span><br><span class="line">    </span><br><span class="line">    int local_k = threadIdx.x * elements_per_thread;</span><br><span class="line">    int local_k_end = min(local_k + elements_per_thread, tile_size);</span><br><span class="line">    </span><br><span class="line">    // 线程内 Co-Rank</span><br><span class="line">    int A_seg_size = i_end - i_start;</span><br><span class="line">    int B_seg_size = j_end - j_start;</span><br><span class="line">    </span><br><span class="line">    int local_i = co_rank(local_k, A + i_start, A_seg_size, </span><br><span class="line">                                   B + j_start, B_seg_size);</span><br><span class="line">    int local_j = local_k - local_i;</span><br><span class="line">    </span><br><span class="line">    int local_i_end = co_rank(local_k_end, A + i_start, A_seg_size,</span><br><span class="line">                                           B + j_start, B_seg_size);</span><br><span class="line">    int local_j_end = local_k_end - local_i_end;</span><br><span class="line">    </span><br><span class="line">    // 串行归并</span><br><span class="line">    merge_sequential(A + i_start + local_i, local_i_end - local_i,</span><br><span class="line">                     B + j_start + local_j, local_j_end - local_j,</span><br><span class="line">                     C + k_start + local_k);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="gong-zuo-liang-fen-xi" tabindex="-1" id="工作量分析">工作量分析</h3><table><thead><tr><th>操作</th><th>次数</th><th>单次复杂度</th></tr></thead><tbody><tr><td>Block Co-Rank</td><td>(m+n)/T</td><td>O(log(m+n))</td></tr><tr><td>线程 Co-Rank</td><td>(m+n)/T × blockDim</td><td>O(log T)</td></tr><tr><td>串行归并</td><td>(m+n)/T × blockDim</td><td>O(T/blockDim)</td></tr></tbody></table><p>总工作量 ≈ O(m+n)，接近串行！</p><h2 id="gong-xiang-nei-cun-you-hua" tabindex="-1" id="共享内存优化">共享内存优化</h2><h3 id="dong-ji" tabindex="-1" id="动机">动机</h3><p>前面的实现每个线程都访问全局内存做串行归并。如果把 Tile 数据加载到共享内存，可以大幅减少全局内存访问。</p><h3 id="shi-xian" tabindex="-1" id="实现">实现</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">#define TILE_SIZE 1024</span><br><span class="line"></span><br><span class="line">__global__ void merge_shared(int *A, int m, int *B, int n, int *C) &#123;</span><br><span class="line">    __shared__ int A_s[TILE_SIZE];</span><br><span class="line">    __shared__ int B_s[TILE_SIZE];</span><br><span class="line">    __shared__ int C_s[TILE_SIZE];</span><br><span class="line">    </span><br><span class="line">    int k_start = blockIdx.x * TILE_SIZE;</span><br><span class="line">    int k_end = min(k_start + TILE_SIZE, m + n);</span><br><span class="line">    int tile_size = k_end - k_start;</span><br><span class="line">    </span><br><span class="line">    // Co-Rank 找边界</span><br><span class="line">    __shared__ int i_start, j_start, i_end, j_end;</span><br><span class="line">    </span><br><span class="line">    if (threadIdx.x == 0) &#123;</span><br><span class="line">        i_start = co_rank(k_start, A, m, B, n);</span><br><span class="line">        j_start = k_start - i_start;</span><br><span class="line">        i_end = co_rank(k_end, A, m, B, n);</span><br><span class="line">        j_end = k_end - i_end;</span><br><span class="line">    &#125;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    int A_size = i_end - i_start;</span><br><span class="line">    int B_size = j_end - j_start;</span><br><span class="line">    </span><br><span class="line">    // 加载到共享内存</span><br><span class="line">    for (int i = threadIdx.x; i &lt; A_size; i += blockDim.x) &#123;</span><br><span class="line">        A_s[i] = A[i_start + i];</span><br><span class="line">    &#125;</span><br><span class="line">    for (int i = threadIdx.x; i &lt; B_size; i += blockDim.x) &#123;</span><br><span class="line">        B_s[i] = B[j_start + i];</span><br><span class="line">    &#125;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    // 线程内 Co-Rank（使用共享内存）</span><br><span class="line">    int elements_per_thread = (tile_size + blockDim.x - 1) / blockDim.x;</span><br><span class="line">    int local_k = threadIdx.x * elements_per_thread;</span><br><span class="line">    int local_k_end = min(local_k + elements_per_thread, tile_size);</span><br><span class="line">    </span><br><span class="line">    int local_i = co_rank(local_k, A_s, A_size, B_s, B_size);</span><br><span class="line">    int local_j = local_k - local_i;</span><br><span class="line">    </span><br><span class="line">    int local_i_end = co_rank(local_k_end, A_s, A_size, B_s, B_size);</span><br><span class="line">    int local_j_end = local_k_end - local_i_end;</span><br><span class="line">    </span><br><span class="line">    // 归并到共享内存</span><br><span class="line">    merge_sequential(A_s + local_i, local_i_end - local_i,</span><br><span class="line">                     B_s + local_j, local_j_end - local_j,</span><br><span class="line">                     C_s + local_k);</span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    // 写回全局内存</span><br><span class="line">    for (int i = threadIdx.x; i &lt; tile_size; i += blockDim.x) &#123;</span><br><span class="line">        C[k_start + i] = C_s[i];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="xing-neng-ti-sheng" tabindex="-1" id="性能提升">性能提升</h3><table><thead><tr><th>版本</th><th>全局内存访问</th><th>性能</th></tr></thead><tbody><tr><td>基础</td><td>O(m+n) 次</td><td>1×</td></tr><tr><td>分块</td><td>O(m+n) 次</td><td>~5×</td></tr><tr><td>共享内存</td><td>O(m+n)/T 次</td><td>~10×</td></tr></tbody></table><h2 id="xun-huan-huan-chong-qu-you-hua" tabindex="-1" id="循环缓冲区优化">循环缓冲区优化</h2><h3 id="wen-ti-1" tabindex="-1" id="问题-2">问题</h3><p>共享内存有限，如果 A_size + B_size &gt; 共享内存容量怎么办？</p><h3 id="si-lu-liu-shi-chu-li" tabindex="-1" id="思路：流式处理">思路：流式处理</h3><p>用<strong>循环缓冲区</strong>逐块处理：</p><ol><li>加载 A 和 B 的一小块到共享内存</li><li>归并能归并的部分</li><li>加载下一块，继续归并</li><li>重复直到完成</li></ol><h3 id="guan-jian-dian" tabindex="-1" id="关键点">关键点</h3><p><strong>消费跟踪</strong>：记录 A 和 B 各消费了多少元素。</p><p><strong>缓冲区管理</strong>：循环使用缓冲区空间。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">__global__ void merge_circular(int *A, int m, int *B, int n, int *C) &#123;</span><br><span class="line">    __shared__ int buffer_A[BUFFER_SIZE];</span><br><span class="line">    __shared__ int buffer_B[BUFFER_SIZE];</span><br><span class="line">    </span><br><span class="line">    // ... 初始化 ...</span><br><span class="line">    </span><br><span class="line">    int a_consumed = 0, b_consumed = 0;</span><br><span class="line">    int a_loaded = 0, b_loaded = 0;</span><br><span class="line">    int c_produced = 0;</span><br><span class="line">    </span><br><span class="line">    while (c_produced &lt; tile_size) &#123;</span><br><span class="line">        // 填充缓冲区</span><br><span class="line">        while (a_loaded - a_consumed &lt; BUFFER_SIZE &amp;&amp; a_loaded &lt; A_size) &#123;</span><br><span class="line">            buffer_A[a_loaded % BUFFER_SIZE] = A_s[a_loaded];</span><br><span class="line">            a_loaded++;</span><br><span class="line">        &#125;</span><br><span class="line">        while (b_loaded - b_consumed &lt; BUFFER_SIZE &amp;&amp; b_loaded &lt; B_size) &#123;</span><br><span class="line">            buffer_B[b_loaded % BUFFER_SIZE] = B_s[b_loaded];</span><br><span class="line">            b_loaded++;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        // 归并一批</span><br><span class="line">        // ...</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这种技术在数据量远超共享内存时很有用。</p><h2 id="gui-bing-lu-jing-ke-shi-hua" tabindex="-1" id="归并路径可视化">归并路径可视化</h2><h3 id="co-rank-de-ji-he-jie-shi" tabindex="-1" id="Co-Rank-的几何解释">Co-Rank 的几何解释</h3><p>把归并过程可视化为 2D 网格中的路径：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">  B: 0   1   2   3   4</span><br><span class="line">     +---+---+---+---+</span><br><span class="line">A:0  |   |   |   |   |</span><br><span class="line">     +---+---+---+---+</span><br><span class="line">  1  |   |   |   |   |</span><br><span class="line">     +---+---+───+───+</span><br><span class="line">  2  |   |   |\  |   |</span><br><span class="line">     +---+---+─\─+---+</span><br><span class="line">  3  |   |   |  \|   |</span><br><span class="line">     +---+---+---+\--+</span><br><span class="line">  4  |   |   |   | \ |</span><br><span class="line">     +---+---+---+---+</span><br></pre></td></tr></table></figure><p><strong>路径规则</strong>：</p><ul><li>从 (0,0) 到 (m,n)</li><li>每步向右（取 A 元素）或向下（取 B 元素）</li><li>选择较小的元素决定方向</li></ul><p><strong>Co-Rank(k)</strong>：路径上第 k 步的位置。</p><h3 id="bing-xing-hua-shi-jiao" tabindex="-1" id="并行化视角">并行化视角</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">把输出分成 T 段：</span><br><span class="line">  段 0: 路径 [0, T)</span><br><span class="line">  段 1: 路径 [T, 2T)</span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">每段的起点由 Co-Rank 确定。</span><br></pre></td></tr></table></figure><h2 id="gui-bing-pai-xu" tabindex="-1" id="归并排序">归并排序</h2><h3 id="fen-zhi-jie-gou" tabindex="-1" id="分治结构">分治结构</h3><p>归并排序 = 递归拆分 + 归并合并</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[3,1,7,4,5,2,6,8]</span><br><span class="line">       ↓ 拆分</span><br><span class="line">[3,1,7,4] [5,2,6,8]</span><br><span class="line">    ↓ 拆分</span><br><span class="line">[3,1] [7,4] [5,2] [6,8]</span><br><span class="line">  ↓ 拆分</span><br><span class="line">[3][1] [7][4] [5][2] [6][8]</span><br><span class="line">  ↓ 归并</span><br><span class="line">[1,3] [4,7] [2,5] [6,8]</span><br><span class="line">    ↓ 归并</span><br><span class="line">[1,3,4,7] [2,5,6,8]</span><br><span class="line">       ↓ 归并</span><br><span class="line">[1,2,3,4,5,6,7,8]</span><br></pre></td></tr></table></figure><h3 id="bing-xing-gui-bing-pai-xu" tabindex="-1" id="并行归并排序">并行归并排序</h3><p>每层归并可以并行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">void parallel_merge_sort(int *data, int n) &#123;</span><br><span class="line">    // 从单元素开始，逐层归并</span><br><span class="line">    for (int width = 1; width &lt; n; width *= 2) &#123;</span><br><span class="line">        int num_merges = (n + 2 * width - 1) / (2 * width);</span><br><span class="line">        </span><br><span class="line">        // 并行执行所有归并</span><br><span class="line">        merge_kernel&lt;&lt;&lt;num_merges, BLOCK_SIZE&gt;&gt;&gt;(</span><br><span class="line">            data, n, width</span><br><span class="line">        );</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">__global__ void merge_kernel(int *data, int n, int width) &#123;</span><br><span class="line">    int merge_id = blockIdx.x;</span><br><span class="line">    int left = merge_id * 2 * width;</span><br><span class="line">    int mid = min(left + width, n);</span><br><span class="line">    int right = min(left + 2 * width, n);</span><br><span class="line">    </span><br><span class="line">    // 归并 [left, mid) 和 [mid, right)</span><br><span class="line">    merge_shared(data + left, mid - left, </span><br><span class="line">                 data + mid, right - mid, </span><br><span class="line">                 temp + left);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="fu-za-du" tabindex="-1" id="复杂度">复杂度</h3><table><thead><tr><th>指标</th><th>串行归并排序</th><th>并行归并排序</th></tr></thead><tbody><tr><td>层数</td><td>log₂N</td><td>log₂N</td></tr><tr><td>每层工作</td><td>O(N)</td><td>O(N)</td></tr><tr><td>总工作</td><td>O(N log N)</td><td>O(N log N)</td></tr><tr><td>并行时间</td><td>O(N log N)</td><td>O(log²N)*</td></tr></tbody></table><p>*假设有足够多的处理器，每层归并并行完成。</p><h2 id="yu-qi-ta-suan-fa-de-guan-xi" tabindex="-1" id="与其他算法的关系">与其他算法的关系</h2><h3 id="gui-bing-vs-ji-shu-pai-xu" tabindex="-1" id="归并-vs-基数排序">归并 vs 基数排序</h3><table><thead><tr><th>特性</th><th>归并排序</th><th>基数排序</th></tr></thead><tbody><tr><td>比较次数</td><td>O(N log N)</td><td>O(N × 位数)</td></tr><tr><td>稳定性</td><td>稳定</td><td>稳定</td></tr><tr><td>适用类型</td><td>通用</td><td>整数/定长键</td></tr><tr><td>GPU 友好度</td><td>中等</td><td>高</td></tr></tbody></table><p>基数排序在 GPU 上通常更快，但归并排序适用范围更广。</p><h3 id="gui-bing-vs-kuai-su-pai-xu" tabindex="-1" id="归并-vs-快速排序">归并 vs 快速排序</h3><table><thead><tr><th>特性</th><th>归并排序</th><th>快速排序</th></tr></thead><tbody><tr><td>最坏复杂度</td><td>O(N log N)</td><td>O(N²)</td></tr><tr><td>空间</td><td>O(N)</td><td>O(log N)</td></tr><tr><td>并行化</td><td>容易</td><td>较难</td></tr><tr><td>稳定性</td><td>稳定</td><td>不稳定</td></tr></tbody></table><p>归并排序的确定性和稳定性使其在并行计算中更受欢迎。</p><h2 id="cub-thrust-ku" tabindex="-1" id="CUB-Thrust-库">CUB/Thrust 库</h2><h3 id="shi-yong-thrust" tabindex="-1" id="使用-Thrust">使用 Thrust</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;thrust/merge.h&gt;</span><br><span class="line">#include &lt;thrust/device_vector.h&gt;</span><br><span class="line"></span><br><span class="line">void mergeWithThrust(int *A, int m, int *B, int n, int *C) &#123;</span><br><span class="line">    thrust::device_ptr&lt;int&gt; d_A(A);</span><br><span class="line">    thrust::device_ptr&lt;int&gt; d_B(B);</span><br><span class="line">    thrust::device_ptr&lt;int&gt; d_C(C);</span><br><span class="line">    </span><br><span class="line">    thrust::merge(d_A, d_A + m, d_B, d_B + n, d_C);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="shi-yong-cub" tabindex="-1" id="使用-CUB">使用 CUB</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;cub/cub.cuh&gt;</span><br><span class="line"></span><br><span class="line">void mergeWithCub(int *d_A, int m, int *d_B, int n, int *d_C) &#123;</span><br><span class="line">    void *d_temp = nullptr;</span><br><span class="line">    size_t temp_bytes = 0;</span><br><span class="line">    </span><br><span class="line">    cub::DeviceMerge::Merge(d_temp, temp_bytes, </span><br><span class="line">                            d_A, m, d_B, n, d_C);</span><br><span class="line">    </span><br><span class="line">    cudaMalloc(&amp;d_temp, temp_bytes);</span><br><span class="line">    </span><br><span class="line">    cub::DeviceMerge::Merge(d_temp, temp_bytes,</span><br><span class="line">                            d_A, m, d_B, n, d_C);</span><br><span class="line">    </span><br><span class="line">    cudaFree(d_temp);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="xiao-jie" tabindex="-1" id="小结">小结</h2><p>第十二章深入讲解并行归并：</p><p><strong>核心挑战</strong>：输出位置取决于输入数据内容（动态数据识别），不能简单根据线程 ID 确定。</p><p><strong>Co-Rank 技术</strong>：给定输出位置 k，用二分搜索找到对应的输入位置 (i, j)，满足 i + j = k。这是并行归并的关键。</p><p><strong>分块归并</strong>：把输出分成 Tile，每个 Tile 做一次 Co-Rank 找边界，Tile 内串行归并。平衡了并行开销和工作效率。</p><p><strong>共享内存优化</strong>：把 Tile 数据加载到共享内存，减少全局内存访问。循环缓冲区处理大 Tile。</p><p><strong>归并路径</strong>：归并过程可视化为 2D 网格中的路径，Co-Rank 找的是路径上的点。</p><p><strong>归并排序</strong>：log N 层归并，每层可以并行。总工作量 O(N log N)，并行时间可达 O(log² N)。</p><p>归并是排序、数据库操作的基础。掌握 Co-Rank 技术，就能处理各种&quot;输出位置依赖输入数据&quot;的问题。下一章学习排序——归并的直接应用。</p><hr><h2 id="xia-yi-bu" tabindex="-1" id="🚀-下一步">🚀 下一步</h2><hr><h2 id="can-kao-zi-liao" tabindex="-1" id="📚-参考资料">📚 参考资料</h2><ul><li>PMPP 第四版 Chapter 12</li><li><a href="https://smarter.xin/posts/31928809/">第十二章：归并</a></li></ul><p><strong>学习愉快！</strong> 🎓</p><hr><blockquote><p><strong>本文 GitHub 仓库</strong>: <a href="https://github.com/psmarter/PMPP-Learning">https://github.com/psmarter/PMPP-Learning</a></p></blockquote>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h2 id=&quot;qian-yan&quot; tabindex=&quot;-1&quot;</summary>
        
      
    
    
    
    <category term="知识分享" scheme="https://smarter.xin/categories/knowledge-sharing/"/>
    
    
    <category term="CUDA" scheme="https://smarter.xin/tags/CUDA/"/>
    
    <category term="GPU编程" scheme="https://smarter.xin/tags/gpu-programming/"/>
    
    <category term="并行计算" scheme="https://smarter.xin/tags/parallel-computing/"/>
    
    <category term="PMPP" scheme="https://smarter.xin/tags/PMPP/"/>
    
    <category term="归并" scheme="https://smarter.xin/tags/merge/"/>
    
    <category term="Merge" scheme="https://smarter.xin/tags/Merge/"/>
    
    <category term="动态数据识别" scheme="https://smarter.xin/tags/dynamic-data-identification/"/>
    
  </entry>
  
  <entry>
    <title>PMPP-第十一章：前缀和</title>
    <link href="https://smarter.xin/posts/a6fc4cf6/"/>
    <id>https://smarter.xin/posts/a6fc4cf6/</id>
    <published>2026-01-18T07:51:17.000Z</published>
    <updated>2026-01-24T11:47:21.463Z</updated>
    
    <content type="html"><![CDATA[<h2 id="qian-yan" tabindex="-1" id="前言">前言</h2><p>第十章学习了归约——把 N 个数归约成 1 个数。本章学习<strong>前缀和（Prefix Sum）</strong>，也称为 <strong>Scan</strong>——把 N 个数变换成 N 个数，每个位置存储之前所有元素的累计结果。虽然看起来计算量更大，但前缀和是并行计算的&quot;瑞士军刀&quot;，能解决许多看似无法并行的问题：流压缩、基数排序、稀疏矩阵运算等。第十一章重点讲解**工作效率（Work Efficiency）**的概念——如何让并行算法的总工作量不超过串行算法太多。</p><blockquote><p><strong>📦 配套资源</strong>：本系列文章配有完整的 <a href="https://github.com/psmarter/PMPP-Learning">GitHub 仓库</a>，包含每章的练习题解答、CUDA 代码实现和详细注释。所有代码都经过测试，可以直接运行。</p></blockquote><h2 id="qian-zhui-he-ji-chu" tabindex="-1" id="前缀和基础">前缀和基础</h2><h3 id="shi-yao-shi-qian-zhui-he" tabindex="-1" id="什么是前缀和">什么是前缀和</h3><p><strong>前缀和</strong>：对于输入数组 <code>[a₀, a₁, a₂, ..., aₙ₋₁]</code>，输出每个位置之前所有元素的累计值。</p><p>有两种变体：</p><p><strong>包含式扫描（Inclusive Scan）</strong>：包含当前元素</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">输入:  [3, 1, 7, 0, 4, 1, 6, 3]</span><br><span class="line">输出:  [3, 4, 11, 11, 15, 16, 22, 25]</span><br><span class="line">       3  3+1  4+7  11+0  ...</span><br></pre></td></tr></table></figure><p><strong>排除式扫描（Exclusive Scan）</strong>：不包含当前元素</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">输入:  [3, 1, 7, 0, 4, 1, 6, 3]</span><br><span class="line">输出:  [0, 3, 4, 11, 11, 15, 16, 22]</span><br><span class="line">       0  前缀  前缀+1  前缀+7  ...</span><br></pre></td></tr></table></figure><p><strong>关系</strong>：<code>exclusive[i] = inclusive[i-1]</code>，<code>exclusive[0] = 0</code></p><h3 id="shu-xue-ding-yi" tabindex="-1" id="数学定义">数学定义</h3><p>对于二元结合运算 ⊕：</p><p><strong>Inclusive Scan</strong>:</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>=</mo><munderover><mo>⨁</mo><mrow><mi>j</mi><mo>=</mo><mn>0</mn></mrow><mi>i</mi></munderover><msub><mi>x</mi><mi>j</mi></msub><mo>=</mo><msub><mi>x</mi><mn>0</mn></msub><mo>⊕</mo><msub><mi>x</mi><mn>1</mn></msub><mo>⊕</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo>⊕</mo><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">y_i = \bigoplus_{j=0}^{i} x_j = x_0 \oplus x_1 \oplus ... \oplus x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.2254em;vertical-align:-1.4138em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8117em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">⨁</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4138em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⊕</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⊕</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord">...</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⊕</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p><p><strong>Exclusive Scan</strong>:</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>=</mo><munderover><mo>⨁</mo><mrow><mi>j</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></munderover><msub><mi>x</mi><mi>j</mi></msub><mo>=</mo><msub><mi>x</mi><mn>0</mn></msub><mo>⊕</mo><msub><mi>x</mi><mn>1</mn></msub><mo>⊕</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo>⊕</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">y_i = \bigoplus_{j=0}^{i-1} x_j = x_0 \oplus x_1 \oplus ... \oplus x_{i-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.2254em;vertical-align:-1.4138em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8117em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">⨁</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4138em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⊕</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⊕</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord">...</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⊕</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.2083em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span></span></span></span></span></p><p>其中 <code>y₀ = identity</code>（单位元）。</p><h3 id="ying-yong-chang-jing" tabindex="-1" id="应用场景">应用场景</h3><p>前缀和用途极广：</p><table><thead><tr><th>应用</th><th>说明</th></tr></thead><tbody><tr><td><strong>流压缩</strong></td><td>根据条件筛选元素</td></tr><tr><td><strong>基数排序</strong></td><td>计算每个桶的起始位置</td></tr><tr><td><strong>稀疏矩阵</strong></td><td>CSR 格式的行指针数组</td></tr><tr><td><strong>多项式求值</strong></td><td>Horner 法则的并行化</td></tr><tr><td><strong>求解三对角方程</strong></td><td>循环归约</td></tr><tr><td><strong>直方图均衡化</strong></td><td>累积分布函数</td></tr></tbody></table><p><strong>核心思想</strong>：前缀和把&quot;依赖前面结果&quot;的问题转化为可并行的形式。</p><h3 id="chuan-xing-shi-xian" tabindex="-1" id="串行实现">串行实现</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">inclusive_scan_sequential</span><span class="params">(<span class="type">float</span> *x, <span class="type">float</span> *y, <span class="type">int</span> n)</span> &#123;</span><br><span class="line">    y[<span class="number">0</span>] = x[<span class="number">0</span>];</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt; n; i++) &#123;</span><br><span class="line">        y[i] = y[i<span class="number">-1</span>] + x[i];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>时间复杂度 O(n)，存在严格的数据依赖：<code>y[i]</code> 依赖 <code>y[i-1]</code>。</p><p>看似无法并行？其实可以！</p><h2 id="kogge-stone-suan-fa" tabindex="-1" id="Kogge-Stone-算法">Kogge-Stone 算法</h2><h3 id="he-xin-si-xiang" tabindex="-1" id="核心思想">核心思想</h3><p>利用结合律，不需要按顺序计算：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y[i] = x[0] + x[1] + ... + x[i]</span><br><span class="line">     = (x[0] + x[1] + ... + x[i-k]) + (x[i-k+1] + ... + x[i])</span><br></pre></td></tr></table></figure><p><strong>思路</strong>：每一步让每个元素与距离为 2^k 的元素相加。</p><h3 id="suan-fa-guo-cheng" tabindex="-1" id="算法过程">算法过程</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">初始:     [3, 1, 7, 0, 4, 1, 6, 3]</span><br><span class="line"></span><br><span class="line">Step 1 (stride=1):</span><br><span class="line">  y[i] = x[i] + x[i-1]</span><br><span class="line">  结果: [3, 4, 8, 7, 4, 5, 7, 9]</span><br><span class="line"></span><br><span class="line">Step 2 (stride=2):</span><br><span class="line">  y[i] = y[i] + y[i-2]</span><br><span class="line">  结果: [3, 4, 11, 11, 12, 12, 11, 14]</span><br><span class="line"></span><br><span class="line">Step 3 (stride=4):</span><br><span class="line">  y[i] = y[i] + y[i-4]</span><br><span class="line">  结果: [3, 4, 11, 11, 15, 16, 22, 25]</span><br><span class="line"></span><br><span class="line">完成！</span><br></pre></td></tr></table></figure><p>每一步，每个元素都并行更新。log₂N 步后完成。</p><h3 id="cuda-shi-xian" tabindex="-1" id="CUDA-实现">CUDA 实现</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">__global__ void kogge_stone_scan(float *X, float *Y, int n) &#123;</span><br><span class="line">    __shared__ float XY[SECTION_SIZE];</span><br><span class="line">    </span><br><span class="line">    int i = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    </span><br><span class="line">    // 加载到共享内存</span><br><span class="line">    if (i &lt; n) &#123;</span><br><span class="line">        XY[threadIdx.x] = X[i];</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        XY[threadIdx.x] = 0;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    // Kogge-Stone 扫描</span><br><span class="line">    for (unsigned int stride = 1; stride &lt; blockDim.x; stride *= 2) &#123;</span><br><span class="line">        __syncthreads();</span><br><span class="line">        float temp;</span><br><span class="line">        if (threadIdx.x &gt;= stride) &#123;</span><br><span class="line">            temp = XY[threadIdx.x] + XY[threadIdx.x - stride];</span><br><span class="line">        &#125;</span><br><span class="line">        __syncthreads();</span><br><span class="line">        if (threadIdx.x &gt;= stride) &#123;</span><br><span class="line">            XY[threadIdx.x] = temp;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    // 写回</span><br><span class="line">    if (i &lt; n) &#123;</span><br><span class="line">        Y[i] = XY[threadIdx.x];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="wei-shi-yao-xu-yao-liang-ci-tong-bu" tabindex="-1" id="为什么需要两次同步？">为什么需要两次同步？</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">__syncthreads();  // 第一次：确保所有线程读完</span><br><span class="line">temp = XY[...] + XY[...];  // 读取</span><br><span class="line">__syncthreads();  // 第二次：确保所有线程读完再写</span><br><span class="line">XY[...] = temp;  // 写入</span><br></pre></td></tr></table></figure><p>如果不用临时变量：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// 错误！</span><br><span class="line">XY[i] = XY[i] + XY[i-stride];  // 如果邻居还没读完就被覆盖</span><br></pre></td></tr></table></figure><p><strong>关键</strong>：读和写必须分离，用同步保证。</p><h3 id="gong-zuo-liang-fen-xi" tabindex="-1" id="工作量分析">工作量分析</h3><table><thead><tr><th>指标</th><th>串行算法</th><th>Kogge-Stone</th></tr></thead><tbody><tr><td>步数</td><td>N</td><td>log₂N</td></tr><tr><td>每步操作</td><td>1</td><td>~N</td></tr><tr><td>总操作</td><td>N</td><td>N·log₂N</td></tr></tbody></table><p><strong>问题</strong>：Kogge-Stone 做了更多的工作！</p><p>对于 N=1024：</p><ul><li>串行：1024 次操作</li><li>Kogge-Stone：1024 × 10 = 10240 次操作</li></ul><p>这就是**工作效率（Work Efficiency）**问题。</p><h2 id="brent-kung-suan-fa" tabindex="-1" id="Brent-Kung-算法">Brent-Kung 算法</h2><h3 id="gong-zuo-xiao-lu-you-hua" tabindex="-1" id="工作效率优化">工作效率优化</h3><p><strong>思路</strong>：减少冗余计算，分两个阶段：</p><ol><li><strong>归约阶段（Reduce）</strong>：自底向上，构建部分和</li><li><strong>分发阶段（Downsweep）</strong>：自顶向下，分发结果</li></ol><h3 id="suan-fa-guo-cheng-1" tabindex="-1" id="算法过程-2">算法过程</h3><p><strong>阶段 1：归约</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">初始:     [3, 1, 7, 0, 4, 1, 6, 3]</span><br><span class="line"></span><br><span class="line">Step 1 (stride=1): 相邻元素配对求和</span><br><span class="line">          [3, 4, 7, 7, 4, 5, 6, 9]</span><br><span class="line">              ↑     ↑     ↑     ↑</span><br><span class="line">             1+3   0+7   1+4   3+6</span><br><span class="line"></span><br><span class="line">Step 2 (stride=2): 隔一个配对</span><br><span class="line">          [3, 4, 7, 11, 4, 5, 6, 14]</span><br><span class="line">                   ↑           ↑</span><br><span class="line">                  4+7         5+9</span><br><span class="line"></span><br><span class="line">Step 3 (stride=4): 隔三个配对</span><br><span class="line">          [3, 4, 7, 11, 4, 5, 6, 25]</span><br><span class="line">                               ↑</span><br><span class="line">                             11+14</span><br></pre></td></tr></table></figure><p>现在 <code>XY[7] = 25 = 全部元素之和</code>。</p><p><strong>阶段 2：分发（Downsweep）</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">从右到左，把部分和&quot;传播&quot;下去：</span><br><span class="line"></span><br><span class="line">Step 1 (stride=2):</span><br><span class="line">  XY[5] = XY[5] + XY[3] = 5 + 11 = 16</span><br><span class="line">          [3, 4, 7, 11, 4, 16, 6, 25]</span><br><span class="line"></span><br><span class="line">Step 2 (stride=1):</span><br><span class="line">  XY[2] = XY[2] + XY[1] = 7 + 4 = 11</span><br><span class="line">  XY[4] = XY[4] + XY[3] = 4 + 11 = 15</span><br><span class="line">  XY[6] = XY[6] + XY[5] = 6 + 16 = 22</span><br><span class="line">          [3, 4, 11, 11, 15, 16, 22, 25]</span><br><span class="line"></span><br><span class="line">完成！</span><br></pre></td></tr></table></figure><h3 id="cuda-shi-xian-1" tabindex="-1" id="CUDA-实现-2">CUDA 实现</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">__global__ void brent_kung_scan(float *X, float *Y, int n) &#123;</span><br><span class="line">    __shared__ float XY[SECTION_SIZE];</span><br><span class="line">    </span><br><span class="line">    int i = 2 * blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    </span><br><span class="line">    // 加载（每线程两个元素）</span><br><span class="line">    if (i &lt; n) XY[threadIdx.x] = X[i];</span><br><span class="line">    if (i + blockDim.x &lt; n) XY[threadIdx.x + blockDim.x] = X[i + blockDim.x];</span><br><span class="line">    </span><br><span class="line">    // ========== 归约阶段 ==========</span><br><span class="line">    for (unsigned int stride = 1; stride &lt;= blockDim.x; stride *= 2) &#123;</span><br><span class="line">        __syncthreads();</span><br><span class="line">        int index = (threadIdx.x + 1) * 2 * stride - 1;</span><br><span class="line">        if (index &lt; SECTION_SIZE) &#123;</span><br><span class="line">            XY[index] += XY[index - stride];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    // ========== 分发阶段 ==========</span><br><span class="line">    for (unsigned int stride = SECTION_SIZE / 4; stride &gt; 0; stride /= 2) &#123;</span><br><span class="line">        __syncthreads();</span><br><span class="line">        int index = (threadIdx.x + 1) * 2 * stride - 1;</span><br><span class="line">        if (index + stride &lt; SECTION_SIZE) &#123;</span><br><span class="line">            XY[index + stride] += XY[index];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    // 写回</span><br><span class="line">    if (i &lt; n) Y[i] = XY[threadIdx.x];</span><br><span class="line">    if (i + blockDim.x &lt; n) Y[i + blockDim.x] = XY[threadIdx.x + blockDim.x];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="gong-zuo-liang-fen-xi-1" tabindex="-1" id="工作量分析-2">工作量分析</h3><table><thead><tr><th>阶段</th><th>步数</th><th>每步操作</th><th>总操作</th></tr></thead><tbody><tr><td>归约</td><td>log₂N</td><td>N/2^k</td><td>N-1</td></tr><tr><td>分发</td><td>log₂N - 1</td><td>N/2^k</td><td>N-1-log₂N</td></tr><tr><td><strong>总计</strong></td><td></td><td></td><td><strong>2N-2-log₂N</strong></td></tr></tbody></table><p>对于 N=1024：</p><ul><li>Kogge-Stone：10240 次操作</li><li>Brent-Kung：~2046 次操作</li></ul><p><strong>工作效率提升 5 倍！</strong></p><h3 id="wei-shi-yao-mei-xian-cheng-chu-li-liang-ge-yuan-su" tabindex="-1" id="为什么每线程处理两个元素？">为什么每线程处理两个元素？</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int i = 2 * blockIdx.x * blockDim.x + threadIdx.x;</span><br></pre></td></tr></table></figure><p>如果 Section 有 1024 个元素，只需要 512 个线程。每线程加载两个元素，减少了线程开销。</p><h2 id="kogge-stone-vs-brent-kung" tabindex="-1" id="Kogge-Stone-vs-Brent-Kung">Kogge-Stone vs Brent-Kung</h2><h3 id="dui-bi" tabindex="-1" id="对比">对比</h3><table><thead><tr><th>指标</th><th>Kogge-Stone</th><th>Brent-Kung</th></tr></thead><tbody><tr><td>总操作数</td><td>N·log₂N</td><td>2N - 2 - log₂N</td></tr><tr><td>步数</td><td>log₂N</td><td>2·log₂N - 1</td></tr><tr><td>并行度（每步）</td><td>N</td><td>递减/递增</td></tr><tr><td>控制逻辑</td><td>简单</td><td>复杂</td></tr><tr><td>工作效率</td><td>低</td><td>高（接近串行）</td></tr></tbody></table><h3 id="suan-fa-xuan-ze-ce-lue" tabindex="-1" id="算法选择策略">算法选择策略</h3><table><thead><tr><th>场景</th><th>推荐算法</th><th>原因</th></tr></thead><tbody><tr><td>小数组（&lt;1K）</td><td>Kogge-Stone</td><td>简单，步数少</td></tr><tr><td>大数组</td><td>Brent-Kung</td><td>工作量小</td></tr><tr><td>带宽受限</td><td>Kogge-Stone</td><td>更多并行隐藏延迟</td></tr><tr><td>计算受限</td><td>Brent-Kung</td><td>总操作少</td></tr></tbody></table><p>实际中，混合策略最常见：大部分用 Brent-Kung，最后几层用 Kogge-Stone。</p><h2 id="san-jie-duan-fen-ceng-sao-miao" tabindex="-1" id="三阶段分层扫描">三阶段分层扫描</h2><h3 id="wen-ti-chao-chu-dan-block" tabindex="-1" id="问题：超出单-Block">问题：超出单 Block</h3><p>当数据量超过共享内存容量时，需要<strong>多 Block 协作</strong>。</p><h3 id="san-jie-duan-suan-fa" tabindex="-1" id="三阶段算法">三阶段算法</h3><p><strong>阶段 1：Block 内扫描</strong></p><p>每个 Block 独立扫描自己的 Section，保存最后一个元素（Section Sum）。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Block 0: [3,4,11,11]  → sum[0] = 11</span><br><span class="line">Block 1: [4,5,11,14]  → sum[1] = 14</span><br><span class="line">Block 2: [5,6,12,15]  → sum[2] = 15</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p><strong>阶段 2：扫描 Section Sums</strong></p><p>对所有 Block 的 sum 做扫描：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sum: [11, 14, 15, ...]</span><br><span class="line">扫描后: [0, 11, 25, 40, ...]  // Exclusive</span><br></pre></td></tr></table></figure><p>这给出了每个 Block 的&quot;起始偏移&quot;。</p><p><strong>阶段 3：加上偏移</strong></p><p>每个 Block 的所有元素加上对应的偏移：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Block 0: [3,4,11,11] + 0  → [3,4,11,11]</span><br><span class="line">Block 1: [4,5,11,14] + 11 → [15,16,22,25]</span><br><span class="line">Block 2: [5,6,12,15] + 25 → [30,31,37,40]</span><br><span class="line">...</span><br></pre></td></tr></table></figure><h3 id="shi-xian" tabindex="-1" id="实现">实现</h3><p><strong>Kernel 1：Block 内扫描</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">__global__ void scan_phase1(float *X, float *Y, float *S, int n) &#123;</span><br><span class="line">    __shared__ float XY[SECTION_SIZE];</span><br><span class="line">    </span><br><span class="line">    // Block 内扫描（Brent-Kung）</span><br><span class="line">    // ...</span><br><span class="line">    </span><br><span class="line">    // 保存 Section Sum</span><br><span class="line">    if (threadIdx.x == blockDim.x - 1) &#123;</span><br><span class="line">        S[blockIdx.x] = XY[SECTION_SIZE - 1];</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    // 写回</span><br><span class="line">    // ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>Kernel 2：扫描 Section Sums</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// 通常只有一个 Block，因为 Section 数量不多</span><br><span class="line">scan_single_block&lt;&lt;&lt;1, numSections&gt;&gt;&gt;(S, S, numSections);</span><br></pre></td></tr></table></figure><p><strong>Kernel 3：加偏移</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">__global__ void scan_phase3(float *Y, float *S, int n) &#123;</span><br><span class="line">    int i = blockIdx.x * SECTION_SIZE + threadIdx.x;</span><br><span class="line">    if (blockIdx.x &gt; 0 &amp;&amp; i &lt; n) &#123;</span><br><span class="line">        Y[i] += S[blockIdx.x - 1];  // Exclusive 扫描的结果</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="di-gui-chu-li" tabindex="-1" id="递归处理">递归处理</h3><p>如果 Section 数量也很大，对 S 的扫描本身需要分层。形成<strong>递归结构</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Level 0: 扫描原始数据 → Section Sums</span><br><span class="line">Level 1: 扫描 Section Sums → Super Section Sums</span><br><span class="line">Level 2: 扫描 Super Section Sums</span><br><span class="line">...</span><br><span class="line">Level K: 单 Block 完成</span><br><span class="line"></span><br><span class="line">然后逆向加偏移：</span><br><span class="line">Level K → Level K-1 → ... → Level 0</span><br></pre></td></tr></table></figure><p><strong>层数</strong>：log(N/SECTION_SIZE)</p><h2 id="dan-bian-sao-miao-single-pass-scan" tabindex="-1" id="单遍扫描（Single-Pass-Scan）">单遍扫描（Single-Pass Scan）</h2><h3 id="dong-ji" tabindex="-1" id="动机">动机</h3><p>三阶段扫描需要多次 Kernel 启动，有开销。能否一遍完成？</p><h3 id="si-lu" tabindex="-1" id="思路">思路</h3><p>用<strong>原子操作 + 内存标志</strong>实现 Block 间通信：</p><ol><li>每个 Block 完成扫描后，发布自己的 Section Sum</li><li>等待前一个 Block 的结果</li><li>加上前缀并继续</li></ol><h3 id="shi-xian-1" tabindex="-1" id="实现-2">实现</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">__global__ void single_pass_scan(float *X, float *Y, float *flags, </span><br><span class="line">                                  float *sums, int n) &#123;</span><br><span class="line">    __shared__ float XY[SECTION_SIZE];</span><br><span class="line">    __shared__ float prefix;</span><br><span class="line">    </span><br><span class="line">    int bid = blockIdx.x;</span><br><span class="line">    </span><br><span class="line">    // Phase 1: Block 内扫描</span><br><span class="line">    // ... 标准 Brent-Kung ...</span><br><span class="line">    </span><br><span class="line">    // Phase 2: 等待前一个 Block</span><br><span class="line">    if (threadIdx.x == 0) &#123;</span><br><span class="line">        // 发布自己的和</span><br><span class="line">        sums[bid] = XY[SECTION_SIZE - 1];</span><br><span class="line">        __threadfence();  // 确保写入对其他 Block 可见</span><br><span class="line">        atomicExch(&amp;flags[bid], 1);  // 标记完成</span><br><span class="line">        </span><br><span class="line">        // 等待前缀</span><br><span class="line">        if (bid &gt; 0) &#123;</span><br><span class="line">            // 等待 Block bid-1</span><br><span class="line">            while (atomicAdd(&amp;flags[bid - 1], 0) == 0);</span><br><span class="line">            __threadfence();</span><br><span class="line">            </span><br><span class="line">            // 累加所有前缀（可优化为 Kogge-Stone 风格）</span><br><span class="line">            float pre = 0;</span><br><span class="line">            for (int i = 0; i &lt; bid; i++) &#123;</span><br><span class="line">                pre += sums[i];</span><br><span class="line">            &#125;</span><br><span class="line">            prefix = pre;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            prefix = 0;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    // Phase 3: 加偏移并写回</span><br><span class="line">    int i = bid * SECTION_SIZE + threadIdx.x;</span><br><span class="line">    if (i &lt; n) &#123;</span><br><span class="line">        Y[i] = XY[threadIdx.x] + prefix;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="wen-ti" tabindex="-1" id="问题">问题</h3><p><strong>顺序依赖</strong>：Block 必须按顺序完成，可能导致<strong>串行化</strong>。</p><p><strong>改进</strong>：使用 <strong>Decoupled Look-back</strong>（分离回溯）算法，每个 Block 只查看部分前缀，链式传播。</p><h2 id="gong-zuo-xiao-lu-de-ben-zhi" tabindex="-1" id="工作效率的本质">工作效率的本质</h2><h3 id="shi-jian-vs-cao-zuo" tabindex="-1" id="时间-vs-操作">时间 vs 操作</h3><p><strong>并行时间</strong>：所有处理器同时工作需要的时间步数</p><p><strong>总操作数</strong>：所有处理器执行的操作总和</p><p><strong>工作效率 = 串行操作数 / 并行操作数</strong></p><table><thead><tr><th>算法</th><th>并行时间</th><th>总操作</th><th>工作效率</th></tr></thead><tbody><tr><td>串行</td><td>N</td><td>N</td><td>100%</td></tr><tr><td>Kogge-Stone</td><td>log N</td><td>N·log N</td><td>1/log N</td></tr><tr><td>Brent-Kung</td><td>2·log N</td><td>2N</td><td>~50%</td></tr></tbody></table><h3 id="he-shi-zhui-qiu-gong-zuo-xiao-lu" tabindex="-1" id="何时追求工作效率？">何时追求工作效率？</h3><p><strong>处理器充足时</strong>：</p><ul><li>操作数主导时间</li><li>应该追求工作效率</li></ul><p><strong>处理器不足时</strong>：</p><ul><li>步数主导时间</li><li>可以牺牲工作效率换取更少步数</li></ul><p>GPU 通常处理器&quot;足够多&quot;，所以工作效率很重要。</p><h2 id="qian-zhui-he-de-ying-yong" tabindex="-1" id="前缀和的应用">前缀和的应用</h2><h3 id="liu-ya-suo-stream-compaction" tabindex="-1" id="流压缩（Stream-Compaction）">流压缩（Stream Compaction）</h3><p>筛选满足条件的元素：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">输入:    [3, 1, 7, 0, 4, 1, 6, 3]</span><br><span class="line">条件:    x &gt; 2</span><br><span class="line">标志:    [1, 0, 1, 0, 1, 0, 1, 1]</span><br><span class="line">前缀和:  [0, 1, 1, 2, 2, 3, 3, 4]  // Exclusive</span><br><span class="line">输出位置: 0, -, 1, -, 2, -, 3, 4</span><br><span class="line">输出:    [3, 7, 4, 6, 3]</span><br></pre></td></tr></table></figure><p><strong>Exclusive 前缀和给出每个满足条件元素的输出位置！</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">__global__ void compact(int *flags, int *positions, </span><br><span class="line">                        float *in, float *out, int n) &#123;</span><br><span class="line">    int i = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    if (i &lt; n &amp;&amp; flags[i]) &#123;</span><br><span class="line">        out[positions[i]] = in[i];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="ji-shu-pai-xu" tabindex="-1" id="基数排序">基数排序</h3><p>按位排序，每一位用前缀和确定位置：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">第 0 位 = 0 的元素: 前缀和确定位置</span><br><span class="line">第 0 位 = 1 的元素: 紧随其后</span><br></pre></td></tr></table></figure><h3 id="fen-pei-gong-zuo" tabindex="-1" id="分配工作">分配工作</h3><p>根据负载分配任务：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">任务大小:  [5, 3, 8, 2, 4]</span><br><span class="line">前缀和:    [0, 5, 8, 16, 18]</span><br><span class="line"></span><br><span class="line">线程 7 应该处理哪个任务？</span><br><span class="line">→ 二分查找前缀和数组</span><br><span class="line">→ 任务 1（因为 5 ≤ 7 &lt; 8）</span><br></pre></td></tr></table></figure><h2 id="cub-ku" tabindex="-1" id="CUB-库">CUB 库</h2><h3 id="shi-yong-cub-shi-xian-sao-miao" tabindex="-1" id="使用-CUB-实现扫描">使用 CUB 实现扫描</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;cub/cub.cuh&gt;</span><br><span class="line"></span><br><span class="line">void scanWithCub(float *d_in, float *d_out, int n) &#123;</span><br><span class="line">    void *d_temp = nullptr;</span><br><span class="line">    size_t temp_bytes = 0;</span><br><span class="line">    </span><br><span class="line">    // 确定临时存储大小</span><br><span class="line">    cub::DeviceScan::InclusiveSum(d_temp, temp_bytes, d_in, d_out, n);</span><br><span class="line">    </span><br><span class="line">    cudaMalloc(&amp;d_temp, temp_bytes);</span><br><span class="line">    </span><br><span class="line">    // 执行扫描</span><br><span class="line">    cub::DeviceScan::InclusiveSum(d_temp, temp_bytes, d_in, d_out, n);</span><br><span class="line">    </span><br><span class="line">    cudaFree(d_temp);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="cub-ti-gong-de-sao-miao" tabindex="-1" id="CUB-提供的扫描">CUB 提供的扫描</h3><table><thead><tr><th>函数</th><th>功能</th></tr></thead><tbody><tr><td><code>DeviceScan::InclusiveSum</code></td><td>包含式求和</td></tr><tr><td><code>DeviceScan::ExclusiveSum</code></td><td>排除式求和</td></tr><tr><td><code>DeviceScan::InclusiveScan</code></td><td>包含式自定义</td></tr><tr><td><code>DeviceScan::ExclusiveScan</code></td><td>排除式自定义</td></tr></tbody></table><h3 id="zi-ding-yi-cao-zuo" tabindex="-1" id="自定义操作">自定义操作</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">struct MaxOp &#123;</span><br><span class="line">    __device__ float operator()(float a, float b) &#123;</span><br><span class="line">        return (a &gt; b) ? a : b;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">MaxOp max_op;</span><br><span class="line">cub::DeviceScan::InclusiveScan(d_temp, temp_bytes, </span><br><span class="line">                                d_in, d_out, max_op, n);</span><br></pre></td></tr></table></figure><h2 id="xiao-jie" tabindex="-1" id="小结">小结</h2><p>第十一章深入讲解前缀和：</p><p><strong>两种变体</strong>：Inclusive（含当前）vs Exclusive（不含当前）。Exclusive 的应用更广，特别是确定输出位置。</p><p><strong>Kogge-Stone</strong>：简单直接，log N 步，但工作量 N·log N，工作效率低。</p><p><strong>Brent-Kung</strong>：分归约和分发两阶段，工作量 ~2N，接近串行。步数略多但更高效。</p><p><strong>分层扫描</strong>：大数据需要多 Block 协作。三阶段：Block 内扫描 → 扫描 Section Sums → 加偏移。可递归处理超大数据。</p><p><strong>工作效率</strong>：并行算法的总操作数不应远超串行。GPU 处理器多，工作效率比步数更重要。</p><p><strong>核心应用</strong>：流压缩、基数排序、负载分配。前缀和把&quot;输出位置&quot;问题变成并行可解。</p><p>前缀和是并行计算的基础原语，理解它对于实现复杂并行算法至关重要。下一章学习合并（Merge）——另一个重要的并行原语。</p><hr><h2 id="xia-yi-bu" tabindex="-1" id="🚀-下一步">🚀 下一步</h2><hr><h2 id="can-kao-zi-liao" tabindex="-1" id="📚-参考资料">📚 参考资料</h2><ul><li>PMPP 第四版 Chapter 11</li><li><a href="https://smarter.xin/posts/a6fc4cf6/">第十一章：前缀和</a></li></ul><p><strong>学习愉快！</strong> 🎓</p><hr><blockquote><p><strong>本文 GitHub 仓库</strong>: <a href="https://github.com/psmarter/PMPP-Learning">https://github.com/psmarter/PMPP-Learning</a></p></blockquote>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h2 id=&quot;qian-yan&quot; tabindex=&quot;-1&quot; id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;第十章学习了归约——把 N 个数归约成 1 个数。本章学习&lt;strong&gt;前缀和（Prefix Sum）&lt;/strong&gt;，也称为</summary>
        
      
    
    
    
    <category term="知识分享" scheme="https://smarter.xin/categories/knowledge-sharing/"/>
    
    
    <category term="CUDA" scheme="https://smarter.xin/tags/CUDA/"/>
    
    <category term="GPU编程" scheme="https://smarter.xin/tags/gpu-programming/"/>
    
    <category term="并行计算" scheme="https://smarter.xin/tags/parallel-computing/"/>
    
    <category term="PMPP" scheme="https://smarter.xin/tags/PMPP/"/>
    
    <category term="前缀和" scheme="https://smarter.xin/tags/prefix-sum/"/>
    
    <category term="Scan" scheme="https://smarter.xin/tags/Scan/"/>
    
    <category term="工作效率" scheme="https://smarter.xin/tags/work-efficiency/"/>
    
  </entry>
  
  <entry>
    <title>PMPP-第十章：归约和最小化发散</title>
    <link href="https://smarter.xin/posts/43b40d12/"/>
    <id>https://smarter.xin/posts/43b40d12/</id>
    <published>2026-01-18T02:14:18.000Z</published>
    <updated>2026-01-24T11:47:21.464Z</updated>
    
    <content type="html"><![CDATA[<h2 id="qian-yan" tabindex="-1" id="前言">前言</h2><p>第九章学习了直方图计算，使用原子操作处理输出冲突。本章学习<strong>归约（Reduction）</strong>——把一组数据&quot;归约&quot;成一个值，例如求和、求最大值。归约操作看似简单，实际涉及并行算法的核心问题：如何高效地合并部分结果？如何避免分支发散？如何最大化硬件利用率？第十章系统讲解这些优化技术。</p><blockquote><p><strong>📦 配套资源</strong>：本系列文章配有完整的 <a href="https://github.com/psmarter/PMPP-Learning">GitHub 仓库</a>，包含每章的练习题解答、CUDA 代码实现和详细注释。所有代码都经过测试，可以直接运行。</p></blockquote><h2 id="gui-yue-ji-chu" tabindex="-1" id="归约基础">归约基础</h2><h3 id="shi-yao-shi-gui-yue" tabindex="-1" id="什么是归约">什么是归约</h3><p><strong>归约</strong>：用一个<strong>二元结合运算</strong>把 N 个元素合并成 1 个值。</p><p><strong>常见归约操作</strong>：</p><table><thead><tr><th>操作</th><th>运算符</th><th>单位元</th><th>示例</th></tr></thead><tbody><tr><td>求和</td><td>+</td><td>0</td><td>1+2+3+4 = 10</td></tr><tr><td>求积</td><td>×</td><td>1</td><td>1×2×3×4 = 24</td></tr><tr><td>最大值</td><td>max</td><td>-∞</td><td>max(1,5,3,2) = 5</td></tr><tr><td>最小值</td><td>min</td><td>+∞</td><td>min(1,5,3,2) = 1</td></tr><tr><td>逻辑与</td><td>&amp;&amp;</td><td>true</td><td>true &amp;&amp; false = false</td></tr><tr><td>逻辑或</td><td>||</td><td>false</td><td>true || false = true</td></tr><tr><td>位与</td><td>&amp;</td><td>~0</td><td>0b1100 &amp; 0b1010 = 0b1000</td></tr><tr><td>位或</td><td>|</td><td>0</td><td>0b1100 | 0b1010 = 0b1110</td></tr></tbody></table><p><strong>结合律</strong>是关键：<code>(a ⊕ b) ⊕ c = a ⊕ (b ⊕ c)</code></p><p>有了结合律，就能任意分组并行计算。</p><h3 id="chuan-xing-gui-yue" tabindex="-1" id="串行归约">串行归约</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">float</span> <span class="title function_">sum_sequential</span><span class="params">(<span class="type">float</span> *data, <span class="type">int</span> n)</span> &#123;</span><br><span class="line">    <span class="type">float</span> sum = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">        sum += data[i];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> sum;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>时间复杂度 O(n)，无法利用并行性。</p><h3 id="bing-xing-gui-yue-de-si-lu" tabindex="-1" id="并行归约的思路">并行归约的思路</h3><p><strong>树形归约</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Level 0: [a0, a1, a2, a3, a4, a5, a6, a7]</span><br><span class="line">Level 1: [a0+a1, a2+a3, a4+a5, a6+a7]</span><br><span class="line">Level 2: [a0+a1+a2+a3, a4+a5+a6+a7]</span><br><span class="line">Level 3: [a0+a1+a2+a3+a4+a5+a6+a7]</span><br></pre></td></tr></table></figure><p>每层把元素数减半，log₂N 层后得到结果。</p><p><strong>时间复杂度</strong>：O(log N) 步，每步 O(N/2^k) 次操作</p><p><strong>工作量</strong>：总操作数 = N/2 + N/4 + … + 1 = N - 1（与串行相同）</p><p><strong>并行度</strong>：第 k 层需要 N/2^k 个并行操作</p><h2 id="po-su-bing-xing-gui-yue" tabindex="-1" id="朴素并行归约">朴素并行归约</h2><h3 id="xiang-lin-pei-dui" tabindex="-1" id="相邻配对">相邻配对</h3><p>最直观的并行化：相邻元素配对求和</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">__global__ void reduce_naive(float *g_data, float *g_result, int n) &#123;</span><br><span class="line">    extern __shared__ float sdata[];</span><br><span class="line">    </span><br><span class="line">    int tid = threadIdx.x;</span><br><span class="line">    int i = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    </span><br><span class="line">    // 加载到共享内存</span><br><span class="line">    sdata[tid] = (i &lt; n) ? g_data[i] : 0;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    // 树形归约</span><br><span class="line">    for (int stride = 1; stride &lt; blockDim.x; stride *= 2) &#123;</span><br><span class="line">        if (tid % (2 * stride) == 0) &#123;</span><br><span class="line">            sdata[tid] += sdata[tid + stride];</span><br><span class="line">        &#125;</span><br><span class="line">        __syncthreads();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    // 写回结果</span><br><span class="line">    if (tid == 0) &#123;</span><br><span class="line">        g_result[blockIdx.x] = sdata[0];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="wen-ti-fen-zhi-fa-san" tabindex="-1" id="问题：分支发散">问题：分支发散</h3><p>看这个条件：<code>if (tid % (2 * stride) == 0)</code></p><p><strong>Level 0</strong> (stride=1)：线程 0,2,4,6… 活跃，1,3,5,7… 空闲<br><strong>Level 1</strong> (stride=2)：线程 0,4,8… 活跃<br><strong>Level 2</strong> (stride=4)：线程 0,8… 活跃</p><p>Warp 内有的线程活跃、有的空闲 = <strong>分支发散</strong>！</p><p>Warp 必须串行执行两个分支，效率减半。</p><h3 id="wen-ti-bank-chong-tu" tabindex="-1" id="问题：Bank-冲突">问题：Bank 冲突</h3><p><code>sdata[tid]</code> 和 <code>sdata[tid + stride]</code> 的访问模式：</p><ul><li>stride=1：线程 0 访问 [0,1]，线程 2 访问 [2,3]…（无冲突）</li><li>stride=16：线程 0 访问 [0,16]，线程 32 访问 [32,48]…</li></ul><p>stride 是 2 的幂时，可能产生 Bank 冲突。</p><h2 id="you-hua-1-jiao-cuo-pei-dui" tabindex="-1" id="优化-1：交错配对">优化 1：交错配对</h2><h3 id="gai-jin-si-lu" tabindex="-1" id="改进思路">改进思路</h3><p>把&quot;空闲线程在右边&quot;改成&quot;空闲线程在后面&quot;：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">朴素：线程 0,2,4,6 活跃，1,3,5,7 空闲</span><br><span class="line">交错：线程 0,1,2,3 活跃，4,5,6,7 空闲</span><br></pre></td></tr></table></figure><p>这样，活跃线程是连续的，前几个 Warp 满载，最后的 Warp 才逐渐空闲。</p><h3 id="shi-xian" tabindex="-1" id="实现">实现</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">__global__ void reduce_interleaved(float *g_data, float *g_result, int n) &#123;</span><br><span class="line">    extern __shared__ float sdata[];</span><br><span class="line">    </span><br><span class="line">    int tid = threadIdx.x;</span><br><span class="line">    int i = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    </span><br><span class="line">    sdata[tid] = (i &lt; n) ? g_data[i] : 0;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    // 交错归约</span><br><span class="line">    for (int stride = blockDim.x / 2; stride &gt; 0; stride &gt;&gt;= 1) &#123;</span><br><span class="line">        if (tid &lt; stride) &#123;</span><br><span class="line">            sdata[tid] += sdata[tid + stride];</span><br><span class="line">        &#125;</span><br><span class="line">        __syncthreads();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    if (tid == 0) &#123;</span><br><span class="line">        g_result[blockIdx.x] = sdata[0];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="fen-xi" tabindex="-1" id="分析">分析</h3><p><strong>Level 0</strong> (stride=128)：线程 0-127 活跃<br><strong>Level 1</strong> (stride=64)：线程 0-63 活跃<br><strong>Level 2</strong> (stride=32)：线程 0-31 活跃（恰好一个 Warp）</p><p>前几层有多个完整 Warp 同时工作，分支发散只在最后几层出现。</p><p><strong>性能提升</strong>：约 2× 相比朴素版本。</p><h2 id="you-hua-2-shou-ci-jia-zai-shi-gui-yue" tabindex="-1" id="优化-2：首次加载时归约">优化 2：首次加载时归约</h2><h3 id="guan-cha" tabindex="-1" id="观察">观察</h3><p>每个线程只加载一个元素，但 Block 数可能远多于 SM 数。如果让每个线程加载多个元素并在加载时求和，可以减少 Block 数，提高效率。</p><h3 id="shi-xian-1" tabindex="-1" id="实现-2">实现</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">__global__ void reduce_first_add(float *g_data, float *g_result, int n) &#123;</span><br><span class="line">    extern __shared__ float sdata[];</span><br><span class="line">    </span><br><span class="line">    int tid = threadIdx.x;</span><br><span class="line">    int i = blockIdx.x * (blockDim.x * 2) + threadIdx.x;</span><br><span class="line">    </span><br><span class="line">    // 首次加载时就求和两个元素</span><br><span class="line">    float sum = 0;</span><br><span class="line">    if (i &lt; n) sum += g_data[i];</span><br><span class="line">    if (i + blockDim.x &lt; n) sum += g_data[i + blockDim.x];</span><br><span class="line">    sdata[tid] = sum;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    // 后续归约</span><br><span class="line">    for (int stride = blockDim.x / 2; stride &gt; 0; stride &gt;&gt;= 1) &#123;</span><br><span class="line">        if (tid &lt; stride) &#123;</span><br><span class="line">            sdata[tid] += sdata[tid + stride];</span><br><span class="line">        &#125;</span><br><span class="line">        __syncthreads();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    if (tid == 0) &#123;</span><br><span class="line">        g_result[blockIdx.x] = sdata[0];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="kuo-zhan-grid-stride-jia-zai" tabindex="-1" id="扩展：Grid-Stride-加载">扩展：Grid-Stride 加载</h3><p>让每个线程加载多个元素：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">__global__ void reduce_grid_stride(float *g_data, float *g_result, int n) &#123;</span><br><span class="line">    extern __shared__ float sdata[];</span><br><span class="line">    </span><br><span class="line">    int tid = threadIdx.x;</span><br><span class="line">    int i = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    int gridSize = blockDim.x * gridDim.x;</span><br><span class="line">    </span><br><span class="line">    // Grid-stride 累加</span><br><span class="line">    float sum = 0;</span><br><span class="line">    while (i &lt; n) &#123;</span><br><span class="line">        sum += g_data[i];</span><br><span class="line">        i += gridSize;</span><br><span class="line">    &#125;</span><br><span class="line">    sdata[tid] = sum;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    // 树形归约</span><br><span class="line">    for (int stride = blockDim.x / 2; stride &gt; 0; stride &gt;&gt;= 1) &#123;</span><br><span class="line">        if (tid &lt; stride) &#123;</span><br><span class="line">            sdata[tid] += sdata[tid + stride];</span><br><span class="line">        &#125;</span><br><span class="line">        __syncthreads();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    if (tid == 0) &#123;</span><br><span class="line">        g_result[blockIdx.x] = sdata[0];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>优势</strong>：</p><ol><li>Block 数量可以固定（如 256），不随数据量变化</li><li>每线程做更多有效工作，分摊同步开销</li><li>更好的指令级并行</li></ol><h2 id="you-hua-3-zhan-kai-zui-hou-warp" tabindex="-1" id="优化-3：展开最后-Warp">优化 3：展开最后 Warp</h2><h3 id="guan-cha-1" tabindex="-1" id="观察-2">观察</h3><p>当 stride &lt; 32 时，只有一个 Warp 在工作。Warp 内线程自动同步（SIMT），不需要 <code>__syncthreads()</code>！</p><h3 id="shi-xian-2" tabindex="-1" id="实现-3">实现</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">__device__ void warpReduce(volatile float *sdata, int tid) &#123;</span><br><span class="line">    sdata[tid] += sdata[tid + 32];</span><br><span class="line">    sdata[tid] += sdata[tid + 16];</span><br><span class="line">    sdata[tid] += sdata[tid + 8];</span><br><span class="line">    sdata[tid] += sdata[tid + 4];</span><br><span class="line">    sdata[tid] += sdata[tid + 2];</span><br><span class="line">    sdata[tid] += sdata[tid + 1];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">__global__ void reduce_warp_unroll(float *g_data, float *g_result, int n) &#123;</span><br><span class="line">    extern __shared__ float sdata[];</span><br><span class="line">    </span><br><span class="line">    int tid = threadIdx.x;</span><br><span class="line">    int i = blockIdx.x * blockDim.x * 2 + threadIdx.x;</span><br><span class="line">    </span><br><span class="line">    sdata[tid] = 0;</span><br><span class="line">    if (i &lt; n) sdata[tid] += g_data[i];</span><br><span class="line">    if (i + blockDim.x &lt; n) sdata[tid] += g_data[i + blockDim.x];</span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    // 常规归约（stride &gt;= 64）</span><br><span class="line">    for (int stride = blockDim.x / 2; stride &gt; 32; stride &gt;&gt;= 1) &#123;</span><br><span class="line">        if (tid &lt; stride) &#123;</span><br><span class="line">            sdata[tid] += sdata[tid + stride];</span><br><span class="line">        &#125;</span><br><span class="line">        __syncthreads();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    // Warp 内展开（stride &lt; 32）</span><br><span class="line">    if (tid &lt; 32) &#123;</span><br><span class="line">        warpReduce(sdata, tid);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    if (tid == 0) &#123;</span><br><span class="line">        g_result[blockIdx.x] = sdata[0];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="guan-jian-dian" tabindex="-1" id="关键点">关键点</h3><p><strong>volatile</strong>：告诉编译器不要优化掉对 sdata 的读写，确保每次都访问共享内存。</p><p><strong>隐式同步</strong>：Warp 内的 32 个线程执行相同指令，自动保持同步。</p><p><strong>性能提升</strong>：减少 5 次 <code>__syncthreads()</code> 调用。</p><h2 id="you-hua-4-wan-quan-zhan-kai" tabindex="-1" id="优化-4：完全展开">优化 4：完全展开</h2><h3 id="dang-block-da-xiao-yi-zhi-shi" tabindex="-1" id="当-Block-大小已知时">当 Block 大小已知时</h3><p>如果 Block 大小是编译时常量（如 256），可以完全展开循环：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">template &lt;unsigned int blockSize&gt;</span><br><span class="line">__global__ void reduce_complete_unroll(float *g_data, float *g_result, int n) &#123;</span><br><span class="line">    extern __shared__ float sdata[];</span><br><span class="line">    </span><br><span class="line">    int tid = threadIdx.x;</span><br><span class="line">    int i = blockIdx.x * blockSize * 2 + threadIdx.x;</span><br><span class="line">    </span><br><span class="line">    sdata[tid] = 0;</span><br><span class="line">    if (i &lt; n) sdata[tid] += g_data[i];</span><br><span class="line">    if (i + blockSize &lt; n) sdata[tid] += g_data[i + blockSize];</span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    // 编译时展开</span><br><span class="line">    if (blockSize &gt;= 512) &#123;</span><br><span class="line">        if (tid &lt; 256) sdata[tid] += sdata[tid + 256];</span><br><span class="line">        __syncthreads();</span><br><span class="line">    &#125;</span><br><span class="line">    if (blockSize &gt;= 256) &#123;</span><br><span class="line">        if (tid &lt; 128) sdata[tid] += sdata[tid + 128];</span><br><span class="line">        __syncthreads();</span><br><span class="line">    &#125;</span><br><span class="line">    if (blockSize &gt;= 128) &#123;</span><br><span class="line">        if (tid &lt; 64) sdata[tid] += sdata[tid + 64];</span><br><span class="line">        __syncthreads();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    // Warp 内展开</span><br><span class="line">    if (tid &lt; 32) &#123;</span><br><span class="line">        volatile float *smem = sdata;</span><br><span class="line">        if (blockSize &gt;= 64) smem[tid] += smem[tid + 32];</span><br><span class="line">        if (blockSize &gt;= 32) smem[tid] += smem[tid + 16];</span><br><span class="line">        if (blockSize &gt;= 16) smem[tid] += smem[tid + 8];</span><br><span class="line">        if (blockSize &gt;= 8)  smem[tid] += smem[tid + 4];</span><br><span class="line">        if (blockSize &gt;= 4)  smem[tid] += smem[tid + 2];</span><br><span class="line">        if (blockSize &gt;= 2)  smem[tid] += smem[tid + 1];</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    if (tid == 0) &#123;</span><br><span class="line">        g_result[blockIdx.x] = sdata[0];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="qi-dong" tabindex="-1" id="启动">启动</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">// 根据 Block 大小选择模板实例</span><br><span class="line">switch (blockSize) &#123;</span><br><span class="line">    case 512: reduce_complete_unroll&lt;512&gt;&lt;&lt;&lt;grid, 512, 512*sizeof(float)&gt;&gt;&gt;(...); break;</span><br><span class="line">    case 256: reduce_complete_unroll&lt;256&gt;&lt;&lt;&lt;grid, 256, 256*sizeof(float)&gt;&gt;&gt;(...); break;</span><br><span class="line">    case 128: reduce_complete_unroll&lt;128&gt;&lt;&lt;&lt;grid, 128, 128*sizeof(float)&gt;&gt;&gt;(...); break;</span><br><span class="line">    // ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>优势</strong>：编译器可以完全展开循环，消除循环开销和分支。</p><h2 id="you-hua-5-warp-shuffle" tabindex="-1" id="优化-5：Warp-Shuffle">优化 5：Warp Shuffle</h2><h3 id="xian-dai-fang-fa" tabindex="-1" id="现代方法">现代方法</h3><p>从 Kepler 架构开始，CUDA 提供 <strong>Warp Shuffle</strong> 指令，线程可以直接交换寄存器值，无需共享内存：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">__device__ float warpReduceSum(float val) &#123;</span><br><span class="line">    for (int offset = 16; offset &gt; 0; offset /= 2) &#123;</span><br><span class="line">        val += __shfl_down_sync(0xffffffff, val, offset);</span><br><span class="line">    &#125;</span><br><span class="line">    return val;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="wan-zheng-shi-xian" tabindex="-1" id="完整实现">完整实现</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">__global__ void reduce_shuffle(float *g_data, float *g_result, int n) &#123;</span><br><span class="line">    int tid = threadIdx.x;</span><br><span class="line">    int i = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    int gridSize = blockDim.x * gridDim.x;</span><br><span class="line">    </span><br><span class="line">    // Grid-stride 累加</span><br><span class="line">    float sum = 0;</span><br><span class="line">    while (i &lt; n) &#123;</span><br><span class="line">        sum += g_data[i];</span><br><span class="line">        i += gridSize;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    // Warp 内归约（shuffle）</span><br><span class="line">    sum = warpReduceSum(sum);</span><br><span class="line">    </span><br><span class="line">    // Warp 间归约</span><br><span class="line">    __shared__ float warpSums[32];  // 最多 32 个 Warp</span><br><span class="line">    int lane = tid % 32;</span><br><span class="line">    int wid = tid / 32;</span><br><span class="line">    </span><br><span class="line">    if (lane == 0) &#123;</span><br><span class="line">        warpSums[wid] = sum;</span><br><span class="line">    &#125;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    // 第一个 Warp 做最终归约</span><br><span class="line">    if (wid == 0) &#123;</span><br><span class="line">        sum = (tid &lt; blockDim.x / 32) ? warpSums[lane] : 0;</span><br><span class="line">        sum = warpReduceSum(sum);</span><br><span class="line">        </span><br><span class="line">        if (tid == 0) &#123;</span><br><span class="line">            g_result[blockIdx.x] = sum;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="shuffle-han-shu" tabindex="-1" id="Shuffle-函数">Shuffle 函数</h3><table><thead><tr><th>函数</th><th>功能</th></tr></thead><tbody><tr><td><code>__shfl_sync</code></td><td>从指定 lane 获取值</td></tr><tr><td><code>__shfl_up_sync</code></td><td>从低 lane 获取值</td></tr><tr><td><code>__shfl_down_sync</code></td><td>从高 lane 获取值</td></tr><tr><td><code>__shfl_xor_sync</code></td><td>与 XOR 偏移的 lane 交换</td></tr></tbody></table><p><strong>优势</strong>：</p><ol><li>不需要共享内存</li><li>延迟比共享内存低</li><li>无 Bank 冲突</li></ol><h2 id="duo-ji-gui-yue" tabindex="-1" id="多级归约">多级归约</h2><h3 id="dan-block-bu-gou" tabindex="-1" id="单-Block-不够">单 Block 不够</h3><p>如果数据量超过单 Block 能处理的范围，需要多级归约：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Level 1: 每个 Block 归约自己的部分 → gridDim 个部分和</span><br><span class="line">Level 2: 再启动一个 Kernel 归约这些部分和</span><br><span class="line">...</span><br><span class="line">重复直到只剩一个值</span><br></pre></td></tr></table></figure><h3 id="shi-xian-3" tabindex="-1" id="实现-4">实现</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">void reduce_multi_level(float *d_data, float *d_result, int n) &#123;</span><br><span class="line">    int blockSize = 256;</span><br><span class="line">    int numBlocks = (n + blockSize * 2 - 1) / (blockSize * 2);</span><br><span class="line">    </span><br><span class="line">    float *d_partial;</span><br><span class="line">    cudaMalloc(&amp;d_partial, numBlocks * sizeof(float));</span><br><span class="line">    </span><br><span class="line">    // Level 1</span><br><span class="line">    reduce_kernel&lt;&lt;&lt;numBlocks, blockSize, blockSize * sizeof(float)&gt;&gt;&gt;</span><br><span class="line">        (d_data, d_partial, n);</span><br><span class="line">    </span><br><span class="line">    // 后续 Level</span><br><span class="line">    while (numBlocks &gt; 1) &#123;</span><br><span class="line">        int n_next = numBlocks;</span><br><span class="line">        numBlocks = (n_next + blockSize * 2 - 1) / (blockSize * 2);</span><br><span class="line">        </span><br><span class="line">        reduce_kernel&lt;&lt;&lt;numBlocks, blockSize, blockSize * sizeof(float)&gt;&gt;&gt;</span><br><span class="line">            (d_partial, d_partial, n_next);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    // 拷贝最终结果</span><br><span class="line">    cudaMemcpy(d_result, d_partial, sizeof(float), cudaMemcpyDeviceToHost);</span><br><span class="line">    cudaFree(d_partial);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="you-hua-yuan-zi-lei-jia" tabindex="-1" id="优化：原子累加">优化：原子累加</h3><p>如果只需要最终和，可以用原子操作避免多级：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">__global__ void reduce_atomic(float *g_data, float *g_result, int n) &#123;</span><br><span class="line">    // ... 常规 Block 内归约 ...</span><br><span class="line">    </span><br><span class="line">    if (tid == 0) &#123;</span><br><span class="line">        atomicAdd(g_result, sdata[0]);  // 直接累加到结果</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>注意</strong>：需要先将 <code>g_result</code> 初始化为 0。</p><h2 id="fen-zhi-fa-san-shen-ru-fen-xi" tabindex="-1" id="分支发散深入分析">分支发散深入分析</h2><h3 id="fa-san-de-dai-jie" tabindex="-1" id="发散的代价">发散的代价</h3><p>当 Warp 内线程走不同分支时：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">if (condition) &#123;</span><br><span class="line">    doA();  // 部分线程</span><br><span class="line">&#125; else &#123;</span><br><span class="line">    doB();  // 其他线程</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>硬件执行：</p><ol><li>所有线程执行 doA()，不满足条件的线程结果被丢弃</li><li>所有线程执行 doB()，满足条件的线程结果被丢弃</li><li>总时间 = doA() + doB()</li></ol><p><strong>发散程度</strong>影响性能：</p><table><thead><tr><th>发散比例</th><th>性能影响</th></tr></thead><tbody><tr><td>0/32</td><td>无影响</td></tr><tr><td>1/32</td><td>几乎无影响</td></tr><tr><td>16/32</td><td>约 50% 性能</td></tr><tr><td>按 Warp 边界</td><td>无发散</td></tr></tbody></table><h3 id="zui-xiao-hua-fa-san-de-ce-lue" tabindex="-1" id="最小化发散的策略">最小化发散的策略</h3><p><strong>1. 让条件按 Warp 对齐</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">// 差：混合发散</span><br><span class="line">if (tid % 2 == 0) &#123; ... &#125;</span><br><span class="line"></span><br><span class="line">// 好：Warp 内无发散</span><br><span class="line">if (tid &lt; 128) &#123; ... &#125;  // 前 4 个 Warp vs 后 4 个 Warp</span><br></pre></td></tr></table></figure><p><strong>2. 用算术替代分支</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">// 有分支</span><br><span class="line">if (a &gt; b) result = a;</span><br><span class="line">else result = b;</span><br><span class="line"></span><br><span class="line">// 无分支</span><br><span class="line">result = (a &gt; b) * a + (a &lt;= b) * b;</span><br><span class="line"></span><br><span class="line">// 更好：用内置函数</span><br><span class="line">result = max(a, b);</span><br></pre></td></tr></table></figure><p><strong>3. 预先分离数据</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">// 差：运行时分支</span><br><span class="line">if (data[i] &gt; threshold) processA();</span><br><span class="line">else processB();</span><br><span class="line"></span><br><span class="line">// 好：预处理分离</span><br><span class="line">// Kernel 1: 分离数据</span><br><span class="line">// Kernel 2: 批量处理 A 类</span><br><span class="line">// Kernel 3: 批量处理 B 类</span><br></pre></td></tr></table></figure><h3 id="gui-yue-zhong-de-fa-san-kong-zhi" tabindex="-1" id="归约中的发散控制">归约中的发散控制</h3><p>朴素 vs 交错的对比：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">朴素 (stride=1):</span><br><span class="line">  Warp 0: threads 0,2,4,...,30 活跃（16个）</span><br><span class="line">  ↪ 每个 Warp 都有 50% 发散</span><br><span class="line"></span><br><span class="line">交错 (stride=128):</span><br><span class="line">  Warp 0-3: 全部活跃</span><br><span class="line">  Warp 4-7: 全部空闲</span><br><span class="line">  ↪ 没有 Warp 内发散！</span><br></pre></td></tr></table></figure><h2 id="xing-neng-dui-bi" tabindex="-1" id="性能对比">性能对比</h2><p>以 2²⁴（约1600万）个单精度浮点数求和为例：</p><table><thead><tr><th>优化版本</th><th>带宽利用率</th><th>相对性能</th></tr></thead><tbody><tr><td>朴素相邻配对</td><td>4%</td><td>1×</td></tr><tr><td>交错配对</td><td>8%</td><td>2×</td></tr><tr><td>首次加载归约</td><td>16%</td><td>4×</td></tr><tr><td>展开最后线程束</td><td>25%</td><td>6×</td></tr><tr><td>完全展开</td><td>40%</td><td>10×</td></tr><tr><td>+ 线程束 Shuffle</td><td>60%</td><td>15×</td></tr></tbody></table><p><strong>测试环境</strong>：</p><ul><li>GPU：NVIDIA RTX 3090（10496 CUDA 核心）</li><li>数据量：16,777,216 个 float（64MB）</li><li>块大小：256线程</li></ul><p>带宽利用率达到60%已经很高——剩余开销来自核函数启动、同步等不可避免的开销。</p><h2 id="qi-ta-gui-yue-cao-zuo" tabindex="-1" id="其他归约操作">其他归约操作</h2><h3 id="zui-da-zhi-zui-xiao-zhi" tabindex="-1" id="最大值-最小值">最大值/最小值</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">__device__ float warpReduceMax(float val) &#123;</span><br><span class="line">    for (int offset = 16; offset &gt; 0; offset /= 2) &#123;</span><br><span class="line">        val = max(val, __shfl_down_sync(0xffffffff, val, offset));</span><br><span class="line">    &#125;</span><br><span class="line">    return val;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="dai-suo-yin-de-zui-da-zhi" tabindex="-1" id="带索引的最大值">带索引的最大值</h3><p>返回最大值及其位置：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">__device__ void warpReduceArgMax(float &amp;val, int &amp;idx) &#123;</span><br><span class="line">    for (int offset = 16; offset &gt; 0; offset /= 2) &#123;</span><br><span class="line">        float other_val = __shfl_down_sync(0xffffffff, val, offset);</span><br><span class="line">        int other_idx = __shfl_down_sync(0xffffffff, idx, offset);</span><br><span class="line">        if (other_val &gt; val) &#123;</span><br><span class="line">            val = other_val;</span><br><span class="line">            idx = other_idx;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="dian-ji" tabindex="-1" id="点积">点积</h3><p>两个向量的点积 = 逐元素乘法 + 求和归约：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">__global__ void dotProduct(float *a, float *b, float *result, int n) &#123;</span><br><span class="line">    extern __shared__ float sdata[];</span><br><span class="line">    </span><br><span class="line">    int tid = threadIdx.x;</span><br><span class="line">    int i = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    </span><br><span class="line">    float sum = 0;</span><br><span class="line">    while (i &lt; n) &#123;</span><br><span class="line">        sum += a[i] * b[i];</span><br><span class="line">        i += blockDim.x * gridDim.x;</span><br><span class="line">    &#125;</span><br><span class="line">    sdata[tid] = sum;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    // 归约</span><br><span class="line">    // ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="cub-ku" tabindex="-1" id="CUB-库">CUB 库</h2><h3 id="wei-shi-yao-yong-ku" tabindex="-1" id="为什么用库">为什么用库</h3><p>手写归约容易出错，且难以覆盖所有优化。NVIDIA 的 CUB 库提供高度优化的实现：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;cub/cub.cuh&gt;</span><br><span class="line"></span><br><span class="line">void reduceWithCub(float *d_data, float *d_result, int n) &#123;</span><br><span class="line">    // 确定临时存储大小</span><br><span class="line">    void *d_temp = nullptr;</span><br><span class="line">    size_t temp_bytes = 0;</span><br><span class="line">    cub::DeviceReduce::Sum(d_temp, temp_bytes, d_data, d_result, n);</span><br><span class="line">    </span><br><span class="line">    // 分配临时存储</span><br><span class="line">    cudaMalloc(&amp;d_temp, temp_bytes);</span><br><span class="line">    </span><br><span class="line">    // 执行归约</span><br><span class="line">    cub::DeviceReduce::Sum(d_temp, temp_bytes, d_data, d_result, n);</span><br><span class="line">    </span><br><span class="line">    cudaFree(d_temp);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="cub-ti-gong-de-gui-yue" tabindex="-1" id="CUB-提供的归约">CUB 提供的归约</h3><table><thead><tr><th>函数</th><th>功能</th></tr></thead><tbody><tr><td><code>DeviceReduce::Sum</code></td><td>求和</td></tr><tr><td><code>DeviceReduce::Max</code></td><td>最大值</td></tr><tr><td><code>DeviceReduce::Min</code></td><td>最小值</td></tr><tr><td><code>DeviceReduce::ArgMax</code></td><td>最大值及索引</td></tr><tr><td><code>DeviceReduce::ArgMin</code></td><td>最小值及索引</td></tr><tr><td><code>DeviceReduce::Reduce</code></td><td>自定义操作符</td></tr></tbody></table><h3 id="block-ji-gui-yue" tabindex="-1" id="Block-级归约">Block 级归约</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;cub/cub.cuh&gt;</span><br><span class="line"></span><br><span class="line">__global__ void myKernel(float *data, float *result) &#123;</span><br><span class="line">    typedef cub::BlockReduce&lt;float, 256&gt; BlockReduce;</span><br><span class="line">    __shared__ typename BlockReduce::TempStorage temp_storage;</span><br><span class="line">    </span><br><span class="line">    float val = data[threadIdx.x];</span><br><span class="line">    float sum = BlockReduce(temp_storage).Sum(val);</span><br><span class="line">    </span><br><span class="line">    if (threadIdx.x == 0) &#123;</span><br><span class="line">        result[blockIdx.x] = sum;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="xiao-jie" tabindex="-1" id="小结">小结</h2><p>第十章系统讲解了并行归约：</p><p><strong>树形归约</strong>：log N 步完成，但朴素实现有严重的分支发散和 Bank 冲突。</p><p><strong>交错配对</strong>：让活跃线程连续，消除 Warp 内发散。这是最关键的优化。</p><p><strong>首次加载归约</strong>：Grid-stride loop 让每线程处理多个元素，减少 Block 数和同步开销。</p><p><strong>展开优化</strong>：利用 Warp 内隐式同步，消除最后几层的 <code>__syncthreads()</code>。完全展开进一步消除循环开销。</p><p><strong>Warp Shuffle</strong>：现代 GPU 的利器，直接交换寄存器，无需共享内存。</p><p><strong>分支发散</strong>：按 Warp 边界划分条件，用算术替代分支，是通用的发散最小化技术。</p><p><strong>CUB 库</strong>：生产环境优先使用库，它集成了所有优化且经过充分测试。</p><p>归约是并行计算的基础模式，卷积的边界处理、直方图的最终合并、神经网络的 Softmax 都用到。下一章学习前缀和——另一个基础且强大的并行原语。</p><hr><h2 id="xia-yi-bu" tabindex="-1" id="🚀-下一步">🚀 下一步</h2><hr><h2 id="can-kao-zi-liao" tabindex="-1" id="📚-参考资料">📚 参考资料</h2><ul><li>PMPP 第四版 Chapter 10</li><li><a href="https://smarter.xin/posts/43b40d12/">第十章：归约和最小化发散</a></li></ul><p><strong>学习愉快！</strong> 🎓</p><hr><blockquote><p><strong>本文 GitHub 仓库</strong>: <a href="https://github.com/psmarter/PMPP-Learning">https://github.com/psmarter/PMPP-Learning</a></p></blockquote>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h2 id=&quot;qian-yan&quot; tabindex=&quot;-1&quot;</summary>
        
      
    
    
    
    <category term="知识分享" scheme="https://smarter.xin/categories/knowledge-sharing/"/>
    
    
    <category term="CUDA" scheme="https://smarter.xin/tags/CUDA/"/>
    
    <category term="GPU编程" scheme="https://smarter.xin/tags/gpu-programming/"/>
    
    <category term="并行计算" scheme="https://smarter.xin/tags/parallel-computing/"/>
    
    <category term="PMPP" scheme="https://smarter.xin/tags/PMPP/"/>
    
    <category term="归约" scheme="https://smarter.xin/tags/reduction/"/>
    
    <category term="分支发散" scheme="https://smarter.xin/tags/divergence/"/>
    
    <category term="并行算法" scheme="https://smarter.xin/tags/parallel-algorithm/"/>
    
  </entry>
  
  <entry>
    <title>PMPP-第九章：并行直方图</title>
    <link href="https://smarter.xin/posts/d29973f1/"/>
    <id>https://smarter.xin/posts/d29973f1/</id>
    <published>2026-01-17T12:54:04.000Z</published>
    <updated>2026-01-24T11:47:21.462Z</updated>
    
    <content type="html"><![CDATA[<h2 id="qian-yan" tabindex="-1" id="前言">前言</h2><p>前几章学的卷积、模板都是&quot;规则&quot;的并行模式——输出位置固定，每个线程知道自己写哪里。但很多实际问题不是这样的，比如<strong>直方图</strong>：每个输入元素决定更新哪个输出桶，多个线程可能同时更新同一个桶。这就是<strong>输出冲突</strong>问题。第九章讲解如何用<strong>原子操作</strong>和<strong>私有化</strong>技术解决这类问题。</p><blockquote><p><strong>📦 配套资源</strong>：本系列文章配有完整的 <a href="https://github.com/psmarter/PMPP-Learning">GitHub 仓库</a>，包含每章的练习题解答、CUDA 代码实现和详细注释。所有代码都经过测试，可以直接运行。</p></blockquote><h2 id="zhi-fang-tu-ji-chu" tabindex="-1" id="直方图基础">直方图基础</h2><h3 id="shi-yao-shi-zhi-fang-tu" tabindex="-1" id="什么是直方图">什么是直方图</h3><p>直方图统计数据的分布。给定一组数据，计算每个值（或区间）出现的次数。</p><p><strong>例子</strong>：统计文本中每个字母的出现次数</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入: &quot;hello world&quot;</span><br><span class="line">输出: h:1, e:1, l:3, o:2, w:1, r:1, d:1, 空格:1</span><br></pre></td></tr></table></figure><p><strong>图像直方图</strong>：统计每个灰度值（0-255）的像素数量</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入: 256×256 图像</span><br><span class="line">输出: histogram[256]，每个元素是该灰度值的像素计数</span><br></pre></td></tr></table></figure><h3 id="chuan-xing-shi-xian" tabindex="-1" id="串行实现">串行实现</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">histogram_sequential</span><span class="params">(<span class="type">unsigned</span> <span class="type">char</span> *data, <span class="type">int</span> *histogram, <span class="type">int</span> n)</span> &#123;</span><br><span class="line">    <span class="comment">// 初始化</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">256</span>; i++) &#123;</span><br><span class="line">        histogram[i] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 统计</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">        histogram[data[i]]++;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>时间复杂度 O(n)，空间复杂度 O(桶数)。</p><h3 id="bing-xing-hua-de-tiao-zhan" tabindex="-1" id="并行化的挑战">并行化的挑战</h3><p>尝试直接并行化：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">__global__ void histogram_naive(unsigned char *data, int *histogram, int n) &#123;</span><br><span class="line">    int i = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    if (i &lt; n) &#123;</span><br><span class="line">        histogram[data[i]]++;  // 危险！读-改-写竞争</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>问题</strong>：多个线程可能同时读取同一个 <code>histogram[k]</code>，各自加 1，然后写回。结果只加了 1 次而不是多次。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">线程 A: 读 histogram[5] = 10</span><br><span class="line">线程 B: 读 histogram[5] = 10</span><br><span class="line">线程 A: 写 histogram[5] = 11</span><br><span class="line">线程 B: 写 histogram[5] = 11  // 应该是 12！</span><br></pre></td></tr></table></figure><p>这就是<strong>竞态条件（Race Condition）</strong>。</p><h2 id="yuan-zi-cao-zuo" tabindex="-1" id="原子操作">原子操作</h2><h3 id="shi-yao-shi-yuan-zi-cao-zuo" tabindex="-1" id="什么是原子操作">什么是原子操作</h3><p><strong>原子操作</strong>：不可分割的操作。整个&quot;读-改-写&quot;过程要么全部完成，要么完全不执行，不会被其他线程打断。</p><p>CUDA 提供的原子函数：</p><table><thead><tr><th>函数</th><th>操作</th><th>返回值</th></tr></thead><tbody><tr><td><code>atomicAdd</code></td><td><code>*addr += val</code></td><td>旧值</td></tr><tr><td><code>atomicSub</code></td><td><code>*addr -= val</code></td><td>旧值</td></tr><tr><td><code>atomicMax</code></td><td><code>*addr = max()</code></td><td>旧值</td></tr><tr><td><code>atomicMin</code></td><td><code>*addr = min()</code></td><td>旧值</td></tr><tr><td><code>atomicExch</code></td><td><code>*addr = val</code></td><td>旧值</td></tr><tr><td><code>atomicCAS</code></td><td>compare-and-swap</td><td>旧值</td></tr><tr><td><code>atomicAnd/Or/Xor</code></td><td>位操作</td><td>旧值</td></tr></tbody></table><h3 id="shi-yong-yuan-zi-cao-zuo-de-zhi-fang-tu" tabindex="-1" id="使用原子操作的直方图">使用原子操作的直方图</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">__global__ void histogram_atomic(unsigned char *data, int *histogram, int n) &#123;</span><br><span class="line">    int i = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    if (i &lt; n) &#123;</span><br><span class="line">        atomicAdd(&amp;histogram[data[i]], 1);  // 原子加</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>正确性保证</strong>：<code>atomicAdd</code> 确保每次增量都被正确计入。</p><h3 id="yuan-zi-cao-zuo-de-kai-xiao" tabindex="-1" id="原子操作的开销">原子操作的开销</h3><p>原子操作比普通操作慢得多：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">普通写入：~4 周期</span><br><span class="line">原子操作：~数百周期（取决于争用程度）</span><br></pre></td></tr></table></figure><p><strong>原因</strong>：</p><ol><li><strong>串行化</strong>：同一地址的原子操作必须排队执行</li><li><strong>缓存一致性</strong>：需要协调多个 SM 的缓存</li><li><strong>内存事务</strong>：需要往返全局内存</li></ol><p><strong>争用程度</strong>影响很大：</p><table><thead><tr><th>场景</th><th>桶数</th><th>争用程度</th><th>性能</th></tr></thead><tbody><tr><td>字母统计</td><td>26</td><td>极高</td><td>很慢</td></tr><tr><td>灰度直方图</td><td>256</td><td>高</td><td>较慢</td></tr><tr><td>颜色直方图</td><td>16M</td><td>低</td><td>接近峰值</td></tr></tbody></table><p>桶越多，争用越低，性能越好。</p><h2 id="si-you-hua-privatization" tabindex="-1" id="私有化（Privatization）">私有化（Privatization）</h2><h3 id="he-xin-si-xiang" tabindex="-1" id="核心思想">核心思想</h3><p><strong>私有化</strong>：每个线程/块维护自己的私有直方图，最后合并。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">原本：所有线程 → 全局直方图（高争用）</span><br><span class="line">私有化：</span><br><span class="line">  线程/块 → 私有直方图（无争用）</span><br><span class="line">  最后：私有直方图 → 全局直方图（一次性合并）</span><br></pre></td></tr></table></figure><h3 id="gong-xiang-nei-cun-si-you-hua" tabindex="-1" id="共享内存私有化">共享内存私有化</h3><p>每个 Block 用共享内存维护私有直方图：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">#define NUM_BINS 256</span><br><span class="line"></span><br><span class="line">__global__ void histogram_privatized(unsigned char *data, int *histogram, int n) &#123;</span><br><span class="line">    // 私有直方图（共享内存）</span><br><span class="line">    __shared__ int private_hist[NUM_BINS];</span><br><span class="line">    </span><br><span class="line">    // 初始化私有直方图</span><br><span class="line">    if (threadIdx.x &lt; NUM_BINS) &#123;</span><br><span class="line">        private_hist[threadIdx.x] = 0;</span><br><span class="line">    &#125;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    // 统计到私有直方图</span><br><span class="line">    int i = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    int stride = blockDim.x * gridDim.x;</span><br><span class="line">    </span><br><span class="line">    while (i &lt; n) &#123;</span><br><span class="line">        atomicAdd(&amp;private_hist[data[i]], 1);  // 共享内存原子操作</span><br><span class="line">        i += stride;</span><br><span class="line">    &#125;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    // 合并到全局直方图</span><br><span class="line">    if (threadIdx.x &lt; NUM_BINS) &#123;</span><br><span class="line">        atomicAdd(&amp;histogram[threadIdx.x], private_hist[threadIdx.x]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="wei-shi-yao-geng-kuai" tabindex="-1" id="为什么更快">为什么更快</h3><p><strong>共享内存原子操作比全局内存快得多</strong>：</p><table><thead><tr><th>操作位置</th><th>延迟</th><th>带宽</th></tr></thead><tbody><tr><td>全局内存</td><td>~400 周期</td><td>~500 GB/s</td></tr><tr><td>共享内存</td><td>~20 周期</td><td>~10 TB/s</td></tr></tbody></table><p>加速比约 20 倍（理想情况）。</p><p><strong>争用也减少</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">原本：所有线程争用同一个全局直方图</span><br><span class="line">私有化：</span><br><span class="line">  - Block 内线程争用私有直方图（共享内存，快）</span><br><span class="line">  - Block 间合并时争用全局直方图（但只有 gridDim 次）</span><br></pre></td></tr></table></figure><h3 id="fen-jie-duan-fen-xi" tabindex="-1" id="分阶段分析">分阶段分析</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">阶段 1（初始化）：NUM_BINS 次写入共享内存</span><br><span class="line">阶段 2（私有统计）：n/gridDim 次共享内存原子操作</span><br><span class="line">阶段 3（合并）：NUM_BINS 次全局内存原子操作</span><br></pre></td></tr></table></figure><p>全局原子操作从 n 次降到 NUM_BINS × gridDim 次，大幅减少。</p><h2 id="xian-cheng-cu-hua" tabindex="-1" id="线程粗化">线程粗化</h2><h3 id="grid-stride-loop" tabindex="-1" id="Grid-Stride-Loop">Grid-Stride Loop</h3><p>之前代码已经用了 grid-stride loop：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">int i = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">int stride = blockDim.x * gridDim.x;</span><br><span class="line"></span><br><span class="line">while (i &lt; n) &#123;</span><br><span class="line">    // 处理元素 i</span><br><span class="line">    i += stride;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>优势</strong>：</p><ol><li>每个线程处理多个元素，分摊开销</li><li>Grid 大小可以固定，不随数据量变化</li><li>更好的缓存利用</li></ol><h3 id="lian-xu-fang-wen-you-hua" tabindex="-1" id="连续访问优化">连续访问优化</h3><p>让每个线程处理连续的一段数据：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">__global__ void histogram_coarsened(unsigned char *data, int *histogram, int n) &#123;</span><br><span class="line">    __shared__ int private_hist[NUM_BINS];</span><br><span class="line">    </span><br><span class="line">    // 初始化</span><br><span class="line">    for (int i = threadIdx.x; i &lt; NUM_BINS; i += blockDim.x) &#123;</span><br><span class="line">        private_hist[i] = 0;</span><br><span class="line">    &#125;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    // 每线程处理连续的 COARSEN_FACTOR 个元素</span><br><span class="line">    int base = (blockIdx.x * blockDim.x + threadIdx.x) * COARSEN_FACTOR;</span><br><span class="line">    </span><br><span class="line">    for (int k = 0; k &lt; COARSEN_FACTOR; k++) &#123;</span><br><span class="line">        int idx = base + k;</span><br><span class="line">        if (idx &lt; n) &#123;</span><br><span class="line">            atomicAdd(&amp;private_hist[data[idx]], 1);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    // 合并</span><br><span class="line">    for (int i = threadIdx.x; i &lt; NUM_BINS; i += blockDim.x) &#123;</span><br><span class="line">        atomicAdd(&amp;histogram[i], private_hist[i]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>优势</strong>：连续访问利于内存合并。</p><h2 id="ju-he-aggregation" tabindex="-1" id="聚合（Aggregation）">聚合（Aggregation）</h2><h3 id="wen-ti" tabindex="-1" id="问题">问题</h3><p>即使用了共享内存私有化，同一 Warp 内的线程可能频繁争用同一个桶。</p><p><strong>例子</strong>：处理全黑图像（所有像素值都是 0）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">32 个线程同时 atomicAdd(&amp;private_hist[0], 1)</span><br><span class="line">→ 32 次串行化的原子操作</span><br></pre></td></tr></table></figure><h3 id="jie-jue-fang-an-xian-cheng-shu-ji-ju-he" tabindex="-1" id="解决方案：线程束级聚合">解决方案：线程束级聚合</h3><p>先在线程束内统计每个值出现多少次，再做一次原子操作：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">__global__ void histogram_aggregated(unsigned char *data, int *histogram, int n) &#123;</span><br><span class="line">    __shared__ int private_hist[NUM_BINS];</span><br><span class="line">    </span><br><span class="line">    // 初始化</span><br><span class="line">    if (threadIdx.x &lt; NUM_BINS) &#123;</span><br><span class="line">        private_hist[threadIdx.x] = 0;</span><br><span class="line">    &#125;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    int i = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    </span><br><span class="line">    if (i &lt; n) &#123;</span><br><span class="line">        unsigned char value = data[i];</span><br><span class="line">        </span><br><span class="line">        // Warp 级投票：找出同值线程</span><br><span class="line">        unsigned int mask = __match_any_sync(__activemask(), value);</span><br><span class="line">        </span><br><span class="line">        // 只有组内第一个线程执行原子操作</span><br><span class="line">        if (__ffs(mask) - 1 == (threadIdx.x % 32)) &#123;</span><br><span class="line">            atomicAdd(&amp;private_hist[value], __popc(mask));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    // 合并到全局</span><br><span class="line">    if (threadIdx.x &lt; NUM_BINS) &#123;</span><br><span class="line">        atomicAdd(&amp;histogram[threadIdx.x], private_hist[threadIdx.x]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="xian-cheng-shu-ji-yuan-yu" tabindex="-1" id="线程束级原语">线程束级原语</h3><table><thead><tr><th>函数</th><th>功能</th></tr></thead><tbody><tr><td><code>__match_any_sync</code></td><td>返回值相同的线程掩码</td></tr><tr><td><code>__ffs</code></td><td>找第一个置位的位（Find First Set）</td></tr><tr><td><code>__popc</code></td><td>统计置位的位数（Population Count）</td></tr><tr><td><code>__activemask</code></td><td>当前活跃线程掩码</td></tr></tbody></table><p><strong><code>__match_any_sync</code> 示例</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">线程束内前8个线程的值：[5, 3, 5, 5, 2, 3, 5, 2]</span><br><span class="line">__match_any_sync 返回值：</span><br><span class="line">  线程 0,2,3,6 返回 0b01001101（值为5的线程掩码）</span><br><span class="line">  线程 1,5 返回 0b00100010（值为3的线程掩码）</span><br><span class="line">  线程 4,7 返回 0b10010000（值为2的线程掩码）</span><br></pre></td></tr></table></figure><p><strong>效果</strong>：原子操作次数从32次降到3次（等于不同值的数量）。对于数据重复率高的场景，性能提升显著。</p><h2 id="wan-zheng-you-hua-ban-ben" tabindex="-1" id="完整优化版本">完整优化版本</h2><h3 id="zong-he-suo-you-you-hua" tabindex="-1" id="综合所有优化">综合所有优化</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">#define BLOCK_SIZE 256</span><br><span class="line">#define NUM_BINS 256</span><br><span class="line">#define COARSEN_FACTOR 4</span><br><span class="line"></span><br><span class="line">__global__ void histogram_optimized(unsigned char *data, int *histogram, int n) &#123;</span><br><span class="line">    // 共享内存私有直方图</span><br><span class="line">    __shared__ int private_hist[NUM_BINS];</span><br><span class="line">    </span><br><span class="line">    // 协作初始化</span><br><span class="line">    for (int i = threadIdx.x; i &lt; NUM_BINS; i += blockDim.x) &#123;</span><br><span class="line">        private_hist[i] = 0;</span><br><span class="line">    &#125;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    // Grid-stride loop + 粗化</span><br><span class="line">    int tid = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    int stride = blockDim.x * gridDim.x;</span><br><span class="line">    </span><br><span class="line">    for (int base = tid * COARSEN_FACTOR; base &lt; n; base += stride * COARSEN_FACTOR) &#123;</span><br><span class="line">        // 加载连续的 COARSEN_FACTOR 个元素</span><br><span class="line">        unsigned char values[COARSEN_FACTOR];</span><br><span class="line">        </span><br><span class="line">        #pragma unroll</span><br><span class="line">        for (int k = 0; k &lt; COARSEN_FACTOR; k++) &#123;</span><br><span class="line">            int idx = base + k;</span><br><span class="line">            values[k] = (idx &lt; n) ? data[idx] : 0xFF;  // 0xFF 作为无效标记</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        // 逐个处理，使用线程束聚合</span><br><span class="line">        #pragma unroll</span><br><span class="line">        for (int k = 0; k &lt; COARSEN_FACTOR; k++) &#123;</span><br><span class="line">            if (values[k] != 0xFF) &#123;</span><br><span class="line">                unsigned int mask = __match_any_sync(__activemask(), values[k]);</span><br><span class="line">                if (__ffs(mask) - 1 == (threadIdx.x % 32)) &#123;</span><br><span class="line">                    atomicAdd(&amp;private_hist[values[k]], __popc(mask));</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    // 合并到全局直方图</span><br><span class="line">    for (int i = threadIdx.x; i &lt; NUM_BINS; i += blockDim.x) &#123;</span><br><span class="line">        if (private_hist[i] &gt; 0) &#123;</span><br><span class="line">            atomicAdd(&amp;histogram[i], private_hist[i]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="qi-dong-pei-zhi" tabindex="-1" id="启动配置">启动配置</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">int numBlocks = (n + BLOCK_SIZE * COARSEN_FACTOR - 1) / (BLOCK_SIZE * COARSEN_FACTOR);</span><br><span class="line">numBlocks = min(numBlocks, 256);  // 限制 block 数量</span><br><span class="line"></span><br><span class="line">histogram_optimized&lt;&lt;&lt;numBlocks, BLOCK_SIZE&gt;&gt;&gt;(d_data, d_histogram, n);</span><br></pre></td></tr></table></figure><h3 id="xing-neng-dui-bi" tabindex="-1" id="性能对比">性能对比</h3><p>以 1920×1080 灰度图像直方图计算为例：</p><table><thead><tr><th>版本</th><th>相对性能</th><th>主要瓶颈</th></tr></thead><tbody><tr><td>朴素全局原子操作</td><td>1×</td><td>全局内存争用</td></tr><tr><td>共享内存私有化</td><td>10×</td><td>共享内存原子</td></tr><tr><td>+ 线程粗化</td><td>15×</td><td>原子操作</td></tr><tr><td>+ 线程束聚合</td><td>25×</td><td>接近带宽上限</td></tr></tbody></table><p><strong>测试环境</strong>：</p><ul><li>图像大小：1920×1080（约207万像素）</li><li>GPU：NVIDIA RTX 3080（8704 CUDA 核心）</li><li>桶数：256（灰度值0-255）</li><li>块大小：256线程</li></ul><h2 id="qi-ta-si-you-hua-ce-lue" tabindex="-1" id="其他私有化策略">其他私有化策略</h2><h3 id="xian-cheng-ji-si-you-hua" tabindex="-1" id="线程级私有化">线程级私有化</h3><p>如果桶数很少（如 8 个），可以用寄存器：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">__global__ void histogram_register(unsigned char *data, int *histogram, int n) &#123;</span><br><span class="line">    // 每线程私有直方图（寄存器）</span><br><span class="line">    int local_hist[8] = &#123;0&#125;;</span><br><span class="line">    </span><br><span class="line">    int i = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    int stride = blockDim.x * gridDim.x;</span><br><span class="line">    </span><br><span class="line">    while (i &lt; n) &#123;</span><br><span class="line">        int bin = data[i] % 8;  // 假设只有 8 个桶</span><br><span class="line">        local_hist[bin]++;</span><br><span class="line">        i += stride;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    // 合并到全局</span><br><span class="line">    for (int b = 0; b &lt; 8; b++) &#123;</span><br><span class="line">        atomicAdd(&amp;histogram[b], local_hist[b]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>优势</strong>：寄存器最快，无争用。</p><p><strong>限制</strong>：桶数必须很少（寄存器数量有限）。</p><h3 id="duo-ji-si-you-hua" tabindex="-1" id="多级私有化">多级私有化</h3><p>对于大桶数：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">寄存器（极少桶）→ 共享内存（中等桶）→ 全局内存（大桶数）</span><br></pre></td></tr></table></figure><p>每级容量递增，速度递减。</p><h2 id="yuan-zi-cao-zuo-de-ying-jian-zhi-chi" tabindex="-1" id="原子操作的硬件支持">原子操作的硬件支持</h2><h3 id="zhi-chi-de-shu-ju-lei-xing" tabindex="-1" id="支持的数据类型">支持的数据类型</h3><table><thead><tr><th>类型</th><th>原子操作支持</th><th>备注</th></tr></thead><tbody><tr><td>int</td><td>全部</td><td>最常用</td></tr><tr><td>unsigned</td><td>全部</td><td></td></tr><tr><td>float</td><td>atomicAdd</td><td>Kepler+ (CC 3.0)</td></tr><tr><td>double</td><td>atomicAdd</td><td>Pascal+ (CC 6.0)</td></tr><tr><td>half</td><td>atomicAdd</td><td>Volta+ (CC 7.0)</td></tr></tbody></table><h3 id="gong-xiang-nei-cun-vs-quan-ju-nei-cun-yuan-zi" tabindex="-1" id="共享内存-vs-全局内存原子">共享内存 vs 全局内存原子</h3><table><thead><tr><th>特性</th><th>共享内存原子</th><th>全局内存原子</th></tr></thead><tbody><tr><td>延迟</td><td>~20 周期</td><td>~400 周期</td></tr><tr><td>带宽</td><td>高</td><td>低</td></tr><tr><td>争用范围</td><td>Block 内</td><td>全设备</td></tr><tr><td>适用场景</td><td>中间结果</td><td>最终结果</td></tr></tbody></table><h3 id="yuan-zi-cao-zuo-shi-xian-yuan-li" tabindex="-1" id="原子操作实现原理">原子操作实现原理</h3><p><strong>Compare-And-Swap (CAS)</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">// atomicAdd 的本质实现</span><br><span class="line">__device__ int atomicAdd_manual(int *addr, int val) &#123;</span><br><span class="line">    int old = *addr, assumed;</span><br><span class="line">    do &#123;</span><br><span class="line">        assumed = old;</span><br><span class="line">        old = atomicCAS(addr, assumed, assumed + val);</span><br><span class="line">    &#125; while (old != assumed);</span><br><span class="line">    return old;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>循环直到成功——高争用时可能循环很多次。</p><h2 id="ying-yong-kuo-zhan" tabindex="-1" id="应用扩展">应用扩展</h2><h3 id="duo-tong-dao-zhi-fang-tu" tabindex="-1" id="多通道直方图">多通道直方图</h3><p>RGB 图像的三通道直方图：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">__global__ void histogram_rgb(unsigned char *image, int *hist_r, int *hist_g, int *hist_b, int n) &#123;</span><br><span class="line">    __shared__ int priv_r[256], priv_g[256], priv_b[256];</span><br><span class="line">    </span><br><span class="line">    // 初始化</span><br><span class="line">    // ...</span><br><span class="line">    </span><br><span class="line">    int i = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    if (i &lt; n) &#123;</span><br><span class="line">        atomicAdd(&amp;priv_r[image[3*i + 0]], 1);</span><br><span class="line">        atomicAdd(&amp;priv_g[image[3*i + 1]], 1);</span><br><span class="line">        atomicAdd(&amp;priv_b[image[3*i + 2]], 1);</span><br><span class="line">    &#125;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    // 合并</span><br><span class="line">    // ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="jia-quan-zhi-fang-tu" tabindex="-1" id="加权直方图">加权直方图</h3><p>每个数据点有权重：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">atomicAdd(&amp;histogram[data[i]], weight[i]);</span><br></pre></td></tr></table></figure><p>用于直方图均衡化等场景。</p><h3 id="er-wei-zhi-fang-tu" tabindex="-1" id="二维直方图">二维直方图</h3><p>统计两个变量的联合分布：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">int bin_x = data_x[i] / bin_width_x;</span><br><span class="line">int bin_y = data_y[i] / bin_width_y;</span><br><span class="line">int bin = bin_y * num_bins_x + bin_x;</span><br><span class="line">atomicAdd(&amp;histogram_2d[bin], 1);</span><br></pre></td></tr></table></figure><h2 id="xing-neng-diao-you-jian-yi" tabindex="-1" id="性能调优建议">性能调优建议</h2><h3 id="xuan-ze-ce-lue" tabindex="-1" id="选择策略">选择策略</h3><table><thead><tr><th>桶数</th><th>推荐策略</th></tr></thead><tbody><tr><td>&lt; 16</td><td>寄存器私有化</td></tr><tr><td>16 - 1024</td><td>共享内存私有化 + 聚合</td></tr><tr><td>&gt; 1024</td><td>直接全局原子（争用低）</td></tr></tbody></table><h3 id="guan-jian-can-shu" tabindex="-1" id="关键参数">关键参数</h3><p><strong>Block 大小</strong>：256 或 512，保证足够的并行度。</p><p><strong>粗化因子</strong>：4-16，平衡寄存器压力和计算粒度。</p><p><strong>Grid 大小</strong>：不要太大，否则合并阶段开销增加。</p><h3 id="nsight-zhi-biao" tabindex="-1" id="Nsight-指标">Nsight 指标</h3><table><thead><tr><th>指标</th><th>含义</th><th>目标</th></tr></thead><tbody><tr><td>Atomic Operations</td><td>原子操作数</td><td>越少越好</td></tr><tr><td>Shared Memory Bandwidth</td><td>共享内存带宽</td><td>接近峰值</td></tr><tr><td>Warp Efficiency</td><td>Warp 利用率</td><td>&gt; 90%</td></tr></tbody></table><h2 id="xiao-jie" tabindex="-1" id="小结">小结</h2><p>第九章解决了&quot;输出冲突&quot;问题：</p><p><strong>原子操作</strong>：保证&quot;读-改-写&quot;的原子性，解决竞态条件。但全局内存原子操作很慢，尤其在高争用时。</p><p><strong>私有化</strong>：每个 Block 用共享内存维护私有副本，最后合并。共享内存原子比全局快 20 倍，争用也被限制在 Block 内。</p><p><strong>线程粗化</strong>：每线程处理多个元素，分摊初始化和合并开销。Grid-stride loop 是通用模式。</p><p><strong>线程束聚合</strong>：使用 <code>__match_any_sync</code> 找同值线程，只做一次原子操作。在数据重复率高时效果显著。</p><p><strong>策略选择</strong>：桶数决定策略——少桶用寄存器，中桶用共享内存，多桶直接全局原子。</p><p>直方图是&quot;归约到多个目标&quot;的典型代表。原子操作和私有化技术也适用于其他类似问题：散射（scatter）、分组聚合、哈希表构建等。下一章将学习另一个重要模式——归约。</p><hr><h2 id="xia-yi-bu" tabindex="-1" id="🚀-下一步">🚀 下一步</h2><hr><h2 id="can-kao-zi-liao" tabindex="-1" id="📚-参考资料">📚 参考资料</h2><ul><li>PMPP 第四版 Chapter 09</li><li><a href="https://smarter.xin/posts/d29973f1/">第九章：并行直方图</a></li></ul><p><strong>学习愉快！</strong> 🎓</p><hr><blockquote><p><strong>本文 GitHub 仓库</strong>: <a href="https://github.com/psmarter/PMPP-Learning">https://github.com/psmarter/PMPP-Learning</a></p></blockquote>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h2 id=&quot;qian-yan&quot; tabindex=&quot;-1&quot;</summary>
        
      
    
    
    
    <category term="知识分享" scheme="https://smarter.xin/categories/knowledge-sharing/"/>
    
    
    <category term="CUDA" scheme="https://smarter.xin/tags/CUDA/"/>
    
    <category term="GPU编程" scheme="https://smarter.xin/tags/gpu-programming/"/>
    
    <category term="并行计算" scheme="https://smarter.xin/tags/parallel-computing/"/>
    
    <category term="PMPP" scheme="https://smarter.xin/tags/PMPP/"/>
    
    <category term="直方图" scheme="https://smarter.xin/tags/histogram/"/>
    
    <category term="原子操作" scheme="https://smarter.xin/tags/atomic-operations/"/>
    
    <category term="私有化" scheme="https://smarter.xin/tags/privatization/"/>
    
  </entry>
  
  <entry>
    <title>PMPP-第八章：模板</title>
    <link href="https://smarter.xin/posts/93c68d7a/"/>
    <id>https://smarter.xin/posts/93c68d7a/</id>
    <published>2026-01-17T09:15:06.000Z</published>
    <updated>2026-01-24T11:47:21.463Z</updated>
    
    <content type="html"><![CDATA[<h2 id="qian-yan" tabindex="-1" id="前言">前言</h2><p>第七章学习了卷积，本章学习模板计算（Stencil）。这两者在计算模式上很相似，但侧重点不同。<strong>卷积</strong>强调信号处理中的滑动加权和，权重来自滤波器；<strong>模板计算</strong>强调科学计算中的邻域更新，常见于偏微分方程（PDE）求解、物理仿真等场景。从 CUDA 优化角度看，两者的技术是相通的，但模板计算有其特点：通常需要<strong>多次迭代</strong>，必须处理<strong>时间步进</strong>和<strong>双缓冲</strong>问题。</p><blockquote><p><strong>📦 配套资源</strong>：本系列文章配有完整的 <a href="https://github.com/psmarter/PMPP-Learning">GitHub 仓库</a>，包含每章的练习题解答、CUDA 代码实现和详细注释。所有代码都经过测试，可以直接运行。</p></blockquote><h2 id="mo-ban-ji-suan-ji-chu" tabindex="-1" id="模板计算基础">模板计算基础</h2><h3 id="shi-yao-shi-mo-ban-ji-suan" tabindex="-1" id="什么是模板计算">什么是模板计算</h3><p>模板计算（Stencil Computation）：用<strong>固定的邻域模式</strong>更新网格中的每个点。</p><p><strong>一维热传导</strong>（最简单的例子）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">时间 t:    [..., A, B, C, ...]</span><br><span class="line">时间 t+1:       B&#x27; = (A + B + C) / 3</span><br></pre></td></tr></table></figure><p>每个点的新值是自己和邻居的加权平均。这就是模板：一个描述&quot;如何从邻居计算自己&quot;的模式。</p><h3 id="mo-ban-de-xing-zhuang" tabindex="-1" id="模板的形状">模板的形状</h3><p>常见的模板形状：</p><p><strong>1D 三点模板</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[ -1  0  +1 ]</span><br><span class="line">   ↓  ↓  ↓</span><br><span class="line">   A  B  C</span><br></pre></td></tr></table></figure><p><strong>2D 五点模板（冯·诺依曼邻域）</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">       [0,-1]</span><br><span class="line">         ↑</span><br><span class="line">[-1,0] ← [0,0] → [+1,0]</span><br><span class="line">         ↓</span><br><span class="line">       [0,+1]</span><br></pre></td></tr></table></figure><p><strong>2D 九点模板（摩尔邻域）</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[-1,-1] [0,-1] [+1,-1]</span><br><span class="line">[-1, 0] [0, 0] [+1, 0]</span><br><span class="line">[-1,+1] [0,+1] [+1,+1]</span><br></pre></td></tr></table></figure><p><strong>3D 七点模板</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">上下前后左右 + 自己</span><br></pre></td></tr></table></figure><h3 id="mo-ban-vs-juan-ji" tabindex="-1" id="模板-vs-卷积">模板 vs 卷积</h3><table><thead><tr><th>特性</th><th>卷积</th><th>模板</th></tr></thead><tbody><tr><td>权重</td><td>来自滤波器，任意值</td><td>通常是固定系数</td></tr><tr><td>迭代</td><td>通常单次</td><td>多次时间步进</td></tr><tr><td>边界</td><td>零填充常见</td><td>周期/固定边界更常见</td></tr><tr><td>应用</td><td>信号/图像处理</td><td>PDE/物理仿真</td></tr><tr><td>读写模式</td><td>只读输入，写输出</td><td>读旧值，写新值</td></tr></tbody></table><p>从 GPU 优化角度，两者的核心技术是相同的：<strong>常量内存</strong>存系数，<strong>共享内存</strong> Tiling 减少全局内存访问。</p><h2 id="2-d-mo-ban-re-chuan-dao-fang-cheng" tabindex="-1" id="2D-模板：热传导方程">2D 模板：热传导方程</h2><h3 id="wu-li-bei-jing" tabindex="-1" id="物理背景">物理背景</h3><p>二维热传导方程：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>T</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>t</mi></mrow></mfrac><mo>=</mo><mi>α</mi><mrow><mo fence="true">(</mo><mfrac><mrow><msup><mi mathvariant="normal">∂</mi><mn>2</mn></msup><mi>T</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msup><mi>x</mi><mn>2</mn></msup></mrow></mfrac><mo>+</mo><mfrac><mrow><msup><mi mathvariant="normal">∂</mi><mn>2</mn></msup><mi>T</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msup><mi>y</mi><mn>2</mn></msup></mrow></mfrac><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\frac{\partial T}{\partial t} = \alpha \left( \frac{\partial^2 T}{\partial x^2} + \frac{\partial^2 T}{\partial y^2} \right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.0574em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal">t</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4411em;vertical-align:-0.95em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.4911em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7401em;"><span style="top:-2.989em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.4911em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7401em;"><span style="top:-2.989em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span></span></span></span></span></p><p>用有限差分离散化后：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msubsup><mi>T</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo>=</mo><msubsup><mi>T</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow><mi>n</mi></msubsup><mo>+</mo><mi>α</mi><mi mathvariant="normal">Δ</mi><mi>t</mi><mrow><mo fence="true">(</mo><mfrac><mrow><msubsup><mi>T</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn><mo separator="true">,</mo><mi>j</mi></mrow><mi>n</mi></msubsup><mo>+</mo><msubsup><mi>T</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn><mo separator="true">,</mo><mi>j</mi></mrow><mi>n</mi></msubsup><mo>+</mo><msubsup><mi>T</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi><mo>+</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mo>+</mo><msubsup><mi>T</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi><mo>−</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mo>−</mo><mn>4</mn><msubsup><mi>T</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow><mi>n</mi></msubsup></mrow><mrow><mi mathvariant="normal">Δ</mi><msup><mi>x</mi><mn>2</mn></msup></mrow></mfrac><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">T_{i,j}^{n+1} = T_{i,j}^n + \alpha \Delta t \left( \frac{T_{i+1,j}^n + T_{i-1,j}^n + T_{i,j+1}^n + T_{i,j-1}^n - 4T_{i,j}^n}{\Delta x^2} \right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2672em;vertical-align:-0.4031em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-2.433em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4031em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0975em;vertical-align:-0.3831em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7144em;"><span style="top:-2.453em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3831em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:2.4181em;vertical-align:-0.95em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mord">Δ</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.4681em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">Δ</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7401em;"><span style="top:-2.989em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.7848em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-2.4413em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3948em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-2.4413em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">1</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3948em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-2.4413em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3948em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-2.4413em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3948em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord">4</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-2.4413em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3948em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span></span></span></span></span></p><p>简化为五点模板：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">T_new[i][j] = c0 * T[i][j] + c1 * (T[i-1][j] + T[i+1][j] + T[i][j-1] + T[i][j+1])</span><br></pre></td></tr></table></figure><p>其中 <code>c0 = 1 - 4*alpha*dt/dx²</code>，<code>c1 = alpha*dt/dx²</code>。</p><h3 id="po-su-shi-xian" tabindex="-1" id="朴素实现">朴素实现</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">__global__ void stencil_2d_basic(float *in, float *out, int N) &#123;</span><br><span class="line">    int i = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    int j = blockIdx.y * blockDim.y + threadIdx.y;</span><br><span class="line">    </span><br><span class="line">    if (i &gt; 0 &amp;&amp; i &lt; N-1 &amp;&amp; j &gt; 0 &amp;&amp; j &lt; N-1) &#123;</span><br><span class="line">        out[i*N + j] = C0 * in[i*N + j] +</span><br><span class="line">                       C1 * (in[(i-1)*N + j] + in[(i+1)*N + j] +</span><br><span class="line">                             in[i*N + (j-1)] + in[i*N + (j+1)]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>问题</strong>：每个点读取 5 次全局内存，相邻点的访问有大量重叠。</p><h3 id="shu-ju-fu-yong-fen-xi" tabindex="-1" id="数据复用分析">数据复用分析</h3><p>考虑一行线程计算：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">线程 j:   读取 T[i][j-1], T[i][j], T[i][j+1], T[i-1][j], T[i+1][j]</span><br><span class="line">线程 j+1: 读取 T[i][j], T[i][j+1], T[i][j+2], T[i-1][j+1], T[i+1][j+1]</span><br><span class="line">                ↑           ↑ 共享</span><br></pre></td></tr></table></figure><p>相邻线程共享了 <code>T[i][j]</code> 和 <code>T[i][j+1]</code>。如果把一个 Tile 的数据加载到共享内存，这些共享访问都变成快速的片上访问。</p><h2 id="tiled-mo-ban-shi-xian" tabindex="-1" id="Tiled-模板实现">Tiled 模板实现</h2><h3 id="shu-ru-shu-chu-tile-guan-xi" tabindex="-1" id="输入输出-Tile-关系">输入输出 Tile 关系</h3><p>与卷积类似，计算 <code>OUT_TILE_SIZE × OUT_TILE_SIZE</code> 的输出，需要 <code>(OUT_TILE_SIZE + 2*r) × (OUT_TILE_SIZE + 2*r)</code> 的输入。</p><p>对于五点模板（r=1）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入 Tile：(T + 2) × (T + 2)</span><br><span class="line">输出 Tile：T × T</span><br></pre></td></tr></table></figure><h3 id="xian-cheng-yu-shu-ju-ying-she" tabindex="-1" id="线程与数据映射">线程与数据映射</h3><p>有两种策略：</p><p><strong>策略 1：线程数 = 输入 Tile 大小</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Block: (T+2) × (T+2) 线程</span><br><span class="line">每线程加载 1 个输入元素</span><br><span class="line">只有内部 T × T 线程计算输出</span><br></pre></td></tr></table></figure><p><strong>策略 2：线程数 = 输出 Tile 大小</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Block: T × T 线程</span><br><span class="line">部分线程负责加载 Halo 元素</span><br><span class="line">所有线程都计算输出</span><br></pre></td></tr></table></figure><p>书中推荐<strong>策略 1</strong>，因为加载更简单，且边界线程虽不计算但仍能并行执行。</p><h3 id="wan-zheng-shi-xian" tabindex="-1" id="完整实现">完整实现</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">#define IN_TILE_SIZE 18  // 16 + 2</span><br><span class="line">#define OUT_TILE_SIZE 16</span><br><span class="line"></span><br><span class="line">__global__ void stencil_2d_tiled(float *in, float *out, int N) &#123;</span><br><span class="line">    __shared__ float tile[IN_TILE_SIZE][IN_TILE_SIZE];</span><br><span class="line">    </span><br><span class="line">    // 线程在输入 Tile 中的位置</span><br><span class="line">    int tx = threadIdx.x, ty = threadIdx.y;</span><br><span class="line">    </span><br><span class="line">    // 对应的全局输入位置</span><br><span class="line">    int in_row = blockIdx.y * OUT_TILE_SIZE + ty - 1;  // -1 是因为 Halo</span><br><span class="line">    int in_col = blockIdx.x * OUT_TILE_SIZE + tx - 1;</span><br><span class="line">    </span><br><span class="line">    // 加载（含边界检查）</span><br><span class="line">    if (in_row &gt;= 0 &amp;&amp; in_row &lt; N &amp;&amp; in_col &gt;= 0 &amp;&amp; in_col &lt; N) &#123;</span><br><span class="line">        tile[ty][tx] = in[in_row * N + in_col];</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        tile[ty][tx] = 0.0f;  // 边界外填 0</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    // 只有内部线程计算输出</span><br><span class="line">    if (tx &gt; 0 &amp;&amp; tx &lt; IN_TILE_SIZE - 1 &amp;&amp; </span><br><span class="line">        ty &gt; 0 &amp;&amp; ty &lt; IN_TILE_SIZE - 1) &#123;</span><br><span class="line">        </span><br><span class="line">        int out_row = blockIdx.y * OUT_TILE_SIZE + ty - 1;</span><br><span class="line">        int out_col = blockIdx.x * OUT_TILE_SIZE + tx - 1;</span><br><span class="line">        </span><br><span class="line">        if (out_row &lt; N &amp;&amp; out_col &lt; N) &#123;</span><br><span class="line">            out[out_row * N + out_col] = </span><br><span class="line">                C0 * tile[ty][tx] +</span><br><span class="line">                C1 * (tile[ty-1][tx] + tile[ty+1][tx] +</span><br><span class="line">                      tile[ty][tx-1] + tile[ty][tx+1]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="qi-dong-pei-zhi" tabindex="-1" id="启动配置">启动配置</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dim3 block(IN_TILE_SIZE, IN_TILE_SIZE);  // 18×18 = 324 线程</span><br><span class="line">dim3 grid((N + OUT_TILE_SIZE - 1) / OUT_TILE_SIZE,</span><br><span class="line">          (N + OUT_TILE_SIZE - 1) / OUT_TILE_SIZE);</span><br><span class="line"></span><br><span class="line">stencil_2d_tiled&lt;&lt;&lt;grid, block&gt;&gt;&gt;(d_in, d_out, N);</span><br></pre></td></tr></table></figure><h3 id="xing-neng-fen-xi" tabindex="-1" id="性能分析">性能分析</h3><table><thead><tr><th>指标</th><th>朴素实现</th><th>Tiled 实现</th></tr></thead><tbody><tr><td>每输出元素</td><td>5 次全局读取</td><td>18²/16² ≈ 1.27 次</td></tr><tr><td>加速比</td><td>1×</td><td>~4×</td></tr><tr><td>共享内存</td><td>0</td><td>18×18×4 = 1.3 KB</td></tr></tbody></table><h2 id="xian-cheng-cu-hua-thread-coarsening" tabindex="-1" id="线程粗化（Thread-Coarsening）">线程粗化（Thread Coarsening）</h2><h3 id="wei-shi-yao-cu-hua" tabindex="-1" id="为什么粗化">为什么粗化</h3><p>Tiled 模板有个问题：边界线程只加载不计算，效率不高。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Block 线程数：18×18 = 324</span><br><span class="line">计算线程数：16×16 = 256</span><br><span class="line">利用率：256/324 = 79%</span><br></pre></td></tr></table></figure><p>如果模板半径更大，利用率更低。</p><p><strong>线程粗化</strong>的思路：让每个线程计算多个输出元素，分摊边界开销。</p><h3 id="z-fang-xiang-cu-hua" tabindex="-1" id="Z-方向粗化">Z 方向粗化</h3><p>对于 3D 模板，常用的技巧是在 Z 方向展开：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">#define IN_TILE_SIZE 18</span><br><span class="line">#define OUT_TILE_SIZE 16</span><br><span class="line">#define Z_COARSEN 8  // 每线程处理 8 层</span><br><span class="line"></span><br><span class="line">__global__ void stencil_3d_coarsened(float *in, float *out, </span><br><span class="line">                                      int Nx, int Ny, int Nz) &#123;</span><br><span class="line">    __shared__ float tile[3][IN_TILE_SIZE][IN_TILE_SIZE];  // 只需 3 层</span><br><span class="line">    </span><br><span class="line">    int tx = threadIdx.x, ty = threadIdx.y;</span><br><span class="line">    int ox = blockIdx.x * OUT_TILE_SIZE + tx - 1;</span><br><span class="line">    int oy = blockIdx.y * OUT_TILE_SIZE + ty - 1;</span><br><span class="line">    </span><br><span class="line">    // 预加载前两层</span><br><span class="line">    load_layer(tile[0], in, ox, oy, 0, Nx, Ny, Nz);</span><br><span class="line">    load_layer(tile[1], in, ox, oy, 1, Nx, Ny, Nz);</span><br><span class="line">    </span><br><span class="line">    // 滑动窗口遍历 Z 方向</span><br><span class="line">    for (int z = 1; z &lt; Nz - 1; z++) &#123;</span><br><span class="line">        // 加载下一层</span><br><span class="line">        load_layer(tile[(z+1) % 3], in, ox, oy, z+1, Nx, Ny, Nz);</span><br><span class="line">        __syncthreads();</span><br><span class="line">        </span><br><span class="line">        // 计算当前层</span><br><span class="line">        if (tx &gt; 0 &amp;&amp; tx &lt; IN_TILE_SIZE - 1 &amp;&amp; </span><br><span class="line">            ty &gt; 0 &amp;&amp; ty &lt; IN_TILE_SIZE - 1) &#123;</span><br><span class="line">            int idx = z * Nx * Ny + oy * Nx + ox;</span><br><span class="line">            out[idx] = compute_stencil(tile, tx, ty, z);</span><br><span class="line">        &#125;</span><br><span class="line">        __syncthreads();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="ji-cun-qi-cu-hua" tabindex="-1" id="寄存器粗化">寄存器粗化</h3><p>更激进的做法：把滑动窗口存在寄存器里：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">__global__ void stencil_3d_register(float *in, float *out, </span><br><span class="line">                                     int Nx, int Ny, int Nz) &#123;</span><br><span class="line">    __shared__ float tile[IN_TILE_SIZE][IN_TILE_SIZE];</span><br><span class="line">    </span><br><span class="line">    int tx = threadIdx.x, ty = threadIdx.y;</span><br><span class="line">    int ox = blockIdx.x * OUT_TILE_SIZE + tx - 1;</span><br><span class="line">    int oy = blockIdx.y * OUT_TILE_SIZE + ty - 1;</span><br><span class="line">    </span><br><span class="line">    // 寄存器存 Z 方向的三个值</span><br><span class="line">    float z_prev, z_curr, z_next;</span><br><span class="line">    </span><br><span class="line">    z_prev = load_element(in, ox, oy, 0, Nx, Ny, Nz);</span><br><span class="line">    z_curr = load_element(in, ox, oy, 1, Nx, Ny, Nz);</span><br><span class="line">    </span><br><span class="line">    for (int z = 1; z &lt; Nz - 1; z++) &#123;</span><br><span class="line">        z_next = load_element(in, ox, oy, z+1, Nx, Ny, Nz);</span><br><span class="line">        </span><br><span class="line">        // 加载 XY 平面到共享内存</span><br><span class="line">        tile[ty][tx] = z_curr;</span><br><span class="line">        __syncthreads();</span><br><span class="line">        </span><br><span class="line">        // 计算</span><br><span class="line">        if (valid_output_thread) &#123;</span><br><span class="line">            out[idx] = C0 * tile[ty][tx] +</span><br><span class="line">                       C1 * (tile[ty-1][tx] + tile[ty+1][tx] +</span><br><span class="line">                             tile[ty][tx-1] + tile[ty][tx+1]) +</span><br><span class="line">                       C2 * (z_prev + z_next);  // Z 方向用寄存器</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        // 滑动窗口</span><br><span class="line">        z_prev = z_curr;</span><br><span class="line">        z_curr = z_next;</span><br><span class="line">        __syncthreads();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>优势</strong>：Z 方向的访问完全在寄存器，无需共享内存。</p><h2 id="bian-jie-tiao-jian-chu-li" tabindex="-1" id="边界条件处理">边界条件处理</h2><h3 id="chang-jian-bian-jie-tiao-jian" tabindex="-1" id="常见边界条件">常见边界条件</h3><p><strong>1. 固定边界（Dirichlet）</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">if (is_boundary) &#123;</span><br><span class="line">    out[idx] = BOUNDARY_VALUE;  // 固定值</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>2. 周期边界（Periodic）</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">int wrapped_x = (x + N) % N;  // 环绕</span><br><span class="line">int wrapped_y = (y + N) % N;</span><br></pre></td></tr></table></figure><p><strong>3. 零梯度边界（Neumann）</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">// 边界处用相邻内部值</span><br><span class="line">if (x == 0) x = 1;</span><br><span class="line">if (x == N-1) x = N-2;</span><br></pre></td></tr></table></figure><h3 id="bian-jie-chu-li-ce-lue" tabindex="-1" id="边界处理策略">边界处理策略</h3><p><strong>方法 1：条件分支</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">if (i &gt; 0 &amp;&amp; i &lt; N-1 &amp;&amp; j &gt; 0 &amp;&amp; j &lt; N-1) &#123;</span><br><span class="line">    // 内部点计算</span><br><span class="line">&#125; else &#123;</span><br><span class="line">    // 边界处理</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>问题：分支发散。</p><p><strong>方法 2：填充（Padding）</strong></p><p>预先在数据周围加一圈边界值，核函数内部无需边界判断。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">原始数据 N×N → 填充后 (N+2)×(N+2)</span><br><span class="line">所有计算都在 [1, N] 范围内</span><br></pre></td></tr></table></figure><p><strong>方法 3：分离边界核函数</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">// 先处理内部区域</span><br><span class="line">stencil_interior&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(in, out, N);</span><br><span class="line"></span><br><span class="line">// 再处理边界区域</span><br><span class="line">stencil_boundary&lt;&lt;&lt;1, boundary_threads&gt;&gt;&gt;(in, out, N);</span><br></pre></td></tr></table></figure><p>内部核函数无分支，边界核函数线程少但逻辑复杂。</p><h2 id="shi-jian-bu-jin-yu-shuang-huan-chong" tabindex="-1" id="时间步进与双缓冲">时间步进与双缓冲</h2><h3 id="die-dai-mo-shi" tabindex="-1" id="迭代模式">迭代模式</h3><p>模板计算通常需要多次迭代：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">for (int t = 0; t &lt; num_steps; t++) &#123;</span><br><span class="line">    stencil_kernel&lt;&lt;&lt;grid, block&gt;&gt;&gt;(d_in, d_out, N);</span><br><span class="line">    cudaDeviceSynchronize();</span><br><span class="line">    swap(d_in, d_out);  // 交换输入输出</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>关键</strong>：不能原地更新！读取邻居时可能读到已更新的值，导致错误。所以需要<strong>双缓冲</strong>：读旧写新，然后交换。</p><h3 id="shi-jian-zu-sai-temporal-blocking" tabindex="-1" id="时间阻塞（Temporal-Blocking）">时间阻塞（Temporal Blocking）</h3><p>每次 kernel 启动有开销。如果能在一次 kernel 中计算多个时间步，就能减少启动开销。</p><p><strong>原理</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">输入 Tile 计算 T 个时间步：</span><br><span class="line">时间 0：需要 (OUT + 2r*T) 的输入</span><br><span class="line">时间 1：需要 (OUT + 2r*(T-1)) 的输入</span><br><span class="line">...</span><br><span class="line">时间 T：输出 OUT 的结果</span><br></pre></td></tr></table></figure><p>随着时间推进，有效数据区域向内收缩。</p><p><strong>实现复杂度高</strong>，通常在高性能计算库中使用，手写较难。</p><h2 id="3-d-mo-ban-you-hua" tabindex="-1" id="3D-模板优化">3D 模板优化</h2><h3 id="tiao-zhan" tabindex="-1" id="挑战">挑战</h3><p>3D 模板的共享内存需求更大：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">2D: (T+2)² × 4 = 324 × 4 = 1.3 KB</span><br><span class="line">3D: (T+2)³ × 4 = 8000 × 4 = 32 KB  // 可能超限！</span><br></pre></td></tr></table></figure><h3 id="jie-jue-fang-an" tabindex="-1" id="解决方案">解决方案</h3><p><strong>1. 减小 Tile 大小</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#define TILE_3D 8</span><br><span class="line">// (8+2)³ = 1000 元素，4 KB</span><br></pre></td></tr></table></figure><p>代价：降低数据复用率。</p><p><strong>2. 2.5D 分解</strong></p><p>只加载 XY 平面的 Tile，Z 方向逐层处理：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">__shared__ float tile[TILE_Y][TILE_X];  // 只存一层 XY</span><br><span class="line"></span><br><span class="line">for (int z = 0; z &lt; Nz; z++) &#123;</span><br><span class="line">    // 加载当前层</span><br><span class="line">    // 计算（Z 方向邻居从全局内存读）</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Z 方向的访问仍走全局内存，但 XY 方向利用共享内存。</p><p><strong>3. 寄存器滑动窗口</strong></p><p>如前所述，Z 方向 3 个值存寄存器，XY 平面存共享内存。</p><h2 id="zhi-ling-ji-you-hua" tabindex="-1" id="指令级优化">指令级优化</h2><h3 id="xun-huan-zhan-kai" tabindex="-1" id="循环展开">循环展开</h3><p>对于小模板，手动展开消除循环开销：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">// 展开前</span><br><span class="line">for (int di = -1; di &lt;= 1; di++) &#123;</span><br><span class="line">    for (int dj = -1; dj &lt;= 1; dj++) &#123;</span><br><span class="line">        sum += tile[ty+di][tx+dj] * weight[di+1][dj+1];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 展开后</span><br><span class="line">sum = tile[ty-1][tx-1] * W00 + tile[ty-1][tx] * W01 + tile[ty-1][tx+1] * W02 +</span><br><span class="line">      tile[ty  ][tx-1] * W10 + tile[ty  ][tx] * W11 + tile[ty  ][tx+1] * W12 +</span><br><span class="line">      tile[ty+1][tx-1] * W20 + tile[ty+1][tx] * W21 + tile[ty+1][tx+1] * W22;</span><br></pre></td></tr></table></figure><p>编译器通常会自动展开，但显式展开保证效果。</p><h3 id="chang-liang-yu-ji-suan" tabindex="-1" id="常量预计算">常量预计算</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// 编译时常量</span><br><span class="line">#define C0 0.25f</span><br><span class="line">#define C1 0.125f</span><br><span class="line"></span><br><span class="line">// 或使用 constexpr（C++11）</span><br><span class="line">__device__ constexpr float c0 = 0.25f;</span><br></pre></td></tr></table></figure><p>避免运行时计算系数。</p><h3 id="xiang-liang-hua-jia-zai" tabindex="-1" id="向量化加载">向量化加载</h3><p>对于对齐的访问模式，使用向量类型：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">float4 data = *reinterpret_cast&lt;float4*&gt;(&amp;in[idx]);</span><br><span class="line">// 一次加载 4 个 float</span><br></pre></td></tr></table></figure><p>需要数据对齐（16 字节边界）。</p><h2 id="shi-zhan-jacobi-die-dai-qiu-jie-qi" tabindex="-1" id="实战：Jacobi-迭代求解器">实战：Jacobi 迭代求解器</h2><h3 id="wen-ti-she-zhi" tabindex="-1" id="问题设置">问题设置</h3><p>求解泊松方程 ∇²u = f：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">// Jacobi 迭代：u_new = (u_left + u_right + u_up + u_down - h²f) / 4</span><br></pre></td></tr></table></figure><h3 id="cuda-shi-xian" tabindex="-1" id="CUDA-实现">CUDA 实现</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">#define BLOCK_SIZE 16</span><br><span class="line">#define TILE_SIZE 18  // BLOCK_SIZE + 2</span><br><span class="line"></span><br><span class="line">__global__ void jacobi_iteration(float *u, float *u_new, float *f,</span><br><span class="line">                                  int N, float h2) &#123;</span><br><span class="line">    __shared__ float tile[TILE_SIZE][TILE_SIZE];</span><br><span class="line">    </span><br><span class="line">    int tx = threadIdx.x + 1;  // 偏移 1，留出 Halo</span><br><span class="line">    int ty = threadIdx.y + 1;</span><br><span class="line">    int gx = blockIdx.x * BLOCK_SIZE + threadIdx.x;</span><br><span class="line">    int gy = blockIdx.y * BLOCK_SIZE + threadIdx.y;</span><br><span class="line">    </span><br><span class="line">    // 加载中心</span><br><span class="line">    if (gx &lt; N &amp;&amp; gy &lt; N) &#123;</span><br><span class="line">        tile[ty][tx] = u[gy * N + gx];</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    // 加载 Halo</span><br><span class="line">    if (threadIdx.x == 0 &amp;&amp; gx &gt; 0) &#123;</span><br><span class="line">        tile[ty][0] = u[gy * N + gx - 1];</span><br><span class="line">    &#125;</span><br><span class="line">    if (threadIdx.x == BLOCK_SIZE - 1 &amp;&amp; gx &lt; N - 1) &#123;</span><br><span class="line">        tile[ty][TILE_SIZE - 1] = u[gy * N + gx + 1];</span><br><span class="line">    &#125;</span><br><span class="line">    if (threadIdx.y == 0 &amp;&amp; gy &gt; 0) &#123;</span><br><span class="line">        tile[0][tx] = u[(gy - 1) * N + gx];</span><br><span class="line">    &#125;</span><br><span class="line">    if (threadIdx.y == BLOCK_SIZE - 1 &amp;&amp; gy &lt; N - 1) &#123;</span><br><span class="line">        tile[TILE_SIZE - 1][tx] = u[(gy + 1) * N + gx];</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    // 计算（跳过边界）</span><br><span class="line">    if (gx &gt; 0 &amp;&amp; gx &lt; N - 1 &amp;&amp; gy &gt; 0 &amp;&amp; gy &lt; N - 1) &#123;</span><br><span class="line">        float f_val = f[gy * N + gx];</span><br><span class="line">        u_new[gy * N + gx] = 0.25f * (tile[ty-1][tx] + tile[ty+1][tx] +</span><br><span class="line">                                       tile[ty][tx-1] + tile[ty][tx+1] -</span><br><span class="line">                                       h2 * f_val);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// Host 端迭代</span><br><span class="line">void jacobi_solve(float *u, float *f, int N, int max_iter, float tol) &#123;</span><br><span class="line">    float *d_u, *d_u_new, *d_f;</span><br><span class="line">    // ... 分配内存 ...</span><br><span class="line">    </span><br><span class="line">    dim3 block(BLOCK_SIZE, BLOCK_SIZE);</span><br><span class="line">    dim3 grid((N + BLOCK_SIZE - 1) / BLOCK_SIZE,</span><br><span class="line">              (N + BLOCK_SIZE - 1) / BLOCK_SIZE);</span><br><span class="line">    </span><br><span class="line">    for (int iter = 0; iter &lt; max_iter; iter++) &#123;</span><br><span class="line">        jacobi_iteration&lt;&lt;&lt;grid, block&gt;&gt;&gt;(d_u, d_u_new, d_f, N, h*h);</span><br><span class="line">        cudaDeviceSynchronize();</span><br><span class="line">        </span><br><span class="line">        // 交换指针</span><br><span class="line">        float *temp = d_u;</span><br><span class="line">        d_u = d_u_new;</span><br><span class="line">        d_u_new = temp;</span><br><span class="line">        </span><br><span class="line">        // 可选：检查收敛</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="shou-lian-jian-cha" tabindex="-1" id="收敛检查">收敛检查</h3><p>每隔几步检查残差：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">__global__ void compute_residual(float *u, float *f, float *residual,</span><br><span class="line">                                  int N, float h2) &#123;</span><br><span class="line">    // 计算 ||∇²u - f||</span><br><span class="line">    // 使用规约求和</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>不需要每步都检查，开销太大。</p><h2 id="xing-neng-diao-you-jian-yi" tabindex="-1" id="性能调优建议">性能调优建议</h2><h3 id="tile-da-xiao-xuan-ze" tabindex="-1" id="Tile-大小选择">Tile 大小选择</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">共享内存限制：96 KB / SM（Ampere）</span><br><span class="line">每 Block 可用：~48 KB</span><br><span class="line"></span><br><span class="line">2D Tile: sqrt(48K/4) ≈ 110 → 实际用 32、48、64</span><br><span class="line">3D Tile: cbrt(48K/4) ≈ 23  → 实际用 8、12、16</span><br></pre></td></tr></table></figure><p>需要考虑占用率：Tile 太大导致每 SM 的 Block 数减少。</p><h3 id="nsight-zhi-biao" tabindex="-1" id="Nsight-指标">Nsight 指标</h3><p>关注：</p><table><thead><tr><th>指标</th><th>意义</th><th>目标</th></tr></thead><tbody><tr><td>Memory Throughput</td><td>带宽利用</td><td>接近峰值</td></tr><tr><td>Compute Throughput</td><td>计算利用</td><td>越高越好</td></tr><tr><td>Shared Memory Usage</td><td>共享内存</td><td>不超限</td></tr><tr><td>Warp Occupancy</td><td>占用率</td><td>&gt;50%</td></tr></tbody></table><h3 id="chang-jian-ping-jing" tabindex="-1" id="常见瓶颈">常见瓶颈</h3><p><strong>带宽受限</strong>：Tiling 优化、寄存器缓存<br><strong>计算受限</strong>：向量化、指令级并行<br><strong>延迟受限</strong>：增加占用率、预取</p><h2 id="mo-ban-you-hua-zong-jie" tabindex="-1" id="模板优化总结">模板优化总结</h2><h3 id="he-xin-ji-zhu" tabindex="-1" id="核心技术">核心技术</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">┌─────────────────────────────────────────────────────────────┐</span><br><span class="line">│ Level 3: 高级优化                                            │</span><br><span class="line">│   - 时间阻塞（多步合并）                                      │</span><br><span class="line">│   - 自动调优（搜索最优参数）                                  │</span><br><span class="line">├─────────────────────────────────────────────────────────────┤</span><br><span class="line">│ Level 2: 数据局部性                                          │</span><br><span class="line">│   - 共享内存 Tiling                                          │</span><br><span class="line">│   - 寄存器滑动窗口                                           │</span><br><span class="line">│   - 线程粗化                                                 │</span><br><span class="line">├─────────────────────────────────────────────────────────────┤</span><br><span class="line">│ Level 1: 基础优化                                            │</span><br><span class="line">│   - 双缓冲避免竞争                                           │</span><br><span class="line">│   - 边界条件处理                                             │</span><br><span class="line">│   - 合并内存访问                                             │</span><br><span class="line">└─────────────────────────────────────────────────────────────┘</span><br></pre></td></tr></table></figure><h3 id="mo-ban-vs-juan-ji-jue-ce" tabindex="-1" id="模板-vs-卷积决策">模板 vs 卷积决策</h3><table><thead><tr><th>场景</th><th>推荐技术</th></tr></thead><tbody><tr><td>单次滤波</td><td>卷积 + 常量内存</td></tr><tr><td>迭代求解</td><td>模板 + 双缓冲</td></tr><tr><td>大半径模板</td><td>时间阻塞</td></tr><tr><td>3D + 大规模</td><td>2.5D + 寄存器滑动</td></tr></tbody></table><h2 id="xiao-jie" tabindex="-1" id="小结">小结</h2><p>第八章围绕模板计算，在第七章卷积的基础上增加了：</p><p><strong>迭代结构</strong>：模板计算通常是多步迭代的。双缓冲是基本技巧——读旧写新，然后交换。</p><p><strong>线程粗化</strong>：让每个线程计算多个输出，分摊边界线程的开销。Z 方向粗化是 3D 模板的常用技巧。</p><p><strong>寄存器优化</strong>：对于滑动窗口模式，把时间维度或空间维度的小邻域存寄存器，比共享内存更快。</p><p><strong>边界处理</strong>：Dirichlet、Neumann、周期边界各有策略。Padding 预处理能简化 kernel 逻辑，但需要额外内存。</p><p><strong>3D 挑战</strong>：共享内存需求爆炸。2.5D 分解、寄存器滑动是解决方案。</p><p>模板计算是科学计算的核心，热传导、流体力学、电磁仿真都用到。掌握这套优化技术，就能高效实现各种 PDE 求解器。下一章进入另一个重要模式——并行直方图。</p><hr><h2 id="xia-yi-bu" tabindex="-1" id="🚀-下一步">🚀 下一步</h2><hr><h2 id="can-kao-zi-liao" tabindex="-1" id="📚-参考资料">📚 参考资料</h2><ul><li>PMPP 第四版 Chapter 08</li><li><a href="https://smarter.xin/posts/93c68d7a/">第八章：模板</a></li></ul><p><strong>学习愉快！</strong> 🎓</p><hr><blockquote><p><strong>本文 GitHub 仓库</strong>: <a href="https://github.com/psmarter/PMPP-Learning">https://github.com/psmarter/PMPP-Learning</a></p></blockquote>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h2 id=&quot;qian-yan&quot; tabindex=&quot;-1&quot;</summary>
        
      
    
    
    
    <category term="知识分享" scheme="https://smarter.xin/categories/knowledge-sharing/"/>
    
    
    <category term="CUDA" scheme="https://smarter.xin/tags/CUDA/"/>
    
    <category term="GPU编程" scheme="https://smarter.xin/tags/gpu-programming/"/>
    
    <category term="并行计算" scheme="https://smarter.xin/tags/parallel-computing/"/>
    
    <category term="PMPP" scheme="https://smarter.xin/tags/PMPP/"/>
    
    <category term="共享内存" scheme="https://smarter.xin/tags/shared-memory/"/>
    
    <category term="模板计算" scheme="https://smarter.xin/tags/template-computation/"/>
    
    <category term="Stencil" scheme="https://smarter.xin/tags/Stencil/"/>
    
  </entry>
  
  <entry>
    <title>PMPP-第七章：卷积</title>
    <link href="https://smarter.xin/posts/1c778456/"/>
    <id>https://smarter.xin/posts/1c778456/</id>
    <published>2026-01-16T13:58:04.000Z</published>
    <updated>2026-01-24T11:47:21.462Z</updated>
    
    <content type="html"><![CDATA[<h2 id="qian-yan" tabindex="-1" id="前言">前言</h2><p>第六章讨论了性能优化的各个方面，现在开始学习具体的并行计算模式。第七章的主角是<strong>卷积（Convolution）</strong>——信号处理和深度学习的核心算子。卷积看似简单，但要高效实现却涉及多个内存层次的配合：常量内存存储卷积核、共享内存实现分块（Tiling）、全局内存处理输入输出。本章将展示如何组合这些技术，实现工业级的卷积核函数。</p><blockquote><p><strong>📦 配套资源</strong>：本系列文章配有完整的 <a href="https://github.com/psmarter/PMPP-Learning">GitHub 仓库</a>，包含每章的练习题解答、CUDA 代码实现和详细注释。所有代码都经过测试，可以直接运行。</p></blockquote><h2 id="juan-ji-ji-chu" tabindex="-1" id="卷积基础">卷积基础</h2><h3 id="shi-yao-shi-juan-ji" tabindex="-1" id="什么是卷积">什么是卷积</h3><p>卷积是一种数学运算，使用一个小矩阵（<strong>卷积核/滤波器，Kernel/Filter</strong>）在输入数据上滑动，在每个位置计算加权和。</p><p><strong>1D 卷积</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">输入：  [1, 2, 3, 4, 5, 6, 7]</span><br><span class="line">卷积核：[1, 2, 1]</span><br><span class="line">输出：  [_, 8, 12, 16, 20, 24, _]</span><br><span class="line"></span><br><span class="line">计算 Output[3]：</span><br><span class="line">= Input[2]*Kernel[0] + Input[3]*Kernel[1] + Input[4]*Kernel[2]</span><br><span class="line">= 3*1 + 4*2 + 5*1 = 12</span><br></pre></td></tr></table></figure><p><strong>2D 卷积</strong>（图像处理常用）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">输入图像                    卷积核 (3×3)</span><br><span class="line">┌───────────────┐           ┌───────┐</span><br><span class="line">│ 1 2 3 4 5     │           │ 1 0 1 │</span><br><span class="line">│ 5 6 7 8 9     │     *     │ 0 1 0 │</span><br><span class="line">│ 9 0 1 2 3     │           │ 1 0 1 │</span><br><span class="line">│ 4 5 6 7 8     │           └───────┘</span><br><span class="line">└───────────────┘</span><br></pre></td></tr></table></figure><h3 id="juan-ji-de-ying-yong" tabindex="-1" id="卷积的应用">卷积的应用</h3><p>卷积无处不在：</p><table><thead><tr><th>领域</th><th>应用</th><th>示例</th></tr></thead><tbody><tr><td>图像处理</td><td>边缘检测、模糊、锐化</td><td>Sobel、Gaussian Blur</td></tr><tr><td>音频处理</td><td>回声、均衡器、降噪</td><td>FIR 滤波器</td></tr><tr><td>深度学习</td><td>特征提取</td><td>CNN 的核心操作</td></tr><tr><td>物理仿真</td><td>扩散方程、有限差分</td><td>热传导、波动方程</td></tr></tbody></table><h3 id="juan-ji-de-shu-xue-ding-yi" tabindex="-1" id="卷积的数学定义">卷积的数学定义</h3><p><strong>1D 离散卷积</strong>：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>O</mi><mi>u</mi><mi>t</mi><mi>p</mi><mi>u</mi><mi>t</mi><mo stretchy="false">[</mo><mi>i</mi><mo stretchy="false">]</mo><mo>=</mo><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mo>−</mo><mi>r</mi></mrow><mi>r</mi></munderover><mi>I</mi><mi>n</mi><mi>p</mi><mi>u</mi><mi>t</mi><mo stretchy="false">[</mo><mi>i</mi><mo>+</mo><mi>j</mi><mo stretchy="false">]</mo><mo>×</mo><mi>K</mi><mi>e</mi><mi>r</mi><mi>n</mi><mi>e</mi><mi>l</mi><mo stretchy="false">[</mo><mi>j</mi><mo>+</mo><mi>r</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">Output[i] = \sum_{j=-r}^{r} Input[i+j] \times Kernel[j+r]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mord mathnormal">u</span><span class="mord mathnormal">tp</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mopen">[</span><span class="mord mathnormal">i</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.0652em;vertical-align:-1.4138em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6514em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4138em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal">n</span><span class="mord mathnormal">p</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mopen">[</span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">Ker</span><span class="mord mathnormal">n</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mclose">]</span></span></span></span></span></p><p>其中 r 是卷积核的&quot;半径&quot;，卷积核大小为 2r+1。</p><p><strong>2D 离散卷积</strong>：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>O</mi><mi>u</mi><mi>t</mi><mi>p</mi><mi>u</mi><mi>t</mi><mo stretchy="false">[</mo><mi>y</mi><mo stretchy="false">]</mo><mo stretchy="false">[</mo><mi>x</mi><mo stretchy="false">]</mo><mo>=</mo><munderover><mo>∑</mo><mrow><mi>d</mi><mi>y</mi><mo>=</mo><mo>−</mo><mi>r</mi></mrow><mi>r</mi></munderover><munderover><mo>∑</mo><mrow><mi>d</mi><mi>x</mi><mo>=</mo><mo>−</mo><mi>r</mi></mrow><mi>r</mi></munderover><mi>I</mi><mi>n</mi><mi>p</mi><mi>u</mi><mi>t</mi><mo stretchy="false">[</mo><mi>y</mi><mo>+</mo><mi>d</mi><mi>y</mi><mo stretchy="false">]</mo><mo stretchy="false">[</mo><mi>x</mi><mo>+</mo><mi>d</mi><mi>x</mi><mo stretchy="false">]</mo><mo>×</mo><mi>K</mi><mi>e</mi><mi>r</mi><mi>n</mi><mi>e</mi><mi>l</mi><mo stretchy="false">[</mo><mi>d</mi><mi>y</mi><mo>+</mo><mi>r</mi><mo stretchy="false">]</mo><mo stretchy="false">[</mo><mi>d</mi><mi>x</mi><mo>+</mo><mi>r</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">Output[y][x] = \sum_{dy=-r}^{r} \sum_{dx=-r}^{r} Input[y+dy][x+dx] \times Kernel[dy+r][dx+r]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mord mathnormal">u</span><span class="mord mathnormal">tp</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">]</span><span class="mopen">[</span><span class="mord mathnormal">x</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.0896em;vertical-align:-1.4382em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6514em;"><span style="top:-1.8479em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="mrel mtight">=</span><span class="mord mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4382em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6514em;"><span style="top:-1.8479em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">x</span><span class="mrel mtight">=</span><span class="mord mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3604em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal">n</span><span class="mord mathnormal">p</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">]</span><span class="mopen">[</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">x</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">Ker</span><span class="mord mathnormal">n</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mopen">[</span><span class="mord mathnormal">d</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mclose">]</span><span class="mopen">[</span><span class="mord mathnormal">d</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mclose">]</span></span></span></span></span></p><h3 id="bian-jie-chu-li" tabindex="-1" id="边界处理">边界处理</h3><p>当卷积窗口超出输入边界时，有几种处理策略：</p><p><strong>1. 零填充（Zero Padding）</strong>：边界外的元素视为 0</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Padding 前：[1, 2, 3, 4, 5]</span><br><span class="line">Padding 后：[0, 0, 1, 2, 3, 4, 5, 0, 0]</span><br></pre></td></tr></table></figure><p><strong>2. 复制填充（Replicate Padding）</strong>：用边界值填充</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Padding 后：[1, 1, 1, 2, 3, 4, 5, 5, 5]</span><br></pre></td></tr></table></figure><p><strong>3. 镜像填充（Reflect Padding）</strong>：镜像边界元素</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Padding 后：[3, 2, 1, 2, 3, 4, 5, 4, 3]</span><br></pre></td></tr></table></figure><p>在 CUDA 实现中，零填充最简单——只需在边界判断时返回 0。</p><h2 id="po-su-1-d-juan-ji-shi-xian" tabindex="-1" id="朴素-1D-卷积实现">朴素 1D 卷积实现</h2><h3 id="ji-ben-si-lu" tabindex="-1" id="基本思路">基本思路</h3><p>每个线程负责计算一个输出元素：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">__global__ void conv1d_basic(float *input, float *kernel, float *output,</span><br><span class="line">                              int n, int kernel_size) &#123;</span><br><span class="line">    int i = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    int r = kernel_size / 2;  // 卷积核半径</span><br><span class="line">    </span><br><span class="line">    if (i &lt; n) &#123;</span><br><span class="line">        float sum = 0.0f;</span><br><span class="line">        for (int j = -r; j &lt;= r; j++) &#123;</span><br><span class="line">            int idx = i + j;</span><br><span class="line">            if (idx &gt;= 0 &amp;&amp; idx &lt; n) &#123;</span><br><span class="line">                sum += input[idx] * kernel[j + r];</span><br><span class="line">            &#125;</span><br><span class="line">            // 边界外隐式为 0（零填充）</span><br><span class="line">        &#125;</span><br><span class="line">        output[i] = sum;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="xing-neng-wen-ti" tabindex="-1" id="性能问题">性能问题</h3><p>这个朴素实现有两个瓶颈：</p><p><strong>1. 卷积核重复读取</strong></p><p>每个线程都要读取整个卷积核。如果有 10 万个线程，卷积核就被读取 10 万次。但卷积核对所有线程是相同的！</p><p><strong>2. 输入数据重复读取</strong></p><p>相邻线程的卷积窗口高度重叠：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">线程 i   读取：input[i-1], input[i], input[i+1]</span><br><span class="line">线程 i+1 读取：input[i], input[i+1], input[i+2]</span><br><span class="line">                ↑ 共享元素</span><br></pre></td></tr></table></figure><p>卷积核大小为 2r+1 时，每个输入元素平均被读取 2r+1 次。</p><h2 id="chang-liang-nei-cun-you-hua" tabindex="-1" id="常量内存优化">常量内存优化</h2><h3 id="chang-liang-nei-cun-te-xing" tabindex="-1" id="常量内存特性">常量内存特性</h3><p>第五章提过常量内存，这里深入讲解：</p><p><strong>硬件结构</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">┌──────────────────────────────────────┐</span><br><span class="line">│           常量内存 (64 KB)            │</span><br><span class="line">│           Device DRAM                │</span><br><span class="line">└──────────────┬───────────────────────┘</span><br><span class="line">               │ 广播</span><br><span class="line">┌──────────────┴───────────────────────┐</span><br><span class="line">│        常量缓存 (每 SM ~8 KB)         │</span><br><span class="line">│           On-chip Cache              │</span><br><span class="line">└──────────────┬───────────────────────┘</span><br><span class="line">               │ 极低延迟</span><br><span class="line">               ↓</span><br><span class="line">         Warp 中的线程</span><br></pre></td></tr></table></figure><p><strong>特点</strong>：</p><ol><li><strong>只读</strong>：Kernel 执行期间不能修改</li><li><strong>缓存优化</strong>：有专用缓存，命中时延迟极低</li><li><strong>广播高效</strong>：同一 Warp 读相同地址时，只需一次访问</li></ol><p><strong>为什么适合卷积核</strong>：</p><ul><li>卷积核对所有线程都是相同的常量</li><li>每次卷积操作，所有线程都读相同的 kernel[j]</li><li>完美匹配常量内存的&quot;广播&quot;特性</li></ul><h3 id="shi-yong-chang-liang-nei-cun" tabindex="-1" id="使用常量内存">使用常量内存</h3><p><strong>声明</strong>（全局作用域）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#define MAX_KERNEL_SIZE 1025</span><br><span class="line">__constant__ float d_kernel[MAX_KERNEL_SIZE];</span><br></pre></td></tr></table></figure><p><strong>Host 端初始化</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">float h_kernel[kernel_size];</span><br><span class="line">// ... 填充卷积核数据 ...</span><br><span class="line"></span><br><span class="line">cudaMemcpyToSymbol(d_kernel, h_kernel, kernel_size * sizeof(float));</span><br></pre></td></tr></table></figure><p><strong>Kernel 中使用</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">__global__ void conv1d_const(float *input, float *output, </span><br><span class="line">                              int n, int kernel_size) &#123;</span><br><span class="line">    int i = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    int r = kernel_size / 2;</span><br><span class="line">    </span><br><span class="line">    if (i &lt; n) &#123;</span><br><span class="line">        float sum = 0.0f;</span><br><span class="line">        for (int j = -r; j &lt;= r; j++) &#123;</span><br><span class="line">            int idx = i + j;</span><br><span class="line">            if (idx &gt;= 0 &amp;&amp; idx &lt; n) &#123;</span><br><span class="line">                sum += input[idx] * d_kernel[j + r];  // 直接使用</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        output[i] = sum;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="xing-neng-ti-sheng" tabindex="-1" id="性能提升">性能提升</h3><p>常量内存解决了<strong>卷积核重复读取</strong>的问题：</p><table><thead><tr><th>版本</th><th>卷积核读取</th><th>带宽消耗</th></tr></thead><tbody><tr><td>朴素</td><td>N×K 次</td><td>高</td></tr><tr><td>常量内存</td><td>K 次 + 缓存</td><td>极低（广播）</td></tr></tbody></table><p>其中 N 是输出元素数，K 是卷积核大小。</p><p>但输入数据的重复读取问题还没解决——这需要 Tiling。</p><h2 id="tiled-juan-ji" tabindex="-1" id="Tiled-卷积">Tiled 卷积</h2><h3 id="wei-shi-yao-xu-yao-tiling" tabindex="-1" id="为什么需要-Tiling">为什么需要 Tiling</h3><p>回顾输入数据访问模式：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Block 内的线程访问：</span><br><span class="line">线程 0:   input[0], input[1], ..., input[k-1]</span><br><span class="line">线程 1:   input[1], input[2], ..., input[k]</span><br><span class="line">...</span><br><span class="line">线程 255: input[255], input[256], ..., input[255+k-1]</span><br></pre></td></tr></table></figure><p>Block 内的线程访问范围是连续的，有大量重叠。把这部分数据加载到共享内存，就能避免重复的全局内存访问。</p><h3 id="shu-ru-tile-she-ji" tabindex="-1" id="输入-Tile-设计">输入 Tile 设计</h3><p>关键问题：<strong>一个 Block 的线程需要多大的输入 Tile？</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Block 大小：BLOCK_SIZE</span><br><span class="line">卷积核半径：r</span><br><span class="line">卷积核大小：2r + 1</span><br><span class="line"></span><br><span class="line">输出范围：[block_start, block_start + BLOCK_SIZE - 1]</span><br><span class="line">输入范围：[block_start - r, block_start + BLOCK_SIZE - 1 + r]</span><br><span class="line">         = block_start - r, block_start + BLOCK_SIZE + r - 1]</span><br><span class="line"></span><br><span class="line">输入 Tile 大小 = BLOCK_SIZE + 2r</span><br></pre></td></tr></table></figure><p>也就是说，要计算 BLOCK_SIZE 个输出，需要读取 BLOCK_SIZE + 2r 个输入元素。</p><h3 id="halo-yuan-su" tabindex="-1" id="Halo-元素">Halo 元素</h3><p>输入 Tile 比输出 Tile 大，多出来的部分叫做 <strong>Halo（光晕）元素</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">                    Halo                 主体                  Halo</span><br><span class="line">            ┌────────────────┬─────────────────────────┬────────────────┐</span><br><span class="line">输入 Tile:  │ r 个元素       │ BLOCK_SIZE 个元素        │ r 个元素       │</span><br><span class="line">            └────────────────┴─────────────────────────┴────────────────┘</span><br><span class="line">                    ↑                                           ↑</span><br><span class="line">                左 Halo                                      右 Halo</span><br></pre></td></tr></table></figure><p>Halo 元素是相邻 Block 边界的重叠部分，也叫 <strong>Ghost Cells</strong>。</p><h3 id="shi-xian-ce-lue" tabindex="-1" id="实现策略">实现策略</h3><p>有两种加载方式：</p><p><strong>策略 1：统一加载</strong></p><p>所有元素由 BLOCK_SIZE 个线程分工加载，每线程可能加载多个元素：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">__shared__ float tile[BLOCK_SIZE + 2 * MAX_R];</span><br><span class="line"></span><br><span class="line">int tile_size = BLOCK_SIZE + 2 * r;</span><br><span class="line">int loads_per_thread = (tile_size + BLOCK_SIZE - 1) / BLOCK_SIZE;</span><br><span class="line"></span><br><span class="line">for (int i = 0; i &lt; loads_per_thread; i++) &#123;</span><br><span class="line">    int tile_idx = threadIdx.x + i * BLOCK_SIZE;</span><br><span class="line">    if (tile_idx &lt; tile_size) &#123;</span><br><span class="line">        int global_idx = block_start - r + tile_idx;</span><br><span class="line">        tile[tile_idx] = (global_idx &gt;= 0 &amp;&amp; global_idx &lt; n) ? </span><br><span class="line">                          input[global_idx] : 0.0f;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>策略 2：分区加载（更高效）</strong></p><p>左 Halo、主体、右 Halo 分别由不同线程加载：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">__shared__ float tile[BLOCK_SIZE + 2 * MAX_R];</span><br><span class="line"></span><br><span class="line">int halo_left = r;</span><br><span class="line">int block_start = blockIdx.x * BLOCK_SIZE;</span><br><span class="line"></span><br><span class="line">// 左 Halo：前 r 个线程负责</span><br><span class="line">if (threadIdx.x &lt; r) &#123;</span><br><span class="line">    int idx = block_start - r + threadIdx.x;</span><br><span class="line">    tile[threadIdx.x] = (idx &gt;= 0) ? input[idx] : 0.0f;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 主体：所有线程各负责一个</span><br><span class="line">int main_idx = block_start + threadIdx.x;</span><br><span class="line">tile[r + threadIdx.x] = (main_idx &lt; n) ? input[main_idx] : 0.0f;</span><br><span class="line"></span><br><span class="line">// 右 Halo：前 r 个线程负责</span><br><span class="line">if (threadIdx.x &lt; r) &#123;</span><br><span class="line">    int idx = block_start + BLOCK_SIZE + threadIdx.x;</span><br><span class="line">    tile[BLOCK_SIZE + r + threadIdx.x] = (idx &lt; n) ? input[idx] : 0.0f;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">__syncthreads();</span><br></pre></td></tr></table></figure><h3 id="wan-zheng-de-tiled-1-d-juan-ji" tabindex="-1" id="完整的-Tiled-1D-卷积">完整的 Tiled 1D 卷积</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">#define BLOCK_SIZE 256</span><br><span class="line">#define MAX_R 512</span><br><span class="line"></span><br><span class="line">__constant__ float d_kernel[2 * MAX_R + 1];</span><br><span class="line"></span><br><span class="line">__global__ void conv1d_tiled(float *input, float *output, </span><br><span class="line">                              int n, int r) &#123;</span><br><span class="line">    // 共享内存 Tile</span><br><span class="line">    __shared__ float tile[BLOCK_SIZE + 2 * MAX_R];</span><br><span class="line">    </span><br><span class="line">    int block_start = blockIdx.x * BLOCK_SIZE;</span><br><span class="line">    int global_idx = block_start + threadIdx.x;</span><br><span class="line">    </span><br><span class="line">    // ========== 协作加载 ==========</span><br><span class="line">    </span><br><span class="line">    // 左 Halo</span><br><span class="line">    if (threadIdx.x &lt; r) &#123;</span><br><span class="line">        int idx = block_start - r + threadIdx.x;</span><br><span class="line">        tile[threadIdx.x] = (idx &gt;= 0) ? input[idx] : 0.0f;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    // 主体元素</span><br><span class="line">    tile[r + threadIdx.x] = (global_idx &lt; n) ? input[global_idx] : 0.0f;</span><br><span class="line">    </span><br><span class="line">    // 右 Halo</span><br><span class="line">    if (threadIdx.x &lt; r) &#123;</span><br><span class="line">        int idx = block_start + BLOCK_SIZE + threadIdx.x;</span><br><span class="line">        tile[BLOCK_SIZE + r + threadIdx.x] = (idx &lt; n) ? input[idx] : 0.0f;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    // ========== 计算卷积 ==========</span><br><span class="line">    </span><br><span class="line">    if (global_idx &lt; n) &#123;</span><br><span class="line">        float sum = 0.0f;</span><br><span class="line">        for (int j = 0; j &lt; 2 * r + 1; j++) &#123;</span><br><span class="line">            sum += tile[threadIdx.x + j] * d_kernel[j];</span><br><span class="line">        &#125;</span><br><span class="line">        output[global_idx] = sum;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="xing-neng-fen-xi" tabindex="-1" id="性能分析">性能分析</h3><p><strong>全局内存访问</strong>：</p><table><thead><tr><th>版本</th><th>每元素读取次数</th><th>总读取量</th></tr></thead><tbody><tr><td>朴素</td><td>2r + 1</td><td>N × (2r + 1)</td></tr><tr><td>Tiled</td><td>1 + 2r/BLOCK_SIZE</td><td>N × (1 + 2r/B)</td></tr></tbody></table><p>当 BLOCK_SIZE = 256, r = 5 时：</p><ul><li>朴素：每元素 11 次</li><li>Tiled：每元素 1.04 次</li></ul><p>全局内存访问减少约 <strong>10 倍</strong>！</p><h2 id="2-d-juan-ji" tabindex="-1" id="2D-卷积">2D 卷积</h2><h3 id="kuo-zhan-dao-er-wei" tabindex="-1" id="扩展到二维">扩展到二维</h3><p>2D 卷积更常见，思路类似但更复杂：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入 Tile 大小：(BLOCK_Y + 2ry) × (BLOCK_X + 2rx)</span><br><span class="line">Halo 元素在四个边和四个角</span><br></pre></td></tr></table></figure><h3 id="2-d-tile-jie-gou" tabindex="-1" id="2D-Tile-结构">2D Tile 结构</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">┌─────────────┬───────────────────────────┬─────────────┐</span><br><span class="line">│  左上角     │        上 Halo            │  右上角     │</span><br><span class="line">│  (ry×rx)    │      (ry×BLOCK_X)         │  (ry×rx)    │</span><br><span class="line">├─────────────┼───────────────────────────┼─────────────┤</span><br><span class="line">│             │                           │             │</span><br><span class="line">│  左 Halo    │       主体                │  右 Halo    │</span><br><span class="line">│ (BLOCK_Y×rx)│   (BLOCK_Y×BLOCK_X)       │(BLOCK_Y×rx) │</span><br><span class="line">│             │                           │             │</span><br><span class="line">├─────────────┼───────────────────────────┼─────────────┤</span><br><span class="line">│  左下角     │        下 Halo            │  右下角     │</span><br><span class="line">│  (ry×rx)    │      (ry×BLOCK_X)         │  (ry×rx)    │</span><br><span class="line">└─────────────┴───────────────────────────┴─────────────┘</span><br></pre></td></tr></table></figure><h3 id="jian-hua-de-2-d-shi-xian" tabindex="-1" id="简化的-2D-实现">简化的 2D 实现</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line">#define TILE_X 16</span><br><span class="line">#define TILE_Y 16</span><br><span class="line">#define R 1  // 3×3 卷积核的半径</span><br><span class="line"></span><br><span class="line">__constant__ float d_kernel2d[(2*R+1) * (2*R+1)];</span><br><span class="line"></span><br><span class="line">__global__ void conv2d_tiled(float *input, float *output,</span><br><span class="line">                              int width, int height) &#123;</span><br><span class="line">    // 共享内存</span><br><span class="line">    __shared__ float tile[TILE_Y + 2*R][TILE_X + 2*R];</span><br><span class="line">    </span><br><span class="line">    int tx = threadIdx.x, ty = threadIdx.y;</span><br><span class="line">    int bx = blockIdx.x * TILE_X, by = blockIdx.y * TILE_Y;</span><br><span class="line">    int gx = bx + tx, gy = by + ty;</span><br><span class="line">    </span><br><span class="line">    // ========== 加载主体 ==========</span><br><span class="line">    int tile_x = tx + R, tile_y = ty + R;</span><br><span class="line">    tile[tile_y][tile_x] = (gx &lt; width &amp;&amp; gy &lt; height) ? </span><br><span class="line">                            input[gy * width + gx] : 0.0f;</span><br><span class="line">    </span><br><span class="line">    // ========== 加载 Halo（边界线程负责）==========</span><br><span class="line">    </span><br><span class="line">    // 上边界</span><br><span class="line">    if (ty &lt; R) &#123;</span><br><span class="line">        int src_y = gy - R;</span><br><span class="line">        tile[ty][tile_x] = (gx &lt; width &amp;&amp; src_y &gt;= 0) ? </span><br><span class="line">                            input[src_y * width + gx] : 0.0f;</span><br><span class="line">    &#125;</span><br><span class="line">    // 下边界</span><br><span class="line">    if (ty &gt;= TILE_Y - R) &#123;</span><br><span class="line">        int src_y = gy + R;</span><br><span class="line">        tile[tile_y + R][tile_x] = (gx &lt; width &amp;&amp; src_y &lt; height) ? </span><br><span class="line">                                    input[src_y * width + gx] : 0.0f;</span><br><span class="line">    &#125;</span><br><span class="line">    // 左边界</span><br><span class="line">    if (tx &lt; R) &#123;</span><br><span class="line">        int src_x = gx - R;</span><br><span class="line">        tile[tile_y][tx] = (src_x &gt;= 0 &amp;&amp; gy &lt; height) ? </span><br><span class="line">                            input[gy * width + src_x] : 0.0f;</span><br><span class="line">    &#125;</span><br><span class="line">    // 右边界</span><br><span class="line">    if (tx &gt;= TILE_X - R) &#123;</span><br><span class="line">        int src_x = gx + R;</span><br><span class="line">        tile[tile_y][tile_x + R] = (src_x &lt; width &amp;&amp; gy &lt; height) ? </span><br><span class="line">                                    input[gy * width + src_x] : 0.0f;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    // 四个角（角落线程负责）</span><br><span class="line">    if (tx &lt; R &amp;&amp; ty &lt; R) &#123;  // 左上</span><br><span class="line">        int sx = gx - R, sy = gy - R;</span><br><span class="line">        tile[ty][tx] = (sx &gt;= 0 &amp;&amp; sy &gt;= 0) ? input[sy * width + sx] : 0.0f;</span><br><span class="line">    &#125;</span><br><span class="line">    if (tx &gt;= TILE_X - R &amp;&amp; ty &lt; R) &#123;  // 右上</span><br><span class="line">        int sx = gx + R, sy = gy - R;</span><br><span class="line">        tile[ty][tile_x + R] = (sx &lt; width &amp;&amp; sy &gt;= 0) ? </span><br><span class="line">                                input[sy * width + sx] : 0.0f;</span><br><span class="line">    &#125;</span><br><span class="line">    if (tx &lt; R &amp;&amp; ty &gt;= TILE_Y - R) &#123;  // 左下</span><br><span class="line">        int sx = gx - R, sy = gy + R;</span><br><span class="line">        tile[tile_y + R][tx] = (sx &gt;= 0 &amp;&amp; sy &lt; height) ? </span><br><span class="line">                                input[sy * width + sx] : 0.0f;</span><br><span class="line">    &#125;</span><br><span class="line">    if (tx &gt;= TILE_X - R &amp;&amp; ty &gt;= TILE_Y - R) &#123;  // 右下</span><br><span class="line">        int sx = gx + R, sy = gy + R;</span><br><span class="line">        tile[tile_y + R][tile_x + R] = (sx &lt; width &amp;&amp; sy &lt; height) ?</span><br><span class="line">                                        input[sy * width + sx] : 0.0f;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    // ========== 计算卷积 ==========</span><br><span class="line">    if (gx &lt; width &amp;&amp; gy &lt; height) &#123;</span><br><span class="line">        float sum = 0.0f;</span><br><span class="line">        for (int dy = -R; dy &lt;= R; dy++) &#123;</span><br><span class="line">            for (int dx = -R; dx &lt;= R; dx++) &#123;</span><br><span class="line">                sum += tile[ty + R + dy][tx + R + dx] * </span><br><span class="line">                       d_kernel2d[(dy + R) * (2*R + 1) + (dx + R)];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        output[gy * width + gx] = sum;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="qi-dong-pei-zhi" tabindex="-1" id="启动配置">启动配置</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dim3 block(TILE_X, TILE_Y);  // 16×16 = 256 线程</span><br><span class="line">dim3 grid((width + TILE_X - 1) / TILE_X, </span><br><span class="line">          (height + TILE_Y - 1) / TILE_Y);</span><br><span class="line"></span><br><span class="line">conv2d_tiled&lt;&lt;&lt;grid, block&gt;&gt;&gt;(d_input, d_output, width, height);</span><br></pre></td></tr></table></figure><h2 id="huan-cun-ji-zhi" tabindex="-1" id="缓存机制">缓存机制</h2><h3 id="l-1-l-2-huan-cun-yu-tiling-de-guan-xi" tabindex="-1" id="L1-L2-缓存与-Tiling-的关系">L1/L2 缓存与 Tiling 的关系</h3><p>前面我们手动用共享内存实现了 Tiling。但 GPU 还有自动的缓存机制：</p><p><strong>L1 缓存</strong>（每 SM）：</p><ul><li>Ampere 架构：128 KB（可配置与共享内存分割）</li><li>自动缓存全局内存访问</li><li>对于小卷积核，可能&quot;免费&quot;获得数据复用</li></ul><p><strong>L2 缓存</strong>（全局共享）：</p><ul><li>几 MB 容量</li><li>所有 SM 共享</li><li>跨 Block 的数据访问可能命中</li></ul><h3 id="he-shi-yi-lai-huan-cun-vs-xian-shi-tiling" tabindex="-1" id="何时依赖缓存-vs-显式-Tiling">何时依赖缓存 vs 显式 Tiling</h3><table><thead><tr><th>场景</th><th>推荐方式</th><th>原因</th></tr></thead><tbody><tr><td>小卷积核（3×3）</td><td>可能只用缓存</td><td>L1 够用，代码简单</td></tr><tr><td>大卷积核（11×11+）</td><td>显式 Tiling</td><td>数据量大，需精确控制</td></tr><tr><td>大图像、小 kernel</td><td>显式 Tiling</td><td>最大化内存带宽利用</td></tr><tr><td>调试/原型</td><td>先用缓存</td><td>快速验证正确性</td></tr></tbody></table><h3 id="xian-dai-gpu-de-you-hua-jian-yi" tabindex="-1" id="现代-GPU-的优化建议">现代 GPU 的优化建议</h3><ol><li><strong>先写简单版本</strong>，依赖 L1/L2 缓存</li><li><strong>用 Nsight Compute 分析</strong>，看内存吞吐是否成为瓶颈</li><li><strong>如果受限于内存带宽</strong>，再添加共享内存 Tiling</li><li><strong>常量内存始终是好选择</strong>（对于卷积核）</li></ol><h2 id="juan-ji-you-hua-zong-jie" tabindex="-1" id="卷积优化总结">卷积优化总结</h2><h3 id="you-hua-shou-duan-ceng-ci" tabindex="-1" id="优化手段层次">优化手段层次</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">┌─────────────────────────────────────────────────────────────────┐</span><br><span class="line">│ Level 4: 算法级优化                                              │</span><br><span class="line">│   - FFT 卷积（大卷积核）                                          │</span><br><span class="line">│   - Winograd 算法（特定尺寸）                                     │</span><br><span class="line">│   - Im2col + GEMM（cuDNN 方式）                                   │</span><br><span class="line">├─────────────────────────────────────────────────────────────────┤</span><br><span class="line">│ Level 3: 数据复用                                                 │</span><br><span class="line">│   - 共享内存 Tiling                                               │</span><br><span class="line">│   - 常量内存存储卷积核                                            │</span><br><span class="line">│   - 寄存器缓存局部结果                                            │</span><br><span class="line">├─────────────────────────────────────────────────────────────────┤</span><br><span class="line">│ Level 2: 内存访问模式                                             │</span><br><span class="line">│   - 合并访问全局内存                                              │</span><br><span class="line">│   - 避免 Bank 冲突                                                │</span><br><span class="line">│   - 预取和双缓冲                                                  │</span><br><span class="line">├─────────────────────────────────────────────────────────────────┤</span><br><span class="line">│ Level 1: 基础正确实现                                             │</span><br><span class="line">│   - 边界检查                                                      │</span><br><span class="line">│   - 正确的索引计算                                                 │</span><br><span class="line">└─────────────────────────────────────────────────────────────────┘</span><br></pre></td></tr></table></figure><h3 id="xuan-ze-ce-lue" tabindex="-1" id="选择策略">选择策略</h3><table><thead><tr><th>卷积核大小</th><th>推荐方法</th></tr></thead><tbody><tr><td>3×3</td><td>Tiled + 常量内存</td></tr><tr><td>5×5 ~ 11×11</td><td>Tiled + 常量内存</td></tr><tr><td>大于 11×11</td><td>考虑 FFT 或 cuDNN</td></tr></tbody></table><h3 id="cu-dnn-gong-ye-ji-xuan-ze" tabindex="-1" id="cuDNN：工业级选择">cuDNN：工业级选择</h3><p>实际生产中，卷积通常用 cuDNN：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cudnnConvolutionForward</span>(handle,</span><br><span class="line">    &amp;alpha,</span><br><span class="line">    inputDesc, d_input,</span><br><span class="line">    filterDesc, d_filter,</span><br><span class="line">    convDesc,</span><br><span class="line">    algo,  <span class="comment">// 自动选择最优算法</span></span><br><span class="line">    workspace, workspaceSize,</span><br><span class="line">    &amp;beta,</span><br><span class="line">    outputDesc, d_output);</span><br></pre></td></tr></table></figure><p>cuDNN 会根据输入尺寸、卷积核大小、GPU 架构，自动选择最优实现（直接卷积、FFT、Winograd、Im2col+GEMM 等）。</p><p>但理解底层原理仍然重要——知道 cuDNN 在做什么，才能正确调用和调优。</p><h2 id="shi-zhan-tu-xiang-rui-hua" tabindex="-1" id="实战：图像锐化">实战：图像锐化</h2><h3 id="rui-hua-juan-ji-he" tabindex="-1" id="锐化卷积核">锐化卷积核</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">┌─────┬─────┬─────┐</span><br><span class="line">│  0  │ -1  │  0  │</span><br><span class="line">├─────┼─────┼─────┤</span><br><span class="line">│ -1  │  5  │ -1  │</span><br><span class="line">├─────┼─────┼─────┤</span><br><span class="line">│  0  │ -1  │  0  │</span><br><span class="line">└─────┴─────┴─────┘</span><br></pre></td></tr></table></figure><h3 id="wan-zheng-shi-li" tabindex="-1" id="完整示例">完整示例</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;cuda_runtime.h&gt;</span><br><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line"></span><br><span class="line">#define TILE_SIZE 16</span><br><span class="line">#define R 1</span><br><span class="line"></span><br><span class="line">__constant__ float d_sharpen_kernel[9] = &#123;</span><br><span class="line">    0, -1,  0,</span><br><span class="line">   -1,  5, -1,</span><br><span class="line">    0, -1,  0</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">__global__ void sharpen_image(unsigned char *input, unsigned char *output,</span><br><span class="line">                               int width, int height) &#123;</span><br><span class="line">    __shared__ float tile[TILE_SIZE + 2][TILE_SIZE + 2];</span><br><span class="line">    </span><br><span class="line">    int tx = threadIdx.x, ty = threadIdx.y;</span><br><span class="line">    int gx = blockIdx.x * TILE_SIZE + tx;</span><br><span class="line">    int gy = blockIdx.y * TILE_SIZE + ty;</span><br><span class="line">    </span><br><span class="line">    // 加载（简化版，假设边界内）</span><br><span class="line">    if (gx &lt; width &amp;&amp; gy &lt; height) &#123;</span><br><span class="line">        tile[ty + 1][tx + 1] = (float)input[gy * width + gx];</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        tile[ty + 1][tx + 1] = 0.0f;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    // 加载 Halo（简化，仅示意）</span><br><span class="line">    if (tx == 0 &amp;&amp; gx &gt; 0) </span><br><span class="line">        tile[ty + 1][0] = input[gy * width + gx - 1];</span><br><span class="line">    if (tx == TILE_SIZE - 1 &amp;&amp; gx &lt; width - 1) </span><br><span class="line">        tile[ty + 1][TILE_SIZE + 1] = input[gy * width + gx + 1];</span><br><span class="line">    if (ty == 0 &amp;&amp; gy &gt; 0) </span><br><span class="line">        tile[0][tx + 1] = input[(gy - 1) * width + gx];</span><br><span class="line">    if (ty == TILE_SIZE - 1 &amp;&amp; gy &lt; height - 1) </span><br><span class="line">        tile[TILE_SIZE + 1][tx + 1] = input[(gy + 1) * width + gx];</span><br><span class="line">    </span><br><span class="line">    // 角落处理省略...</span><br><span class="line">    </span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    // 卷积计算</span><br><span class="line">    if (gx &lt; width &amp;&amp; gy &lt; height) &#123;</span><br><span class="line">        float sum = 0.0f;</span><br><span class="line">        for (int dy = -1; dy &lt;= 1; dy++) &#123;</span><br><span class="line">            for (int dx = -1; dx &lt;= 1; dx++) &#123;</span><br><span class="line">                sum += tile[ty + 1 + dy][tx + 1 + dx] * </span><br><span class="line">                       d_sharpen_kernel[(dy + 1) * 3 + (dx + 1)];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        // 钳制到 [0, 255]</span><br><span class="line">        sum = fminf(fmaxf(sum, 0.0f), 255.0f);</span><br><span class="line">        output[gy * width + gx] = (unsigned char)sum;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="1-d-vs-2-d-juan-ji-de-ke-fen-chi-xing" tabindex="-1" id="1D-vs-2D-卷积的可分离性">1D vs 2D 卷积的可分离性</h2><h3 id="ke-fen-chi-juan-ji" tabindex="-1" id="可分离卷积">可分离卷积</h3><p>有些 2D 卷积核可以分解为两个 1D 卷积核的外积：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">                       ┌───┐   ┌─────────────┐</span><br><span class="line">┌───────────┐          │ 1 │   │             │</span><br><span class="line">│ 1  4  6  4  1 │      │ 4 │ × │ 1 4 6 4 1   │</span><br><span class="line">│ 4 16 24 16 4 │  =    │ 6 │   │             │</span><br><span class="line">│ 6 24 36 24 6 │       │ 4 │   │             │</span><br><span class="line">│ 4 16 24 16 4 │       │ 1 │   │             │</span><br><span class="line">│ 1  4  6  4  1 │      └───┘   └─────────────┘</span><br><span class="line">└───────────┘        垂直 1D     水平 1D</span><br><span class="line">   5×5 高斯</span><br></pre></td></tr></table></figure><h3 id="ke-fen-chi-juan-ji-de-you-shi" tabindex="-1" id="可分离卷积的优势">可分离卷积的优势</h3><p>原始 2D：每像素 5×5 = 25 次乘法<br>可分离：每像素 5 + 5 = 10 次乘法</p><p><strong>计算量减少 60%！</strong></p><h3 id="cuda-shi-xian-si-lu" tabindex="-1" id="CUDA-实现思路">CUDA 实现思路</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">// 第一步：水平卷积（每行）</span><br><span class="line">conv1d_horizontal&lt;&lt;&lt;gridH, blockH&gt;&gt;&gt;(input, temp, width, height, kernel_h);</span><br><span class="line"></span><br><span class="line">// 第二步：垂直卷积（每列）</span><br><span class="line">conv1d_vertical&lt;&lt;&lt;gridV, blockV&gt;&gt;&gt;(temp, output, width, height, kernel_v);</span><br></pre></td></tr></table></figure><p>常见的高斯模糊、盒状模糊都是可分离的，这是实际优化中的重要技巧。</p><h2 id="xiao-jie" tabindex="-1" id="小结">小结</h2><p>第七章围绕卷积，整合了多项内存优化技术：</p><p><strong>常量内存</strong>：卷积核对所有线程相同，放常量内存是自然选择。广播访问让带宽消耗趋近于零。</p><p><strong>Tiled 共享内存</strong>：输入数据有大量重叠访问。用共享内存缓存 Tile，全局内存访问降低到接近 1 次/元素。</p><p><strong>Halo 处理</strong>：2D Tiling 的关键难点。边界、角落需要细心处理。建议分区加载——不同区域由不同线程负责。</p><p><strong>缓存利用</strong>：现代 GPU 的 L1/L2 缓存能自动覆盖部分数据复用。小卷积核、调试阶段可以依赖缓存，正式优化再加 Tiling。</p><p><strong>可分离卷积</strong>：高斯等可分离核，分解成两次 1D 卷积，计算量直接减半。</p><p>卷积是深度学习和图像处理的核心算子，优化卷积的思路——常量内存、Tiling、Halo 处理——适用于很多相似的模板计算模式。下一章会学习另一个重要模式——Stencil（模板计算），思路类似但有自己的特点。</p><hr><h2 id="xia-yi-bu" tabindex="-1" id="🚀-下一步">🚀 下一步</h2><hr><h2 id="can-kao-zi-liao" tabindex="-1" id="📚-参考资料">📚 参考资料</h2><ul><li>PMPP 第四版 Chapter 07</li><li><a href="https://smarter.xin/posts/1c778456/">第七章：卷积</a></li></ul><p><strong>学习愉快！</strong> 🎓</p><hr><blockquote><p><strong>本文 GitHub 仓库</strong>: <a href="https://github.com/psmarter/PMPP-Learning">https://github.com/psmarter/PMPP-Learning</a></p></blockquote>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h2 id=&quot;qian-yan&quot; tabindex=&quot;-1&quot;</summary>
        
      
    
    
    
    <category term="知识分享" scheme="https://smarter.xin/categories/knowledge-sharing/"/>
    
    
    <category term="CUDA" scheme="https://smarter.xin/tags/CUDA/"/>
    
    <category term="GPU编程" scheme="https://smarter.xin/tags/gpu-programming/"/>
    
    <category term="并行计算" scheme="https://smarter.xin/tags/parallel-computing/"/>
    
    <category term="PMPP" scheme="https://smarter.xin/tags/PMPP/"/>
    
    <category term="卷积" scheme="https://smarter.xin/tags/convolution/"/>
    
    <category term="常量内存" scheme="https://smarter.xin/tags/constant-memory/"/>
    
    <category term="Tiling" scheme="https://smarter.xin/tags/Tiling/"/>
    
  </entry>
  
  <entry>
    <title>PMPP-第六章：性能方面的考虑</title>
    <link href="https://smarter.xin/posts/220818c3/"/>
    <id>https://smarter.xin/posts/220818c3/</id>
    <published>2026-01-16T09:11:58.000Z</published>
    <updated>2026-01-24T11:47:21.463Z</updated>
    
    <content type="html"><![CDATA[<h2 id="qian-yan" tabindex="-1" id="前言">前言</h2><p>第五章学习了内存层次和分块（Tiling）技术，矩阵乘法性能提升了10倍。但这只是开始——实际优化中还有很多细节会影响性能。第六章系统梳理这些性能因素：内存合并、分支发散、资源分配、指令吞吐量等。本章内容偏重工程实践，掌握这些技巧，可以让代码性能进一步提升数倍。</p><blockquote><p><strong>📦 配套资源</strong>：本系列文章配有完整的 <a href="https://github.com/psmarter/PMPP-Learning">GitHub 仓库</a>，包含每章的练习题解答、CUDA 代码实现和详细注释。所有代码都经过测试，可以直接运行。</p></blockquote><h2 id="nei-cun-he-bing-memory-coalescing" tabindex="-1" id="内存合并（Memory-Coalescing）">内存合并（Memory Coalescing）</h2><h3 id="quan-ju-nei-cun-de-ying-jian-te-xing" tabindex="-1" id="全局内存的硬件特性">全局内存的硬件特性</h3><p>全局内存（DRAM）不是按单个字节访问的，而是按**事务（Transaction）**批量访问：</p><ul><li>每次事务读取一个<strong>内存段（Memory Segment）</strong></li><li>段大小通常是 32 字节或 128 字节</li><li>段必须对齐（起始地址是段大小的倍数）</li></ul><p>这意味着：读 1 个 float（4 字节）和读 32 个 float（128 字节），如果落在同一个段，硬件开销相同。</p><h3 id="he-bing-fang-wen-de-tiao-jian" tabindex="-1" id="合并访问的条件">合并访问的条件</h3><p>当 Warp 中的 32 个线程访问<strong>连续且对齐</strong>的内存地址时，这些访问可以合并成最少的事务：</p><p><strong>理想情况</strong>：32 线程访问连续 128 字节</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">// 合并访问（1 次 128B 事务）</span><br><span class="line">float val = data[threadIdx.x];</span><br><span class="line">// 线程 0 访问 data[0], 线程 1 访问 data[1], ...</span><br></pre></td></tr></table></figure><p><strong>糟糕情况</strong>：32 线程访问跨步地址</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">// 非合并访问（可能 32 次事务！）</span><br><span class="line">float val = data[threadIdx.x * 32];</span><br><span class="line">// 线程 0 访问 data[0], 线程 1 访问 data[32], ...</span><br><span class="line">// 每个访问落在不同段</span><br></pre></td></tr></table></figure><h3 id="liang-hua-ying-xiang" tabindex="-1" id="量化影响">量化影响</h3><p>假设每次事务延迟相同，合并访问带来的加速：</p><table><thead><tr><th>访问模式</th><th>事务数</th><th>相对带宽</th></tr></thead><tbody><tr><td>完全合并</td><td>1</td><td>100%</td></tr><tr><td>步长 2</td><td>2</td><td>50%</td></tr><tr><td>步长 4</td><td>4</td><td>25%</td></tr><tr><td>步长 32</td><td>32</td><td>3%</td></tr></tbody></table><p>步长越大，带宽利用率越低。</p><h3 id="ju-zhen-fang-wen-mo-shi-de-ying-xiang" tabindex="-1" id="矩阵访问模式的影响">矩阵访问模式的影响</h3><p>考虑行主序矩阵 <code>M[row][col]</code>，一维索引为 <code>M[row * width + col]</code>：</p><p><strong>按行遍历（合并访问）</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">// 同一线程束的线程，row 相同，col 连续</span><br><span class="line">int idx = row * width + threadIdx.x;</span><br><span class="line">float val = M[idx];  // 连续地址，实现合并访问</span><br></pre></td></tr></table></figure><p><strong>按列遍历（非合并访问）</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">// 同一线程束的线程，col 相同，row 连续</span><br><span class="line">int idx = threadIdx.x * width + col;</span><br><span class="line">float val = M[idx];  // 步长 = width，无法合并</span><br></pre></td></tr></table></figure><p>对于 width = 1024 的矩阵，步长为 1024×4 = 4096 字节，远超内存段大小，每个线程访问不同的内存段，无法合并。</p><h3 id="ju-zhen-zhuan-zhi-you-hua" tabindex="-1" id="矩阵转置优化">矩阵转置优化</h3><p>矩阵转置 <code>B[j][i] = A[i][j]</code>，必然有一个矩阵按列访问。解决方案：<strong>用共享内存做中转</strong>。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">__global__ void transposeCoalesced(float *A, float *B, int width) &#123;</span><br><span class="line">    __shared__ float tile[32][33];  // 注意 padding 防 bank 冲突</span><br><span class="line">    </span><br><span class="line">    int x = blockIdx.x * 32 + threadIdx.x;</span><br><span class="line">    int y = blockIdx.y * 32 + threadIdx.y;</span><br><span class="line">    </span><br><span class="line">    // 合并读取 A（按行）</span><br><span class="line">    if (x &lt; width &amp;&amp; y &lt; width)</span><br><span class="line">        tile[threadIdx.y][threadIdx.x] = A[y * width + x];</span><br><span class="line">    </span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    // 交换 block 索引</span><br><span class="line">    x = blockIdx.y * 32 + threadIdx.x;</span><br><span class="line">    y = blockIdx.x * 32 + threadIdx.y;</span><br><span class="line">    </span><br><span class="line">    // 合并写入 B（按行，但数据来自 tile 的列）</span><br><span class="line">    if (x &lt; width &amp;&amp; y &lt; width)</span><br><span class="line">        B[y * width + x] = tile[threadIdx.x][threadIdx.y];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>关键</strong>：共享内存没有合并要求，可以任意顺序访问（只需注意 Bank 冲突）。通过共享内存&quot;转换&quot;访问模式，让全局内存读写都是合并的。</p><h2 id="fen-qu-lu-ying-partition-camping" tabindex="-1" id="分区露营（Partition-Camping）">分区露营（Partition Camping）</h2><h3 id="dram-de-fen-qu-jie-gou" tabindex="-1" id="DRAM-的分区结构">DRAM 的分区结构</h3><p>全局内存由多个**分区（Partition）**组成，每个分区有独立的访问通道。地址到分区的映射通常是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">分区 = (地址 / 256) % 分区数</span><br></pre></td></tr></table></figure><p>如果所有访问都落在同一分区，其他分区空闲，带宽只有 1/N。</p><h3 id="he-shi-fa-sheng" tabindex="-1" id="何时发生">何时发生</h3><p>当多个 Warp 访问地址&quot;步调一致&quot;时：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">// 假设每个 block 处理矩阵的一列</span><br><span class="line">int col = blockIdx.x;</span><br><span class="line">for (int row = 0; row &lt; height; row++) &#123;</span><br><span class="line">    float val = M[row * width + col];  // 所有 block 同步访问</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果 width 恰好是分区数的倍数，所有 block 同时访问同一分区。</p><h3 id="jie-jue-fang-an" tabindex="-1" id="解决方案">解决方案</h3><ol><li><strong>调整数据布局</strong>：加 padding 打破对齐</li><li><strong>调整访问顺序</strong>：让不同 block 访问不同分区</li><li><strong>通常问题不大</strong>：现代 GPU 分区多，自动调度能力强</li></ol><p>分区露营在早期 GPU 上是严重问题，现代架构（Ampere+）影响较小，但仍值得注意。</p><h2 id="zhi-ling-hun-he-yu-tun-tu-liang" tabindex="-1" id="指令混合与吞吐量">指令混合与吞吐量</h2><h3 id="bu-tong-zhi-ling-de-tun-tu-liang" tabindex="-1" id="不同指令的吞吐量">不同指令的吞吐量</h3><p>并非所有操作速度相同：</p><table><thead><tr><th>操作类型</th><th>吞吐量（FLOP/周期/SM）</th><th>相对速度</th></tr></thead><tbody><tr><td>FP32 加法/乘法</td><td>128</td><td>1×</td></tr><tr><td>FP32 FMA</td><td>128</td><td>1×</td></tr><tr><td>FP32 除法</td><td>16</td><td>1/8</td></tr><tr><td>FP32 特殊函数</td><td>32</td><td>1/4</td></tr><tr><td>FP64 加法/乘法</td><td>64（或更少）</td><td>1/2</td></tr><tr><td>整数乘法</td><td>64</td><td>1/2</td></tr></tbody></table><p><strong>注意</strong>：除法和特殊函数（sin/cos/exp）慢很多。</p><h3 id="you-hua-ce-lue" tabindex="-1" id="优化策略">优化策略</h3><p><strong>用乘法替代除法</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// 慢</span><br><span class="line">float y = x / 3.0f;</span><br><span class="line"></span><br><span class="line">// 快（预计算倒数）</span><br><span class="line">float inv3 = 1.0f / 3.0f;  // 常量，编译时计算</span><br><span class="line">float y = x * inv3;</span><br></pre></td></tr></table></figure><p><strong>用近似函数</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">// 精确但慢</span><br><span class="line">float y = sinf(x);</span><br><span class="line"></span><br><span class="line">// 快速近似（误差略大）</span><br><span class="line">float y = __sinf(x);  // 内置快速版本</span><br></pre></td></tr></table></figure><p><strong>减少特殊函数调用</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">// 差：3 次特殊函数</span><br><span class="line">float a = expf(x);</span><br><span class="line">float b = expf(y);</span><br><span class="line">float c = expf(z);</span><br><span class="line"></span><br><span class="line">// 好：利用数学性质</span><br><span class="line">float abc = expf(x + y + z);</span><br></pre></td></tr></table></figure><h3 id="hun-he-jing-du" tabindex="-1" id="混合精度">混合精度</h3><p>如果精度允许，用 FP16 或 TF32：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">// 使用 half 精度（需要 include cuda_fp16.h）</span><br><span class="line">half x = __float2half(input);</span><br><span class="line">half y = __hmul(x, x);  // FP16 乘法，吞吐量更高</span><br><span class="line">float result = __half2float(y);</span><br></pre></td></tr></table></figure><p>Tensor Core 可以做 FP16/TF32 矩阵乘法，吞吐量比 FP32 CUDA 核心高数倍。</p><h2 id="xian-cheng-li-du" tabindex="-1" id="线程粒度">线程粒度</h2><h3 id="mei-xian-cheng-gong-zuo-liang" tabindex="-1" id="每线程工作量">每线程工作量</h3><p>线程粒度指每个线程处理的数据量。两个极端：</p><p><strong>细粒度</strong>：每线程处理 1 个元素</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">// 每线程 1 个元素</span><br><span class="line">int i = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">C[i] = A[i] + B[i];</span><br></pre></td></tr></table></figure><p><strong>粗粒度</strong>：每线程处理多个元素</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">// 每线程 4 个元素</span><br><span class="line">int base = (blockIdx.x * blockDim.x + threadIdx.x) * 4;</span><br><span class="line">for (int i = 0; i &lt; 4; i++) &#123;</span><br><span class="line">    C[base + i] = A[base + i] + B[base + i];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="cu-li-du-de-you-shi" tabindex="-1" id="粗粒度的优势">粗粒度的优势</h3><ol><li><strong>减少启动开销</strong>：更少的线程总数</li><li><strong>寄存器复用</strong>：循环变量、指针可复用</li><li><strong>指令级并行</strong>：循环展开后多条指令可流水</li><li><strong>减少同步</strong>：每线程更多独立工作</li></ol><h3 id="cu-li-du-de-feng-xian" tabindex="-1" id="粗粒度的风险">粗粒度的风险</h3><ol><li><strong>负载不均衡</strong>：如果元素数不是粒度倍数，最后一批线程工作量不同</li><li><strong>占用率下降</strong>：每线程更多寄存器，可能降低并行度</li><li><strong>复杂边界处理</strong>：需要额外检查</li></ol><h3 id="shi-jian-jian-yi" tabindex="-1" id="实践建议">实践建议</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">// 每线程处理 4 个元素，带边界检查</span><br><span class="line">__global__ void vectorAddCoarsened(float *A, float *B, float *C, int n) &#123;</span><br><span class="line">    int tid = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    int stride = blockDim.x * gridDim.x;</span><br><span class="line">    </span><br><span class="line">    // Grid-stride loop</span><br><span class="line">    for (int i = tid; i &lt; n; i += stride) &#123;</span><br><span class="line">        C[i] = A[i] + B[i];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>Grid-stride loop</strong> 是经典模式：每线程从自己的起始位置开始，按 grid 大小步进，直到处理完所有元素。兼顾了粒度和灵活性。</p><h2 id="zi-yuan-ping-heng" tabindex="-1" id="资源平衡">资源平衡</h2><h3 id="zhan-yong-lu-vs-mei-xian-cheng-zi-yuan" tabindex="-1" id="占用率-vs-每线程资源">占用率 vs 每线程资源</h3><p>回顾第四章的占用率概念。资源使用增加会降低占用率：</p><table><thead><tr><th>每线程寄存器</th><th>每 SM 线程数</th><th>占用率</th></tr></thead><tbody><tr><td>32</td><td>2048</td><td>100%</td></tr><tr><td>64</td><td>1024</td><td>50%</td></tr><tr><td>128</td><td>512</td><td>25%</td></tr><tr><td>256</td><td>256</td><td>12.5%</td></tr></tbody></table><p>类似地，每 Block 共享内存越多，能同时运行的 Block 越少。</p><h3 id="quan-heng-an-li" tabindex="-1" id="权衡案例">权衡案例</h3><p><strong>场景</strong>：Tiled 矩阵乘法</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">// 方案 A：小 Tile</span><br><span class="line">#define TILE 16</span><br><span class="line">__shared__ float As[16][16];  // 2 KB</span><br><span class="line">__shared__ float Bs[16][16];  // 2 KB</span><br><span class="line">// 共享内存少，可以多 Block，高占用率</span><br><span class="line">// 但 Tile 小，算术强度低</span><br><span class="line"></span><br><span class="line">// 方案 B：大 Tile</span><br><span class="line">#define TILE 32</span><br><span class="line">__shared__ float As[32][32];  // 8 KB</span><br><span class="line">__shared__ float Bs[32][32];  // 8 KB</span><br><span class="line">// 共享内存多，Block 少，低占用率</span><br><span class="line">// 但 Tile 大，算术强度高</span><br></pre></td></tr></table></figure><p><strong>通常大 Tile 更优</strong>：矩阵乘法是计算密集型，算术强度比占用率更重要。但需要实测验证。</p><h3 id="shi-yong-launch-bounds" tabindex="-1" id="使用-Launch-Bounds">使用 Launch Bounds</h3><p>告诉编译器你的配置，帮助优化寄存器分配：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">__global__ void __launch_bounds__(256, 4) matMulKernel(...) &#123;</span><br><span class="line">    // 每 Block 256 线程</span><br><span class="line">    // 期望每 SM 至少 4 个 Block</span><br><span class="line">    // 编译器据此限制寄存器使用</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果不指定，编译器可能过度使用寄存器，导致占用率低于预期。</p><h2 id="warp-zhi-xing-xiao-lu" tabindex="-1" id="Warp-执行效率">Warp 执行效率</h2><h3 id="xian-cheng-shu-li-yong-lu" tabindex="-1" id="线程束利用率">线程束利用率</h3><p>如果 Block 大小不是 32 的倍数，最后一个 Warp 有线程空闲：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dim3 block(100);  // 100 / 32 = 3.125 → 4 个 warp</span><br><span class="line">// Warp 3 只有 4 个活跃线程，28 个空闲</span><br><span class="line">// warp 利用率 = 100 / 128 = 78%</span><br></pre></td></tr></table></figure><p><strong>永远用 32 的倍数作为 Block 大小</strong>。</p><h3 id="dong-tai-fen-zhi-de-e-wai-kai-xiao" tabindex="-1" id="动态分支的额外开销">动态分支的额外开销</h3><p>即使没有分支发散，动态分支本身也有开销：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">// 有分支开销</span><br><span class="line">if (condition) &#123;</span><br><span class="line">    doWork();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 无分支（条件总为 true）</span><br><span class="line">doWork();</span><br></pre></td></tr></table></figure><p>编译器无法知道 <code>condition</code> 是否总为 true，必须生成分支指令。如果条件可以在编译时确定，用模板或 constexpr。</p><h2 id="shu-ju-yu-qu" tabindex="-1" id="数据预取">数据预取</h2><h3 id="ruan-jian-liu-shui" tabindex="-1" id="软件流水">软件流水</h3><p>通过提前发起内存请求，与计算重叠：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">// 无预取</span><br><span class="line">for (int i = 0; i &lt; n; i++) &#123;</span><br><span class="line">    float data = load(i);      // 等待</span><br><span class="line">    process(data);             // 计算</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 有预取</span><br><span class="line">float next = load(0);</span><br><span class="line">for (int i = 0; i &lt; n - 1; i++) &#123;</span><br><span class="line">    float curr = next;</span><br><span class="line">    next = load(i + 1);        // 提前请求</span><br><span class="line">    process(curr);             // 同时计算</span><br><span class="line">&#125;</span><br><span class="line">process(next);</span><br></pre></td></tr></table></figure><p>预取让 load 和 compute 重叠，隐藏部分延迟。</p><h3 id="zai-cuda-zhong-de-ying-yong" tabindex="-1" id="在-CUDA-中的应用">在 CUDA 中的应用</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">__global__ void prefetchExample(float *in, float *out, int n) &#123;</span><br><span class="line">    __shared__ float buffer[2][TILE_SIZE];  // 双缓冲</span><br><span class="line">    </span><br><span class="line">    int tile = 0;</span><br><span class="line">    </span><br><span class="line">    // 预加载第一块</span><br><span class="line">    buffer[0][threadIdx.x] = in[threadIdx.x];</span><br><span class="line">    </span><br><span class="line">    for (int i = TILE_SIZE; i &lt; n; i += TILE_SIZE) &#123;</span><br><span class="line">        __syncthreads();</span><br><span class="line">        </span><br><span class="line">        // 加载下一块到另一个缓冲区</span><br><span class="line">        buffer[1 - tile][threadIdx.x] = in[i + threadIdx.x];</span><br><span class="line">        </span><br><span class="line">        // 处理当前块</span><br><span class="line">        out[i - TILE_SIZE + threadIdx.x] = process(buffer[tile][threadIdx.x]);</span><br><span class="line">        </span><br><span class="line">        tile = 1 - tile;  // 切换缓冲区</span><br><span class="line">        __syncthreads();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    // 处理最后一块</span><br><span class="line">    out[n - TILE_SIZE + threadIdx.x] = process(buffer[tile][threadIdx.x]);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>双缓冲是经典技术：一个缓冲区处理，另一个加载，交替进行。</p><h2 id="xing-neng-fen-xi-gong-ju" tabindex="-1" id="性能分析工具">性能分析工具</h2><h3 id="nsight-compute" tabindex="-1" id="Nsight-Compute">Nsight Compute</h3><p>NVIDIA 官方 profiler，分析 kernel 性能：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ncu --<span class="built_in">set</span> full ./myprogram</span><br></pre></td></tr></table></figure><p>关键指标：</p><table><thead><tr><th>指标</th><th>含义</th><th>目标</th></tr></thead><tbody><tr><td>SM Throughput</td><td>计算单元利用率</td><td>越高越好</td></tr><tr><td>Memory Throughput</td><td>内存带宽利用率</td><td>接近硬件峰值</td></tr><tr><td>Occupancy</td><td>占用率</td><td>视情况而定</td></tr><tr><td>Warp Execution Efficiency</td><td>线程束效率</td><td>接近 100%</td></tr><tr><td>Memory Coalescing</td><td>合并效率</td><td>接近 100%</td></tr></tbody></table><h3 id="nsight-systems" tabindex="-1" id="Nsight-Systems">Nsight Systems</h3><p>分析整体执行流程：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nsys profile ./myprogram</span><br></pre></td></tr></table></figure><p>可视化：</p><ul><li>Kernel 执行时间线</li><li>Memory 拷贝时间</li><li>CPU/GPU 交互</li><li>流和事件</li></ul><h3 id="chang-jian-xing-neng-mo-shi" tabindex="-1" id="常见性能模式">常见性能模式</h3><p><strong>内存受限</strong>：Memory Throughput 高，SM Throughput 低</p><ul><li>解决：提高算术强度、用共享内存</li></ul><p><strong>计算受限</strong>：SM Throughput 高，Memory Throughput 低</p><ul><li>解决：已经很好了，优化算法复杂度</li></ul><p><strong>延迟受限</strong>：两个 Throughput 都低，Occupancy 也低</p><ul><li>解决：增加并行度，调整 Block 配置</li></ul><h2 id="you-hua-jian-cha-qing-dan" tabindex="-1" id="优化检查清单">优化检查清单</h2><p>按优先级排序的优化步骤：</p><h3 id="1-zheng-que-xing-you-xian" tabindex="-1" id="1-正确性优先">1. 正确性优先</h3><ul><li>[ ] 边界检查完整</li><li>[ ] 同步正确使用</li><li>[ ] 无竞态条件</li></ul><h3 id="2-nei-cun-you-hua" tabindex="-1" id="2-内存优化">2. 内存优化</h3><ul><li>[ ] 全局内存合并访问</li><li>[ ] 使用共享内存减少全局内存访问</li><li>[ ] 避免 Bank 冲突</li><li>[ ] 常量数据用 <code>__constant__</code></li></ul><h3 id="3-zhi-xing-you-hua" tabindex="-1" id="3-执行优化">3. 执行优化</h3><ul><li>[ ] Block 大小是 32 的倍数</li><li>[ ] 避免 Warp 内分支发散</li><li>[ ] 减少同步次数</li><li>[ ] 合理线程粒度</li></ul><h3 id="4-zhi-ling-you-hua" tabindex="-1" id="4-指令优化">4. 指令优化</h3><ul><li>[ ] 避免除法和特殊函数</li><li>[ ] 用 FMA（编译器自动）</li><li>[ ] 考虑混合精度</li></ul><h3 id="5-zi-yuan-ping-heng" tabindex="-1" id="5-资源平衡">5. 资源平衡</h3><ul><li>[ ] 监控寄存器使用</li><li>[ ] 使用 launch_bounds</li><li>[ ] 实测不同配置</li></ul><h2 id="xiao-jie" tabindex="-1" id="小结">小结</h2><p>第六章是性能优化的工程实践：</p><p><strong>内存合并核心</strong>：Warp 线程访问连续地址，事务数最少。矩阵按行访问好，按列访问差。用共享内存转换访问模式。</p><p><strong>分支发散回顾</strong>：Warp 内走不同分支会串行化。按 Warp 边界划分任务，用算术替代分支。</p><p><strong>指令吞吐量</strong>：除法慢 8 倍，特殊函数慢 4 倍。预计算倒数，用快速近似，考虑混合精度。</p><p><strong>线程粒度</strong>：每线程处理多个元素可提高效率。Grid-stride loop 是通用模式。</p><p><strong>资源平衡</strong>：占用率不是越高越好。计算密集型可接受低占用率，内存密集型需要高占用率来隐藏延迟。</p><p><strong>工具驱动优化</strong>：用 Nsight Compute 分析瓶颈，不要猜测。Memory Throughput 和 SM Throughput 指明优化方向。</p><p>这些技巧组合使用，能让代码性能再提升数倍。下一章开始学习具体的并行模式——卷积、规约、前缀和，这些都需要本章的优化技术。</p><hr><h2 id="xia-yi-bu" tabindex="-1" id="🚀-下一步">🚀 下一步</h2><hr><h2 id="can-kao-zi-liao" tabindex="-1" id="📚-参考资料">📚 参考资料</h2><ul><li>PMPP 第四版 Chapter 06</li><li><a href="https://smarter.xin/posts/220818c3/">第六章：性能方面的考虑</a></li></ul><p><strong>学习愉快！</strong> 🎓</p><hr><blockquote><p><strong>本文 GitHub 仓库</strong>: <a href="https://github.com/psmarter/PMPP-Learning">https://github.com/psmarter/PMPP-Learning</a></p></blockquote>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h2 id=&quot;qian-yan&quot; tabindex=&quot;-1&quot;</summary>
        
      
    
    
    
    <category term="知识分享" scheme="https://smarter.xin/categories/knowledge-sharing/"/>
    
    
    <category term="CUDA" scheme="https://smarter.xin/tags/CUDA/"/>
    
    <category term="GPU编程" scheme="https://smarter.xin/tags/gpu-programming/"/>
    
    <category term="并行计算" scheme="https://smarter.xin/tags/parallel-computing/"/>
    
    <category term="PMPP" scheme="https://smarter.xin/tags/PMPP/"/>
    
    <category term="性能优化" scheme="https://smarter.xin/tags/performance-optimization/"/>
    
    <category term="内存合并" scheme="https://smarter.xin/tags/memory-coalescing/"/>
    
  </entry>
  
  <entry>
    <title>PMPP-第五章：内存架构和数据局部性</title>
    <link href="https://smarter.xin/posts/3bb3179b/"/>
    <id>https://smarter.xin/posts/3bb3179b/</id>
    <published>2026-01-16T02:16:08.000Z</published>
    <updated>2026-01-24T11:47:21.462Z</updated>
    
    <content type="html"><![CDATA[<h2 id="qian-yan" tabindex="-1" id="前言">前言</h2><p>第四章理解了GPU的调度机制和硬件架构，这一章进入性能优化的核心——内存。GPU计算能力强大，但数据供应跟不上就白搭。第五章讲解GPU的内存层次结构，重点是Shared Memory和Tiling技术。掌握这些，矩阵乘法性能可以提升10倍以上。</p><blockquote><p><strong>📦 配套资源</strong>：本系列文章配有完整的 <a href="https://github.com/psmarter/PMPP-Learning">GitHub 仓库</a>，包含每章的练习题解答、CUDA 代码实现和详细注释。所有代码都经过测试，可以直接运行。</p></blockquote><h2 id="nei-cun-dai-kuan-xing-neng-de-tian-hua-ban" tabindex="-1" id="内存带宽：性能的天花板">内存带宽：性能的天花板</h2><h3 id="wen-ti-de-ben-zhi" tabindex="-1" id="问题的本质">问题的本质</h3><p>回顾第三章的矩阵乘法：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">__global__ void matMul(float *M, float *N, float *P, int width) &#123;</span><br><span class="line">    int row = blockIdx.y * blockDim.y + threadIdx.y;</span><br><span class="line">    int col = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    </span><br><span class="line">    if (row &lt; width &amp;&amp; col &lt; width) &#123;</span><br><span class="line">        float sum = 0.0f;</span><br><span class="line">        for (int k = 0; k &lt; width; k++) &#123;</span><br><span class="line">            sum += M[row * width + k] * N[k * width + col];</span><br><span class="line">        &#125;</span><br><span class="line">        P[row * width + col] = sum;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>计算 P[row][col] 需要读取 M 的一行和 N 的一列，共 2×width 个元素。每个元素 4 字节，width=1024 时：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">每线程读取：2 × 1024 × 4 = 8192 字节</span><br><span class="line">每线程计算：2 × 1024 = 2048 FLOP</span><br><span class="line">算术强度：2048 / 8192 = 0.25 FLOP/Byte</span><br></pre></td></tr></table></figure><p>现代 GPU 峰值 10+ TFLOPS，带宽 500+ GB/s，需要 20 FLOP/Byte 才能跑满计算单元。实际只有 0.25，<strong>GPU 大部分时间在等数据</strong>。</p><h3 id="shu-ju-zhong-fu-fang-wen" tabindex="-1" id="数据重复访问">数据重复访问</h3><p>更严重的是：<strong>同一数据被多个线程重复读取</strong>。</p><p>M[i][k] 被第 i 行的所有线程读取，N[k][j] 被第 j 列的所有线程读取。1024×1024 矩阵，每个元素被读 1024 次，但每次都从全局内存（DRAM）读。</p><p>这就是优化的切入点：<strong>让数据复用发生在快速存储上，而不是全局内存</strong>。</p><h2 id="gpu-nei-cun-ceng-ci" tabindex="-1" id="GPU-内存层次">GPU 内存层次</h2><h3 id="ceng-ci-jie-gou" tabindex="-1" id="层次结构">层次结构</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">┌─────────────────────────────────────────────┐</span><br><span class="line">│                   Host Memory               │   CPU DDR4/DDR5</span><br><span class="line">│                   (GB 级别)                  │   ~50 GB/s</span><br><span class="line">├─────────────────────────────────────────────┤</span><br><span class="line">│              Global Memory (DRAM)           │   GPU 显存</span><br><span class="line">│                  (GB 级别)                   │   ~500 GB/s</span><br><span class="line">├─────────────────────────────────────────────┤</span><br><span class="line">│    L2 Cache (SM 共享)                        │   几 MB</span><br><span class="line">│                                              │   ~1-2 TB/s</span><br><span class="line">├──────────────┬──────────────┬───────────────┤</span><br><span class="line">│   Shared     │   Shared     │   Shared      │   每 SM</span><br><span class="line">│   Memory     │   Memory     │   Memory      │   ~100 KB</span><br><span class="line">│   L1 Cache   │   L1 Cache   │   L1 Cache    │   ~10 TB/s</span><br><span class="line">├──────────────┼──────────────┼───────────────┤</span><br><span class="line">│  Registers   │  Registers   │  Registers    │   每线程</span><br><span class="line">│              │              │               │   ~几十 TB/s</span><br><span class="line">└──────────────┴──────────────┴───────────────┘</span><br><span class="line">     SM 0           SM 1           SM 2</span><br></pre></td></tr></table></figure><p><strong>核心规律</strong>：越靠近计算单元，容量越小，速度越快。</p><h3 id="ge-ji-cun-chu-te-dian" tabindex="-1" id="各级存储特点">各级存储特点</h3><table><thead><tr><th>存储类型</th><th>作用域</th><th>容量</th><th>延迟</th><th>程序员控制</th></tr></thead><tbody><tr><td>寄存器</td><td>单线程</td><td>~255个/线程</td><td>1周期</td><td>隐式（变量）</td></tr><tr><td>共享内存</td><td>Block内</td><td>~100KB/SM</td><td>~20周期</td><td>显式</td></tr><tr><td>L1缓存</td><td>SM内</td><td>~128KB/SM</td><td>~20周期</td><td>部分</td></tr><tr><td>L2缓存</td><td>全局</td><td>~6MB</td><td>~200周期</td><td>无</td></tr><tr><td>全局内存</td><td>全局</td><td>~数GB</td><td>~400周期</td><td>显式</td></tr></tbody></table><p><strong>关键洞察</strong>：</p><ul><li><strong>寄存器</strong>最快，但容量有限，且只属于单个线程</li><li><strong>共享内存</strong>是程序员可控的 Block 级缓存，这是优化的主战场</li><li><strong>全局内存</strong>是唯一能容纳大数据的地方，但太慢</li></ul><h2 id="gong-xiang-nei-cun-shared-memory" tabindex="-1" id="共享内存（Shared-Memory）">共享内存（Shared Memory）</h2><h3 id="ji-ben-gai-nian" tabindex="-1" id="基本概念">基本概念</h3><p>共享内存是 SM 上的可编程缓存：</p><ul><li><strong>Block 内所有线程共享</strong>：同 Block 的线程可以读写同一块共享内存</li><li><strong>生命周期与 Block 绑定</strong>：Block 结束，共享内存释放</li><li><strong>低延迟</strong>：约 20 周期，比全局内存快 20 倍</li></ul><h3 id="sheng-ming-yu-fa" tabindex="-1" id="声明语法">声明语法</h3><p><strong>静态分配</strong>（编译时确定大小）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">__global__ void kernel() &#123;</span><br><span class="line">    __shared__ float sharedData[256];  // Block 内共享</span><br><span class="line">    // ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>动态分配</strong>（运行时确定大小）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">__global__ void kernel() &#123;</span><br><span class="line">    extern __shared__ float sharedData[];  // 大小由启动配置指定</span><br><span class="line">    // ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 启动时指定共享内存大小</span><br><span class="line">kernel&lt;&lt;&lt;grid, block, sharedMemBytes&gt;&gt;&gt;(args);</span><br></pre></td></tr></table></figure><h3 id="tong-bu-syncthreads" tabindex="-1" id="同步：-syncthreads">同步：__syncthreads()</h3><p>共享内存是 Block 内共享的，需要同步保证数据一致性：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">__shared__ float data[256];</span><br><span class="line"></span><br><span class="line">// 阶段1：所有线程写入</span><br><span class="line">data[threadIdx.x] = input[globalIdx];</span><br><span class="line"></span><br><span class="line">__syncthreads();  // 等待所有线程完成写入</span><br><span class="line"></span><br><span class="line">// 阶段2：所有线程读取（此时数据已就绪）</span><br><span class="line">float val = data[(threadIdx.x + 1) % 256];</span><br></pre></td></tr></table></figure><p><strong>__syncthreads() 是栅栏同步</strong>：Block 内所有线程必须到达这一点，才能继续执行。</p><p><strong>常见错误</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">// 危险！条件内使用 syncthreads</span><br><span class="line">if (threadIdx.x &lt; 128) &#123;</span><br><span class="line">    data[threadIdx.x] = ...;</span><br><span class="line">    __syncthreads();  // 只有部分线程执行，会死锁！</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>同步必须保证 Block 内所有活跃线程都执行到。</p><h2 id="tiling-fen-kuai-chu-li" tabindex="-1" id="Tiling：分块处理">Tiling：分块处理</h2><h3 id="he-xin-si-xiang" tabindex="-1" id="核心思想">核心思想</h3><p>既然全局内存慢但共享内存快，策略就是：</p><ol><li><strong>分块加载</strong>：将数据分成小块（Tile），逐块加载到共享内存</li><li><strong>计算复用</strong>：在共享内存中完成该块的所有计算</li><li><strong>移动窗口</strong>：处理下一块，直到完成</li></ol><p>这样，每个数据从全局内存只读一次，但在共享内存中被多次使用。</p><h3 id="tiled-ju-zhen-cheng-fa" tabindex="-1" id="Tiled-矩阵乘法">Tiled 矩阵乘法</h3><p><strong>问题</strong>：计算 P = M × N，每个 P[i][j] = Σ M[i][k] × N[k][j]</p><p><strong>朴素版本</strong>：每个线程独立读取整行和整列（大量重复读取）</p><p><strong>Tiled 版本</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">┌───────────────┐   ┌───────────────┐</span><br><span class="line">│   M 矩阵       │   │   N 矩阵       │</span><br><span class="line">│  ┌───┐        │   │      ┌───┐    │</span><br><span class="line">│  │Tile│ ────→ │   │      │Tile│   │</span><br><span class="line">│  └───┘        │   │      └───┘    │</span><br><span class="line">│               │   │        │      │</span><br><span class="line">└───────────────┘   └────────│──────┘</span><br><span class="line">                             ↓</span><br><span class="line">                    ┌───────────────┐</span><br><span class="line">                    │   P 矩阵       │</span><br><span class="line">                    │      ┌───┐    │</span><br><span class="line">                    │      │计算│    │</span><br><span class="line">                    │      └───┘    │</span><br><span class="line">                    └───────────────┘</span><br></pre></td></tr></table></figure><p><strong>步骤</strong>：</p><ol><li>将 M 的一个 Tile 和 N 的一个 Tile 加载到共享内存</li><li>Block 内所有线程使用共享内存中的数据进行部分计算</li><li>加载下一对 Tile，累加结果</li><li>重复直到完成</li></ol><h3 id="dai-ma-shi-xian" tabindex="-1" id="代码实现">代码实现</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">#define TILE_WIDTH 16</span><br><span class="line"></span><br><span class="line">__global__ void matMulTiled(float *M, float *N, float *P, int width) &#123;</span><br><span class="line">    // 共享内存声明</span><br><span class="line">    __shared__ float Mds[TILE_WIDTH][TILE_WIDTH];</span><br><span class="line">    __shared__ float Nds[TILE_WIDTH][TILE_WIDTH];</span><br><span class="line">    </span><br><span class="line">    int bx = blockIdx.x, by = blockIdx.y;</span><br><span class="line">    int tx = threadIdx.x, ty = threadIdx.y;</span><br><span class="line">    </span><br><span class="line">    // 计算该线程负责的 P 元素位置</span><br><span class="line">    int row = by * TILE_WIDTH + ty;</span><br><span class="line">    int col = bx * TILE_WIDTH + tx;</span><br><span class="line">    </span><br><span class="line">    float Pvalue = 0;</span><br><span class="line">    </span><br><span class="line">    // 分块循环</span><br><span class="line">    for (int ph = 0; ph &lt; width / TILE_WIDTH; ++ph) &#123;</span><br><span class="line">        </span><br><span class="line">        // 协作加载 M 的 Tile</span><br><span class="line">        Mds[ty][tx] = M[row * width + (ph * TILE_WIDTH + tx)];</span><br><span class="line">        </span><br><span class="line">        // 协作加载 N 的 Tile</span><br><span class="line">        Nds[ty][tx] = N[(ph * TILE_WIDTH + ty) * width + col];</span><br><span class="line">        </span><br><span class="line">        __syncthreads();  // 确保 Tile 加载完成</span><br><span class="line">        </span><br><span class="line">        // 使用共享内存计算部分点积</span><br><span class="line">        for (int k = 0; k &lt; TILE_WIDTH; ++k) &#123;</span><br><span class="line">            Pvalue += Mds[ty][k] * Nds[k][tx];</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        __syncthreads();  // 确保计算完成再加载下一个 Tile</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    P[row * width + col] = Pvalue;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="guan-jian-dian-jie-xi" tabindex="-1" id="关键点解析">关键点解析</h3><p><strong>1. 协作加载</strong></p><p>Block 内的线程分工加载 Tile：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Mds[ty][tx] = M[row * width + (ph * TILE_WIDTH + tx)];</span><br></pre></td></tr></table></figure><p>每个线程加载一个元素，16×16 = 256 个线程加载 256 个元素。比单线程加载整个 Tile 高效得多。</p><p><strong>2. 两次同步</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">__syncthreads();  // 第一次：确保数据加载完成</span><br><span class="line">// ... 计算 ...</span><br><span class="line">__syncthreads();  // 第二次：确保计算完成再覆盖共享内存</span><br></pre></td></tr></table></figure><p>两次同步都必要：</p><ul><li>第一次：防止读到未加载的数据</li><li>第二次：防止快线程覆盖慢线程还在用的数据</li></ul><p><strong>3. 内层循环</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">for (int k = 0; k &lt; TILE_WIDTH; ++k) &#123;</span><br><span class="line">    Pvalue += Mds[ty][k] * Nds[k][tx];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个循环只访问共享内存，没有全局内存访问。这是性能提升的来源。</p><h3 id="xing-neng-fen-xi" tabindex="-1" id="性能分析">性能分析</h3><p><strong>朴素版本</strong>：</p><ul><li>每线程读取全局内存：2 × width 次</li><li>总全局内存访问：width³ × 2（读）+ width²（写）</li></ul><p><strong>Tiled 版本</strong>：</p><ul><li>每 Tile 阶段：Block 读 2 × TILE_WIDTH² 个元素</li><li>共 width/TILE_WIDTH 个阶段</li><li>每线程贡献：2 × width 次（与朴素相同？不对！）</li></ul><p><strong>关键差异</strong>：在 Tiled 版本中，每个全局内存读取被 TILE_WIDTH 个线程共享使用。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">全局内存访问减少倍数 = TILE_WIDTH</span><br><span class="line">算术强度提升 = TILE_WIDTH 倍</span><br></pre></td></tr></table></figure><p>TILE_WIDTH = 16 时，算术强度从 0.25 提升到 4 FLOP/Byte。TILE_WIDTH = 32 时可达 8 FLOP/Byte。</p><h3 id="bian-jie-chu-li" tabindex="-1" id="边界处理">边界处理</h3><p>上面的代码假设 width 是 TILE_WIDTH 的倍数。实际需要处理边界：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">// 带边界检查的加载</span><br><span class="line">if (row &lt; width &amp;&amp; (ph * TILE_WIDTH + tx) &lt; width)</span><br><span class="line">    Mds[ty][tx] = M[row * width + (ph * TILE_WIDTH + tx)];</span><br><span class="line">else</span><br><span class="line">    Mds[ty][tx] = 0;  // 越界元素填0</span><br><span class="line"></span><br><span class="line">if ((ph * TILE_WIDTH + ty) &lt; width &amp;&amp; col &lt; width)</span><br><span class="line">    Nds[ty][tx] = N[(ph * TILE_WIDTH + ty) * width + col];</span><br><span class="line">else</span><br><span class="line">    Nds[ty][tx] = 0;</span><br></pre></td></tr></table></figure><p>填 0 不影响加法结果，是处理边界的常用技巧。</p><h2 id="nei-cun-fang-wen-mo-shi" tabindex="-1" id="内存访问模式">内存访问模式</h2><h3 id="he-bing-fang-wen-coalesced-access" tabindex="-1" id="合并访问（Coalesced-Access）">合并访问（Coalesced Access）</h3><p>GPU 内存控制器按 <strong>32 字节或 128 字节</strong> 的事务读写数据。如果 Warp 中的线程访问连续地址，可以合并成一次事务：</p><p><strong>好的访问模式</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// 线程 0,1,2,...,31 访问连续地址</span><br><span class="line">data[threadIdx.x];  // 一次 128B 事务</span><br></pre></td></tr></table></figure><p><strong>差的访问模式</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// 线程 0,1,2,...,31 访问跨步地址</span><br><span class="line">data[threadIdx.x * 32];  // 32 次事务！</span><br></pre></td></tr></table></figure><p><strong>矩阵访问的陷阱</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">// P[i][j] 遍历</span><br><span class="line">// 按行遍历（好）：data[row * width + col]，col 连续</span><br><span class="line">// 按列遍历（差）：data[row * width + col]，row 连续（跨步 = width）</span><br></pre></td></tr></table></figure><h3 id="gong-xiang-nei-cun-bank-chong-tu" tabindex="-1" id="共享内存-Bank-冲突">共享内存 Bank 冲突</h3><p>共享内存分成 32 个 <strong>Bank</strong>，每个 Bank 宽度 4 字节。不同 Bank 可以同时访问，但同一 Bank 的不同地址会串行化。</p><p><strong>Bank 映射</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">地址 0,32,64,...  → Bank 0</span><br><span class="line">地址 4,36,68,...  → Bank 1</span><br><span class="line">地址 8,40,72,...  → Bank 2</span><br><span class="line">...</span><br><span class="line">地址 124,156,... → Bank 31</span><br></pre></td></tr></table></figure><p><strong>无冲突</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data[threadIdx.x];      // 32 线程访问 32 个 Bank</span><br><span class="line">data[threadIdx.x * 2];  // 跨步 2，访问 Bank 0,2,4,...（无冲突）</span><br></pre></td></tr></table></figure><p><strong>有冲突</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data[threadIdx.x * 32]; // 所有线程访问 Bank 0！32-way 冲突</span><br></pre></td></tr></table></figure><p><strong>特例——广播</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data[0];  // 所有线程读同一地址，硬件广播，无冲突</span><br></pre></td></tr></table></figure><h3 id="ju-zhen-zhuan-zhi-de-bank-chong-tu" tabindex="-1" id="矩阵转置的-Bank-冲突">矩阵转置的 Bank 冲突</h3><p>考虑共享内存中 16×16 的矩阵：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">__shared__ float tile[16][16];</span><br><span class="line"></span><br><span class="line">// 加载（列访问）</span><br><span class="line">tile[ty][tx] = input[row * width + col];  // 无冲突</span><br><span class="line"></span><br><span class="line">// 存储（行访问）</span><br><span class="line">output[col * width + row] = tile[tx][ty];  // 有冲突！</span><br></pre></td></tr></table></figure><p><code>tile[tx][ty]</code> 使得线程 0,1,2,…,15 分别访问 tile[0][ty], tile[1][ty], …，这些元素地址为 ty, ty+16, ty+32, …，步长 16×4 = 64 字节 = 16 个 Bank。部分线程会访问同一 Bank。</p><p><strong>解决方案——Padding</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">__shared__ float tile[16][17];  // 多加一列</span><br><span class="line"></span><br><span class="line">// 现在 tile[i][j] 的地址是 i*17 + j</span><br><span class="line">// 步长变成 17×4 = 68 字节，不再对齐</span><br></pre></td></tr></table></figure><p>Padding 打破了 Bank 对齐，消除冲突。代价是浪费一点共享内存。</p><h2 id="chang-liang-nei-cun-constant-memory" tabindex="-1" id="常量内存（Constant-Memory）">常量内存（Constant Memory）</h2><h3 id="te-dian" tabindex="-1" id="特点">特点</h3><ul><li><strong>只读</strong>：Kernel 内不能写</li><li><strong>缓存优化</strong>：有专用缓存，广播访问效率高</li><li><strong>容量有限</strong>：64 KB</li></ul><h3 id="gua-yong-chang-jing" tabindex="-1" id="适用场景">适用场景</h3><p>所有线程读相同数据（如卷积核、变换矩阵）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">__constant__ float kernel[9];  // 声明</span><br><span class="line"></span><br><span class="line">// Host 端写入</span><br><span class="line">cudaMemcpyToSymbol(kernel, h_kernel, 9 * sizeof(float));</span><br><span class="line"></span><br><span class="line">// Kernel 内使用</span><br><span class="line">__global__ void conv(...) &#123;</span><br><span class="line">    float sum = 0;</span><br><span class="line">    for (int i = 0; i &lt; 9; i++) &#123;</span><br><span class="line">        sum += data[i] * kernel[i];  // 所有线程读相同 kernel[i]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果每个线程读不同地址，常量内存反而更慢（串行化）。</p><h2 id="ji-cun-qi-you-hua" tabindex="-1" id="寄存器优化">寄存器优化</h2><h3 id="ji-cun-qi-de-zhong-yao-xing" tabindex="-1" id="寄存器的重要性">寄存器的重要性</h3><p>寄存器是最快的存储，单周期延迟。但数量有限（每 SM 约 64K 个），过度使用会导致：</p><ol><li><strong>寄存器溢出（Spilling）</strong>：溢出到 Local Memory（实际是全局内存），极慢</li><li><strong>占用率下降</strong>：每线程用更多寄存器，SM 能容纳的线程数减少</li></ol><h3 id="cha-kan-ji-cun-qi-shi-yong" tabindex="-1" id="查看寄存器使用">查看寄存器使用</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvcc --ptxas-options=-v kernel.cu</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ptxas info: Used 32 registers, ...</span><br></pre></td></tr></table></figure><h3 id="kong-zhi-ce-lue" tabindex="-1" id="控制策略">控制策略</h3><p><strong>编译器提示</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">__global__ void __launch_bounds__(256, 4) kernel(...) &#123;</span><br><span class="line">    // 告诉编译器：每 Block 256 线程，每 SM 至少 4 个 Block</span><br><span class="line">    // 编译器据此优化寄存器分配</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>编译选项</strong>：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvcc -maxrregcount=32 kernel.cu  <span class="comment"># 限制每线程最多 32 个寄存器</span></span><br></pre></td></tr></table></figure><p><strong>权衡</strong>：限制过严可能导致溢出，限制过松可能降低占用率。需要实测。</p><h2 id="shu-ju-ju-bu-xing-you-hua-qing-dan" tabindex="-1" id="数据局部性优化清单">数据局部性优化清单</h2><h3 id="kong-jian-ju-bu-xing" tabindex="-1" id="空间局部性">空间局部性</h3><p><strong>定义</strong>：访问的数据在内存中相邻</p><p><strong>优化手段</strong>：</p><ul><li>连续访问，利用合并</li><li>数据布局优化（AoS → SoA）</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">// Array of Structures（差）</span><br><span class="line">struct Particle &#123; float x, y, z; &#125;;</span><br><span class="line">Particle particles[N];</span><br><span class="line">particles[i].x;  // 跨步 12 字节</span><br><span class="line"></span><br><span class="line">// Structure of Arrays（好）</span><br><span class="line">struct Particles &#123; float x[N], y[N], z[N]; &#125;;</span><br><span class="line">Particles p;</span><br><span class="line">p.x[i];  // 连续访问</span><br></pre></td></tr></table></figure><h3 id="shi-jian-ju-bu-xing" tabindex="-1" id="时间局部性">时间局部性</h3><p><strong>定义</strong>：同一数据短期内被多次访问</p><p><strong>优化手段</strong>：</p><ul><li>Tiling 到共享内存/寄存器</li><li>循环分块</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">// 无时间局部性</span><br><span class="line">for (int k = 0; k &lt; N; k++) &#123;</span><br><span class="line">    C[i][j] += A[i][k] * B[k][j];  // A、B 每次从全局内存读</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 有时间局部性（Tiled）</span><br><span class="line">for (int tile = 0; tile &lt; N/TILE; tile++) &#123;</span><br><span class="line">    // 加载 tile 到共享内存</span><br><span class="line">    for (int k = 0; k &lt; TILE; k++) &#123;</span><br><span class="line">        C[i][j] += As[ty][k] * Bs[k][tx];  // 从共享内存读，复用</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="shi-zhan-you-hua-hou-de-ju-zhen-cheng-fa-xing-neng" tabindex="-1" id="实战：优化后的矩阵乘法性能">实战：优化后的矩阵乘法性能</h2><p>以 1024×1024 单精度矩阵为例：</p><table><thead><tr><th>版本</th><th>全局内存访问</th><th>算术强度</th><th>相对性能</th></tr></thead><tbody><tr><td>朴素</td><td>2×10⁹ 次</td><td>0.25</td><td>1×</td></tr><tr><td>Tiled (16×16)</td><td>1.25×10⁸ 次</td><td>4</td><td>~8×</td></tr><tr><td>Tiled (32×32)</td><td>6.25×10⁷ 次</td><td>8</td><td>~12×</td></tr><tr><td>+ 寄存器优化</td><td>更少</td><td>16+</td><td>~20×</td></tr></tbody></table><p><strong>测试环境</strong>：</p><ul><li>GPU：NVIDIA RTX 3080（8704 CUDA 核心）</li><li>CUDA：11.x</li><li>编译器：nvcc -O3</li></ul><p>实际提升取决于具体 GPU 和问题规模，但 10× 以上是常见的。cuBLAS 的高度优化实现可达到 30-40× 加速。</p><h2 id="xiao-jie" tabindex="-1" id="小结">小结</h2><p>第五章是性能优化的核心：</p><p><strong>内存层次认知</strong>：寄存器→共享内存→L2→全局内存，速度差 100 倍以上。写高性能代码就是让热数据留在快存储。</p><p><strong>共享内存本质</strong>：程序员可控的 Block 级缓存。声明简单，但需要正确同步。两次 __syncthreads() 别忘。</p><p><strong>Tiling 核心</strong>：分块加载，块内复用。矩阵乘法从 0.25 提升到 8+ FLOP/Byte，这是实打实的 10× 加速。</p><p><strong>访问模式</strong>：</p><ul><li>全局内存要合并访问</li><li>共享内存要避免 Bank 冲突</li><li>必要时用 Padding</li></ul><p><strong>局部性原则</strong>：空间局部性（连续访问），时间局部性（重复使用）。Tiling 同时利用了两者。</p><p>掌握了内存优化，GPU 的计算能力才能真正发挥。第六章将讨论更多性能优化的细节考虑，而第七章开始将学习具体的并行计算模式——卷积、模板、归约、前缀和等，这些都需要精心设计的内存访问策略。</p><hr><h2 id="xia-yi-bu" tabindex="-1" id="🚀-下一步">🚀 下一步</h2><hr><h2 id="can-kao-zi-liao" tabindex="-1" id="📚-参考资料">📚 参考资料</h2><ul><li>PMPP 第四版 Chapter 05</li><li><a href="https://smarter.xin/posts/3bb3179b/">第五章：内存架构和数据局部性</a></li></ul><p><strong>学习愉快！</strong> 🎓</p><hr><blockquote><p><strong>本文 GitHub 仓库</strong>: <a href="https://github.com/psmarter/PMPP-Learning">https://github.com/psmarter/PMPP-Learning</a></p></blockquote>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h2 id=&quot;qian-yan&quot; tabindex=&quot;-1&quot; id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;第四章理解了GPU的调度机制和硬件架构，这一章进入性能优化的核心——内存。GPU计算能力强大，但数据供应跟不上就白搭。第五章讲解GPU的内存层次结构，重点是Shared</summary>
        
      
    
    
    
    <category term="知识分享" scheme="https://smarter.xin/categories/knowledge-sharing/"/>
    
    
    <category term="CUDA" scheme="https://smarter.xin/tags/CUDA/"/>
    
    <category term="GPU编程" scheme="https://smarter.xin/tags/gpu-programming/"/>
    
    <category term="并行计算" scheme="https://smarter.xin/tags/parallel-computing/"/>
    
    <category term="PMPP" scheme="https://smarter.xin/tags/PMPP/"/>
    
    <category term="Tiling" scheme="https://smarter.xin/tags/Tiling/"/>
    
    <category term="共享内存" scheme="https://smarter.xin/tags/shared-memory/"/>
    
  </entry>
  
  <entry>
    <title>PMPP-第四章：计算架构和调度</title>
    <link href="https://smarter.xin/posts/bd5d1d6/"/>
    <id>https://smarter.xin/posts/bd5d1d6/</id>
    <published>2026-01-15T05:08:55.000Z</published>
    <updated>2026-01-24T11:47:21.464Z</updated>
    
    <content type="html"><![CDATA[<h2 id="qian-yan" tabindex="-1" id="前言">前言</h2><p>前三章打下了基础：第一章理解&quot;为什么使用 GPU&quot;，第二章学会&quot;如何编写核函数&quot;，第三章掌握&quot;多维数据处理&quot;。但到目前为止，我们只是在使用 GPU，还未深入理解其内部机制。第四章开始深入 GPU 内部——硬件架构如何影响性能，线程如何被调度执行，代码性能差异的根本原因。理解这些硬件细节，才算真正入门 GPU 编程。</p><blockquote><p><strong>📦 配套资源</strong>：本系列文章配有完整的 <a href="https://github.com/psmarter/PMPP-Learning">GitHub 仓库</a>，包含每章的练习题解答、CUDA 代码实现和详细注释。所有代码都经过测试，可以直接运行。</p></blockquote><h2 id="gpu-jia-gou-gai-lan" tabindex="-1" id="GPU架构概览">GPU架构概览</h2><h3 id="liu-shi-duo-chu-li-qi-sm" tabindex="-1" id="流式多处理器（SM）">流式多处理器（SM）</h3><p>GPU并不是一个巨大的处理器，而是由多个**流式多处理器（Streaming Multiprocessor, SM）**组成的阵列。每个SM是相对独立的执行单元，可以同时运行多个线程块。</p><p>以NVIDIA Ampere架构（如RTX 3080）为例：</p><table><thead><tr><th>组件</th><th>数量/规格</th></tr></thead><tbody><tr><td>SM数量</td><td>68</td></tr><tr><td>每SM CUDA核心</td><td>128</td></tr><tr><td>每SM最大线程</td><td>1536</td></tr><tr><td>每SM最大Block</td><td>16</td></tr><tr><td>共享内存</td><td>每SM 128KB可配置</td></tr><tr><td>L2缓存</td><td>5MB</td></tr></tbody></table><p>不同架构参数不同，但核心思想相同：<strong>大量小核心并行工作</strong>。</p><h3 id="sm-nei-bu-jie-gou" tabindex="-1" id="SM内部结构">SM内部结构</h3><p>每个SM包含：</p><ol><li><strong>CUDA核心</strong>：执行整数和单精度浮点运算</li><li><strong>Tensor核心</strong>：专用矩阵运算（深度学习加速）</li><li><strong>特殊功能单元（SFU）</strong>：执行sin/cos/exp等超越函数</li><li><strong>加载/存储单元（LD/ST）</strong>：处理内存访问</li><li><strong>Warp调度器</strong>：调度线程执行</li><li><strong>寄存器文件</strong>：快速存储，每SM约64KB</li><li><strong>共享内存</strong>：block内共享的可编程缓存</li></ol><p>关键认识：SM是资源池，多个block共享这些资源。block分配多少资源，决定了SM能同时运行几个block。</p><h3 id="xian-cheng-kuai-dao-sm-de-ying-she" tabindex="-1" id="线程块到SM的映射">线程块到SM的映射</h3><p>启动kernel时，runtime负责将线程块分配到各SM：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kernel&lt;&lt;&lt;gridDim, blockDim&gt;&gt;&gt;(args);</span><br><span class="line">         ↓</span><br><span class="line">运行时分配：Block 0→SM0, Block 1→SM2, Block 2→SM1, ...</span><br></pre></td></tr></table></figure><p><strong>关键规则</strong>：</p><ul><li>每个block只在一个SM上执行，不会跨SM</li><li>一个SM可以同时执行多个block（资源允许的话）</li><li>Block之间没有执行顺序保证</li><li>Block一旦开始执行，会运行到结束</li></ul><p>这种设计的好处：block完全独立，硬件可以自由调度，适应不同规模的GPU。</p><h2 id="xian-cheng-shu-warp-zhi-xing-de-ji-ben-dan-wei" tabindex="-1" id="线程束（Warp）：执行的基本单位">线程束（Warp）：执行的基本单位</h2><h3 id="shi-yao-shi-xian-cheng-shu" tabindex="-1" id="什么是线程束">什么是线程束</h3><p><strong>线程束（Warp）是32个连续线程组成的执行单位</strong>。这是 NVIDIA GPU 的核心设计，理解线程束就理解了 GPU 执行模型的一半。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">块（Block）包含256个线程</span><br><span class="line">├── 线程束 0：线程 0-31</span><br><span class="line">├── 线程束 1：线程 32-63</span><br><span class="line">├── 线程束 2：线程 64-95</span><br><span class="line">├── 线程束 3：线程 96-127</span><br><span class="line">├── 线程束 4：线程 128-159</span><br><span class="line">├── 线程束 5：线程 160-191</span><br><span class="line">├── 线程束 6：线程 192-223</span><br><span class="line">└── 线程束 7：线程 224-255</span><br></pre></td></tr></table></figure><p><strong>为什么是32个</strong>？硬件设计决定的。每个 SM 有一定数量的计算单元，32是效率最优的分组大小。</p><h3 id="simt-zhi-xing-mo-xing" tabindex="-1" id="SIMT-执行模型">SIMT 执行模型</h3><p>GPU 采用 <strong>SIMT（Single Instruction Multiple Thread，单指令多线程）</strong> 模型：</p><ul><li>同一线程束内的32个线程，在同一时钟周期执行相同指令</li><li>但操作不同的数据（不同的寄存器）</li><li>类似 SIMD，但更灵活（线程可以有独立状态）</li></ul><p><strong>举例</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">C[i] = A[i] + B[i];</span><br></pre></td></tr></table></figure><p>线程束中的32个线程同时执行&quot;加法&quot;指令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">线程束 0 执行：</span><br><span class="line">线程 0：C[0] = A[0] + B[0]  ─┐</span><br><span class="line">线程 1：C[1] = A[1] + B[1]   │ 同一条 add 指令</span><br><span class="line">...                         │ 同一时钟周期</span><br><span class="line">线程 31：C[31] = A[31] + B[31]─┘</span><br></pre></td></tr></table></figure><p>硬件只需取一次指令，就能完成32个操作。这就是 GPU 高吞吐的来源。</p><h3 id="xian-cheng-shu-diao-du" tabindex="-1" id="线程束调度">线程束调度</h3><p>每个 SM 有多个线程束调度器（如 Ampere 架构有4个）。每个时钟周期，调度器选择一个就绪的线程束发射指令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">周期1：线程束调度器0选择线程束3，发射 add 指令</span><br><span class="line">周期2：线程束调度器0选择线程束7，发射 load 指令</span><br><span class="line">周期3：线程束调度器0选择线程束0，发射 mul 指令</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p><strong>关键</strong>：线程束之间是独立调度的。如果线程束3在等待内存数据，调度器可以切换到线程束7执行，避免浪费时钟周期。</p><h2 id="kong-zhi-liu-fa-san-xing-neng-sha-shou" tabindex="-1" id="控制流发散：性能杀手">控制流发散：性能杀手</h2><h3 id="shi-yao-shi-fen-zhi-fa-san" tabindex="-1" id="什么是分支发散">什么是分支发散</h3><p>当warp内的线程走不同分支时，就发生<strong>控制流发散（Control Divergence）</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">if (threadIdx.x &lt; 16) &#123;</span><br><span class="line">    // 分支A</span><br><span class="line">    A[i] = ...;</span><br><span class="line">&#125; else &#123;</span><br><span class="line">    // 分支B</span><br><span class="line">    B[i] = ...;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>问题来了：32个线程必须执行相同指令，但这里线程0-15需要执行分支A，线程16-31需要执行分支B。怎么办？</p><h3 id="ying-jian-ru-he-chu-li" tabindex="-1" id="硬件如何处理">硬件如何处理</h3><p>GPU采用<strong>谓词执行（Predicated Execution）</strong>：</p><ol><li>所有线程先执行分支A，但只有满足条件的线程写入结果</li><li>再执行分支B，只有不满足条件的线程写入结果</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">实际执行序列:</span><br><span class="line">Step 1: 执行分支A（线程0-15活跃，16-31抑制）</span><br><span class="line">Step 2: 执行分支B（线程0-15抑制，16-31活跃）</span><br></pre></td></tr></table></figure><p><strong>代价</strong>：两个分支都被执行，时间翻倍。如果有n个分支，最坏情况性能降为1/n。</p><h3 id="xing-neng-ying-xiang-liang-hua" tabindex="-1" id="性能影响量化">性能影响量化</h3><p><strong>场景1</strong>：无发散</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">int i = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">C[i] = A[i] + B[i];  // 所有线程执行相同操作</span><br></pre></td></tr></table></figure><p>100%效率，理想情况。</p><p><strong>场景2</strong>：warp内发散</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">if (threadIdx.x % 2 == 0) &#123;</span><br><span class="line">    C[i] = A[i] + B[i];</span><br><span class="line">&#125; else &#123;</span><br><span class="line">    C[i] = A[i] * B[i];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>每个warp一半执行加法，一半执行乘法。效率约50%。</p><p><strong>场景3</strong>：warp间无发散</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">if (threadIdx.x &lt; 32) &#123;  // warp 0整体走这边</span><br><span class="line">    C[i] = A[i] + B[i];</span><br><span class="line">&#125; else &#123;                  // warp 1-7整体走这边</span><br><span class="line">    C[i] = A[i] * B[i];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>每个warp内部不发散，效率接近100%。</p><p><strong>核心原则</strong>：分支发散只在warp内部有开销。让同一warp的线程走相同分支，就不损失性能。</p><h3 id="bi-mian-fa-san-de-ji-qiao" tabindex="-1" id="避免发散的技巧">避免发散的技巧</h3><p><strong>技巧1</strong>：按warp边界划分任务</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">// 差：奇偶分支，warp内发散</span><br><span class="line">if (threadIdx.x % 2 == 0) &#123; taskA(); &#125;</span><br><span class="line">else &#123; taskB(); &#125;</span><br><span class="line"></span><br><span class="line">// 好：按warp划分，warp间分工</span><br><span class="line">if (threadIdx.x / 32 == 0) &#123; taskA(); &#125;  // warp 0</span><br><span class="line">else &#123; taskB(); &#125;                         // 其他warp</span><br></pre></td></tr></table></figure><p><strong>技巧2</strong>：重组数据</p><p>如果必须处理不同类型的元素，可以先排序，让同类元素落在同一warp。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">// 原始：type分布随机，每个warp都发散</span><br><span class="line">if (type[i] == 0) &#123; processType0(); &#125;</span><br><span class="line">else &#123; processType1(); &#125;</span><br><span class="line"></span><br><span class="line">// 优化：按type排序后处理，warp内type相同</span><br><span class="line">sort_by_type(data);  // 预处理</span><br><span class="line">kernel&lt;&lt;&lt;...&gt;&gt;&gt;(sorted_data);</span><br></pre></td></tr></table></figure><p><strong>技巧3</strong>：用算术替代分支</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">// 分支版本</span><br><span class="line">if (x &gt; 0) &#123; y = x; &#125;</span><br><span class="line">else &#123; y = -x; &#125;</span><br><span class="line"></span><br><span class="line">// 无分支版本（ReLU可以这样）</span><br><span class="line">y = x * (x &gt; 0);  // 利用布尔转int</span><br><span class="line">// 或用内置函数</span><br><span class="line">y = fabs(x);</span><br></pre></td></tr></table></figure><h2 id="yan-chi-yin-cang-gpu-de-he-xin-you-hua-ce-lue" tabindex="-1" id="延迟隐藏：GPU的核心优化策略">延迟隐藏：GPU的核心优化策略</h2><h3 id="shi-yao-shi-yan-chi" tabindex="-1" id="什么是延迟">什么是延迟</h3><p>**延迟（Latency）**是指令从发出到完成需要的时钟周期：</p><table><thead><tr><th>操作</th><th>典型延迟</th></tr></thead><tbody><tr><td>算术运算</td><td>4-8周期</td></tr><tr><td>共享内存</td><td>20-30周期</td></tr><tr><td>全局内存</td><td>200-400周期</td></tr><tr><td>特殊函数(sin/exp)</td><td>20-40周期</td></tr></tbody></table><p>全局内存访问是大头，400周期意味着读一次数据的时间可以做100次计算。</p><h3 id="gpu-ru-he-yin-cang-yan-chi" tabindex="-1" id="GPU如何隐藏延迟">GPU如何隐藏延迟</h3><p>CPU用复杂的乱序执行、预取来隐藏延迟。GPU用更简单粗暴的方法：<strong>大量线程+快速切换</strong>。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">时钟周期推演:</span><br><span class="line">周期1: Warp0发起load A[0]（需要400周期返回）</span><br><span class="line">周期2: Warp1发起load A[32]</span><br><span class="line">周期3: Warp2发起load A[64]</span><br><span class="line">...（继续切换执行其他warp）</span><br><span class="line">周期400: Warp0的数据到了，可以继续执行</span><br><span class="line">周期401: 切回Warp0执行计算</span><br></pre></td></tr></table></figure><p>只要有足够多的warp可以切换，计算单元就不会空闲。这就是<strong>延迟隐藏</strong>。</p><h3 id="yan-chi-yin-cang-de-shu-xue" tabindex="-1" id="延迟隐藏的数学">延迟隐藏的数学</h3><p>假设：</p><ul><li>全局内存延迟400周期</li><li>算术指令吞吐量1个/周期（每个调度器）</li><li>每SM有4个调度器</li></ul><p>完全隐藏延迟需要的最小warp数：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">需要活跃warp数 = 延迟 / 吞吐量 = 400 / 1 = 400（每调度器）</span><br><span class="line">每SM需要 = 400 / 4 = 100 warp（理论最小值）</span><br></pre></td></tr></table></figure><p>实际上每SM最多64 warp（2048线程），所以全局内存延迟很难完全隐藏。这就是为什么要尽量用共享内存和寄存器。</p><h2 id="zhan-yong-lu-occupancy" tabindex="-1" id="占用率（Occupancy）">占用率（Occupancy）</h2><h3 id="ding-yi" tabindex="-1" id="定义">定义</h3><p>**占用率（Occupancy）**是&quot;SM上活跃warp数&quot;与&quot;SM最大支持warp数&quot;的比值：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">占用率 = 活跃Warp数 / SM最大Warp数</span><br></pre></td></tr></table></figure><p>例如，Ampere SM最多支持64 warp（2048线程）。如果实际有32 warp在运行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">占用率 = 32 / 64 = 50%</span><br></pre></td></tr></table></figure><h3 id="ying-xiang-zhan-yong-lu-de-zi-yuan" tabindex="-1" id="影响占用率的资源">影响占用率的资源</h3><p>三大限制因素：</p><p><strong>1. 每block线程数</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">dim3 block(1024);  // 每block 1024线程 = 32 warp</span><br><span class="line">// SM最多16 block，但...</span><br><span class="line">// SM最多2048线程，所以只能放2个这样的block</span><br><span class="line">// 活跃 = 2 × 32 = 64 warp，占用率100%</span><br><span class="line"></span><br><span class="line">dim3 block(64);    // 每block 64线程 = 2 warp</span><br><span class="line">// SM最多16 block，可以放16个</span><br><span class="line">// 活跃 = 16 × 2 = 32 warp，占用率50%</span><br></pre></td></tr></table></figure><p><strong>2. 寄存器使用</strong></p><p>每SM寄存器数量有限（如65536个）。kernel用的寄存器越多，能同时运行的线程越少：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">假设kernel用64个寄存器/线程</span><br><span class="line">每SM可支持线程 = 65536 / 64 = 1024线程 = 32 warp</span><br><span class="line">占用率 = 32 / 64 = 50%</span><br><span class="line"></span><br><span class="line">假设kernel用32个寄存器/线程</span><br><span class="line">每SM可支持线程 = 65536 / 32 = 2048线程 = 64 warp</span><br><span class="line">占用率 = 100%</span><br></pre></td></tr></table></figure><p><strong>3. 共享内存使用</strong></p><p>每SM共享内存有限（如96KB）。block用的共享内存越多，能同时运行的block越少：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">假设block用48KB共享内存</span><br><span class="line">每SM可运行block = 96 / 48 = 2个</span><br><span class="line">假设每block 256线程 = 8 warp</span><br><span class="line">活跃 = 2 × 8 = 16 warp</span><br><span class="line">占用率 = 16 / 64 = 25%</span><br></pre></td></tr></table></figure><h3 id="ji-suan-zhan-yong-lu" tabindex="-1" id="计算占用率">计算占用率</h3><p>使用CUDA Occupancy Calculator或API：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;cuda_runtime.h&gt;</span><br><span class="line"></span><br><span class="line">int blockSize = 256;</span><br><span class="line">int minGridSize, gridSize;</span><br><span class="line"></span><br><span class="line">// 自动计算最优block大小</span><br><span class="line">cudaOccupancyMaxPotentialBlockSize(&amp;minGridSize, &amp;blockSize, </span><br><span class="line">                                    myKernel, 0, 0);</span><br><span class="line"></span><br><span class="line">// 计算给定配置的占用率</span><br><span class="line">int numBlocks;</span><br><span class="line">cudaOccupancyMaxActiveBlocksPerMultiprocessor(&amp;numBlocks, </span><br><span class="line">                                               myKernel, blockSize, 0);</span><br><span class="line">int device;</span><br><span class="line">cudaGetDevice(&amp;device);</span><br><span class="line">cudaDeviceProp prop;</span><br><span class="line">cudaGetDeviceProperties(&amp;prop, device);</span><br><span class="line">float occupancy = (float)(numBlocks * blockSize) / prop.maxThreadsPerMultiProcessor;</span><br><span class="line">printf(&quot;占用率: %.2f%%\n&quot;, occupancy * 100);</span><br></pre></td></tr></table></figure><h3 id="zhan-yong-lu-yu-xing-neng" tabindex="-1" id="占用率与性能">占用率与性能</h3><p><strong>高占用率不一定意味着高性能</strong>。这是常见误解。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">场景1：计算密集型kernel</span><br><span class="line">- 每线程用大量寄存器做复杂计算</span><br><span class="line">- 占用率可能只有25%</span><br><span class="line">- 但计算单元利用率高，性能好</span><br><span class="line"></span><br><span class="line">场景2：内存密集型kernel</span><br><span class="line">- 每线程操作简单，主要在读写内存</span><br><span class="line">- 需要高占用率来隐藏延迟</span><br><span class="line">- 50%占用率可能不够</span><br></pre></td></tr></table></figure><p><strong>原则</strong>：</p><ul><li>内存受限kernel：提高占用率有帮助</li><li>计算受限kernel：占用率够用就行，优先利用好计算资源</li><li>最佳实践：从分析实际瓶颈入手，而不是盲目追求占用率</li></ul><h2 id="zi-yuan-xian-zhi-hui-zong" tabindex="-1" id="资源限制汇总">资源限制汇总</h2><p>以Ampere架构为例：</p><table><thead><tr><th>资源</th><th>每SM限制</th><th>每Block限制</th></tr></thead><tbody><tr><td>线程数</td><td>2048</td><td>1024</td></tr><tr><td>Block数</td><td>16</td><td>-</td></tr><tr><td>Warp数</td><td>64</td><td>32</td></tr><tr><td>寄存器</td><td>65536</td><td>65536</td></tr><tr><td>共享内存</td><td>可配置,最大164KB</td><td>可配置,最大99KB</td></tr></tbody></table><h3 id="block-da-xiao-xuan-ze" tabindex="-1" id="Block大小选择">Block大小选择</h3><p><strong>实用建议</strong>：</p><ol><li><strong>128-256是安全起点</strong>：满足warp整数倍，不太大不太小</li><li><strong>必须是32的倍数</strong>：否则最后一个warp浪费线程</li><li><strong>考虑共享内存需求</strong>：block越大，共享内存分摊效率越高</li><li><strong>实测为王</strong>：最终还是要profile不同配置的性能</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">// 不好：不是32的倍数</span><br><span class="line">dim3 block(100);  // 最后warp只有4个有效线程</span><br><span class="line"></span><br><span class="line">// 好：32的倍数</span><br><span class="line">dim3 block(128);  // 4个完整warp</span><br><span class="line"></span><br><span class="line">// 也好</span><br><span class="line">dim3 block(256);  // 8个完整warp</span><br></pre></td></tr></table></figure><h2 id="bian-yi-qi-you-hua-yu-diao-shi" tabindex="-1" id="编译器优化与调试">编译器优化与调试</h2><h3 id="cha-kan-ji-cun-qi-shi-yong" tabindex="-1" id="查看寄存器使用">查看寄存器使用</h3><p>编译时加<code>--ptxas-options=-v</code>：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvcc -O3 --ptxas-options=-v mykernel.cu -o mykernel</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ptxas info : Compiling entry function &#x27;mykernel&#x27;</span><br><span class="line">ptxas info : Function properties for mykernel</span><br><span class="line">    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads</span><br><span class="line">ptxas info : Used 32 registers, 336 bytes cmem[0]</span><br></pre></td></tr></table></figure><p>32个寄存器/线程，没有溢出到local memory。</p><h3 id="kong-zhi-ji-cun-qi-shu-liang" tabindex="-1" id="控制寄存器数量">控制寄存器数量</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">__global__ void __launch_bounds__(256, 4) myKernel(...) &#123;</span><br><span class="line">    // 提示编译器：每block 256线程，每SM至少4 block</span><br><span class="line">    // 编译器会据此优化寄存器分配</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>或编译选项：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvcc -maxrregcount=32 mykernel.cu  <span class="comment"># 限制每线程最多32寄存器</span></span><br></pre></td></tr></table></figure><p><strong>权衡</strong>：限制寄存器可能导致溢出到local memory（很慢），需要平衡。</p><h3 id="nsight-compute-fen-xi" tabindex="-1" id="Nsight-Compute分析">Nsight Compute分析</h3><p>使用NVIDIA的profiler分析实际瓶颈：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ncu --<span class="built_in">set</span> full ./mykernel</span><br></pre></td></tr></table></figure><p>关注：</p><ul><li>Warp执行效率（分支发散）</li><li>内存吞吐率</li><li>计算吞吐率</li><li>占用率</li></ul><p>这比猜测有效得多。</p><h2 id="shi-li-fen-xi-ju-zhen-cheng-fa-de-block-pei-zhi" tabindex="-1" id="实例分析：矩阵乘法的Block配置">实例分析：矩阵乘法的Block配置</h2><p>回顾第三章的矩阵乘法：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">__global__ void matMul(float *M, float *N, float *P, int width) &#123;</span><br><span class="line">    int row = blockIdx.y * blockDim.y + threadIdx.y;</span><br><span class="line">    int col = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    </span><br><span class="line">    if (row &lt; width &amp;&amp; col &lt; width) &#123;</span><br><span class="line">        float sum = 0.0f;</span><br><span class="line">        for (int k = 0; k &lt; width; k++) &#123;</span><br><span class="line">            sum += M[row * width + k] * N[k * width + col];</span><br><span class="line">        &#125;</span><br><span class="line">        P[row * width + col] = sum;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>配置选择</strong>：</p><table><thead><tr><th>Block大小</th><th>Warp数</th><th>分析</th></tr></thead><tbody><tr><td>8×8=64</td><td>2</td><td>太小，warp少，延迟隐藏不足</td></tr><tr><td>16×16=256</td><td>8</td><td>合适，每SM可放多个block</td></tr><tr><td>32×32=1024</td><td>32</td><td>接近限制，灵活性差</td></tr></tbody></table><p><strong>16×16通常是二维问题的好选择</strong>。</p><p><strong>进一步优化</strong>（第5章会详细讲）：</p><ul><li>用共享内存做tiling</li><li>减少全局内存访问</li><li>算术强度从0.25提升到10+</li></ul><h2 id="xiao-jie" tabindex="-1" id="小结">小结</h2><p>第四章揭示了GPU的内部机制：</p><p><strong>架构认识</strong>：SM是独立执行单元，多个block分配到SM共享资源。理解资源限制（寄存器、共享内存、线程数），就理解了为什么某些配置性能差。</p><p><strong>Warp本质</strong>：32线程一组，SIMT执行。所有优化都围绕warp展开——让warp内线程做相同的事（避免发散），让足够多的warp参与执行（隐藏延迟）。</p><p><strong>发散代价</strong>：控制流发散是性能杀手。按warp边界划分任务、用算术替代分支、重组数据，这些技巧很实用。</p><p><strong>延迟与占用率</strong>：高占用率帮助隐藏延迟，但不是越高越好。计算密集型kernel可能不需要那么高占用率。关键是分析实际瓶颈。</p><p><strong>调优思路</strong>：</p><ul><li>Block大小选128-256，32的倍数</li><li>检查寄存器使用，控制溢出</li><li>用profiler分析，不要猜</li></ul><p>理解了这些硬件知识，第五章的共享内存（Shared Memory）优化就容易理解了。分块（Tiling）的本质就是利用共享内存减少全局内存访问，提高算术强度，充分利用计算单元。</p><hr><h2 id="xia-yi-bu" tabindex="-1" id="🚀-下一步">🚀 下一步</h2><hr><h2 id="can-kao-zi-liao" tabindex="-1" id="📚-参考资料">📚 参考资料</h2><ul><li>PMPP 第四版 Chapter 04</li><li><a href="https://smarter.xin/posts/bd5d1d6/">第四章：计算架构和调度</a></li></ul><p><strong>学习愉快！</strong> 🎓</p><hr><blockquote><p><strong>本文 GitHub 仓库</strong>: <a href="https://github.com/psmarter/PMPP-Learning">https://github.com/psmarter/PMPP-Learning</a></p></blockquote>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h2 id=&quot;qian-yan&quot; tabindex=&quot;-1&quot; id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;前三章打下了基础：第一章理解&amp;quot;为什么使用</summary>
        
      
    
    
    
    <category term="知识分享" scheme="https://smarter.xin/categories/knowledge-sharing/"/>
    
    
    <category term="CUDA" scheme="https://smarter.xin/tags/CUDA/"/>
    
    <category term="GPU编程" scheme="https://smarter.xin/tags/gpu-programming/"/>
    
    <category term="并行计算" scheme="https://smarter.xin/tags/parallel-computing/"/>
    
    <category term="PMPP" scheme="https://smarter.xin/tags/PMPP/"/>
    
    <category term="GPU架构" scheme="https://smarter.xin/tags/gpu-architecture/"/>
    
    <category term="Warp" scheme="https://smarter.xin/tags/Warp/"/>
    
  </entry>
  
</feed>
